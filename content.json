{"meta":{"title":"Jie-Think","subtitle":null,"description":"jie blog","author":"jie","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2018-08-29T12:07:03.000Z","updated":"2018-08-29T12:11:52.380Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-08-29T12:11:19.000Z","updated":"2018-08-29T12:11:36.698Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"basic/正则零宽断言","date":"2019-07-13T06:31:13.423Z","updated":"2019-07-13T06:42:17.336Z","comments":true,"path":"2019/07/13/basic/正则零宽断言/","link":"","permalink":"http://yoursite.com/2019/07/13/basic/正则零宽断言/","excerpt":"","text":"正则零宽断言(?=exp):零宽度正预测先行断言，它断言自身出现的位置的后面能匹配表达式exp。 匹配后面为_path，结果为product ‘product_path’.scan 1/(product)(?=_path)/ vscode 和 sublime 支持 (?&lt;=exp):零宽度正回顾后发断言，它断言自身出现的位置的前面能匹配表达式exp 匹配前面为name:，结果为wangfei ‘name:wangfei’.scan 1/(?&lt;=name:)(wangfei)/ vscode 和 sublime 支持 (?!exp):零宽度负预测先行断言，断言此位置的后面不能匹配表达式exp。 匹配后面不是_path ‘product_path’.scan 1/(product)(?!_path)/ 匹配后面不是_url ‘product_path’.scan 1/(product)(?!_url)/ vscode 和 sublime 支持 (?&lt;!exp):零宽度负回顾后发断言来断言此位置的前面不能匹配表达式exp 匹配前面不是name: ‘name:angelica’.scan 1/(?&lt;!name:)(angelica)/ 匹配前面不是nick_name: ‘name:angelica’.scan 1/(?&lt;!nick_name:)(angelica)/ vscode 和 sublime 支持 参考: https://www.cnblogs.com/macq/p/6597366.html#bc3","categories":[],"tags":[]},{"title":"","slug":"ide/vscode/vscode-snippet","date":"2019-07-12T04:10:34.779Z","updated":"2019-07-12T05:08:18.491Z","comments":true,"path":"2019/07/12/ide/vscode/vscode-snippet/","link":"","permalink":"http://yoursite.com/2019/07/12/ide/vscode/vscode-snippet/","excerpt":"","text":"vscode snippet参考: https://my.oschina.net/imsole/blog/1794999 https://code.visualstudio.com/docs/editor/userdefinedsnippets go.json123456789101112131415161718192021222324252627282930313233343536373839// go&#123; // Place your snippets for go here. Each snippet is defined under a snippet name and has a prefix, body and // description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are: // $1, $2 for tab stops, $0 for the final cursor position, and $&#123;1:label&#125;, $&#123;2:another&#125; for placeholders. Placeholders with the // same ids are connected. // Example: // \"Print to console\": &#123; // \"prefix\": \"log\", // \"body\": [ // \"console.log('$1');\", // \"$2\" // ], // \"description\": \"Log output to console\" // &#125; \"log_info\": &#123; \"prefix\": \"log_info\", \"body\": \"$&#123;1:log&#125;.Infof(ctx, \\\"[@%s] $3\\\", $&#123;2:fn&#125;)\", \"description\": \"log.Infof()\" &#125;, \"log_err\": &#123; \"prefix\": \"log_err\", \"body\": \"$&#123;1:log&#125;.Errorf(ctx, \\\"[@%s] $3$&#123;4:err&#125;=%v\\\", $&#123;2:fn&#125;, $4)\", \"description\": \"log Errorf\" &#125;, \"log_warn\": &#123; \"prefix\": \"log_warn\", \"body\": \"$&#123;1:log&#125;.Warningf(ctx, \\\"[@%s] $3\\\", $&#123;2:fn&#125;)\", \"description\": \"log Warningf\" &#125;, \"iferr_log\": &#123; \"prefix\": \"iferr_log\", \"body\": [ \"if $&#123;1:err&#125; != nil &#123;\", \" $&#123;2:log&#125;.Errorf(ctx, \\\"[@%s] $4$1=%v\\\", $&#123;3:fn&#125;, $1)\", \"&#125;\" ] &#125;,&#125;","categories":[],"tags":[]},{"title":"","slug":"backend/styleguide/python","date":"2019-07-09T02:38:05.087Z","updated":"2019-07-09T03:37:11.946Z","comments":true,"path":"2019/07/09/backend/styleguide/python/","link":"","permalink":"http://yoursite.com/2019/07/09/backend/styleguide/python/","excerpt":"","text":"Google Python Style Guide参考: https://google.github.io/styleguide/pyguide.html 中文翻译: https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/background/","categories":[],"tags":[]},{"title":"","slug":"backend/python/python 项目目录结构","date":"2019-07-03T15:47:46.548Z","updated":"2019-07-03T15:49:23.415Z","comments":true,"path":"2019/07/03/backend/python/python 项目目录结构/","link":"","permalink":"http://yoursite.com/2019/07/03/backend/python/python 项目目录结构/","excerpt":"","text":"python 项目结构参考: https://www.cnblogs.com/harrychinese/p/python_project_structure.html 1234567891011121314151617181920|- LICENSE |- README.md |- TODO.md |- docs | |-- index.md | |-- installation.md | |-- quickstart.md |- sandman | |-- __init__.py | |-- exception.py | |-- model.py | |-- sandman.py |- tests | |-- __init__.py | |-- test_sandman.py |- setup.py |- tox.ini |- .gitignore |- requirements.txt |- requirements_dev.txt ,比requirements.txt多的是单元测试库 Top 10项目的研究发现: readme.md和setup.py和requirements.txt放在根目录下 一个项目至少有3个子目录, docs目录, root package 和tests package 的python代码要放在一个package中, 而不是一般的src目录中. tox 测试工具大家都在用. 用pytest和nose单元测试工具比较多, 尤其是pytest 脚手架工具:下载并安装cookiecutter命令行工具,网站: 下载pip install cookiecutter cookiecutter更详细的教材","categories":[],"tags":[]},{"title":"","slug":"alg/finance/rsi","date":"2019-07-02T14:13:34.599Z","updated":"2019-07-02T14:55:16.600Z","comments":true,"path":"2019/07/02/alg/finance/rsi/","link":"","permalink":"http://yoursite.com/2019/07/02/alg/finance/rsi/","excerpt":"","text":"RSI 指标RSI ( Relative Strength Index ) 相对强弱指数RSI是根据一定时期内上涨点数和涨跌点数之和的比率制作出的一种技术曲线。能够反映出市场在一定时期内的景气程度. 由威尔斯.威尔德（Welles Wilder)最早应用于期货买卖，后来人们发现在众多的图表技术分析中，强弱指标的理论和实践极其适合于股票市场的短线投资，于是被用于股票升跌的测量和分析中。该分析指标的设计是以三条线来反映价格走势的强弱，这种图形可以为投资者提供操作依据，非常适合做短线差价操作。 参考: RSI-百度百科","categories":[],"tags":[]},{"title":"","slug":"alg/finance/bias","date":"2019-06-29T14:20:13.239Z","updated":"2019-07-06T06:03:36.254Z","comments":true,"path":"2019/06/29/alg/finance/bias/","link":"","permalink":"http://yoursite.com/2019/06/29/alg/finance/bias/","excerpt":"","text":"BIASBIAS(乖离率), 又称偏离率，简称Y值, 是通过计算市场指数或收盘价与某条移动平均线之间的差距百分比，以反映一定时期内价格与其MA偏离程度的指标，从而得出价格在剧烈波动时因偏离移动平均趋势而造成回档或反弹的可能性，以及价格在正常波动范围内移动而形成继续原有势的可信度。 乖离率，是用百分比来表示价格与MA间的偏离程度(差距率)。 乖离率曲线(BIAS)，是将各BIAS值连成线，得到的一条以0值为横向中轴之波动伸延的曲线。 计算方法 计算方法 一 $$BIAS(乖离率) = \\frac{当日收盘价-N日平均价}{N日平均价} * 100 \\%$$ 其中N，一般5、6、10、12、24、30和72。在实际运用中，短线使用6日乖离率较为有效，中线则放大为10日或12日。 计算方法 二 $BIAS=(EMA(收盘价, N) - \\frac{MA(收盘价, M)}{MA(收盘价, M)}) * 100$ 其中，N取超短周期，例如4，7，9，12等；M为大周期，例如，38，57，137，254，526等； 使用技巧 当取N的值为6: 1) 如果指数和平均线之间的乖离率达到6%以上,则表示该阶段处于超买区,投资者可以在此进行卖出的操作,如果指数与平均线之间的乖离率达到6%以下时为则显示为超卖区,投资者可在此进行买入操作. 2) 如果指数和均线乖离率达8%以上时为超买区,投资者可以考虑卖出;指数和平均线间的乖离率达到-3%以下时为超卖区,是交易者进行买进的时机. 当N取值12时; 1) 指数和12日平均线间的乖离率达5%以上时为超买区域,是投资者卖出的时机;指数和12日平均线乖离率达-5%以下时为超卖区,是交易买进的时机. 2)指数与12日平均线乖离率达6%以上时为超买区,是交易卖出的时机;指数与12日平均线的乖离率达-4%以下时为超卖区,看做是交易买进的时机. 如果汇市处于不断上升的时候,可以选择在高价处的正乖离率点卖出操作;反之汇市不断下降,可以选择在最低价的负乖离率数卖出操作. 如果遇到汇率在不断下跌的同时,负乖离率增大,空头方向可以在此处进行平仓的操作,比较安全.另外在乖离率等于零以后出现反弹,则可以进行卖出的操作. 组合应用在技术性反弹行情中乖离率指标适合与随机指标组合运用，KD指标和BIAS指标可以使得反弹行情中的操作变得及时准确。在反弹行情中，BIAS指标的功用是确认股价是否超跌，而KD指标的作用是显示个股是否有拐头向上的动能，两者的结合有利于投资者准确判断出抢反弹的最佳时机。具体的应用原则： 将BIAS指标的参数设置为24日，将KD指标的参数设置为9；3；3。 BIAS指标要小于-6，这只是确认该股超跌的初选条件。 KD指标产生黄金交叉，K线上穿D线。 KD交叉同时，KD指标中的D值要小于16。 第二种组合，乖离率指标与布林线指标的结合运用适合在超跌反弹行情中的买入：对于这类反弹行情，投资者不宜采用追涨，而要结合技术分析方法，运用BIAS和布林线指标的组合分析，把握个股进出时机。具体方法是： 当BIAS的三条短期均线全部小于0时； 股价也已经触及BOLL的下轨线LB； 布林线正处于不断收敛状态中的； BIAS的短期均线上穿长期均线，并且成交量逐渐放大的。 当符合上述条件时，投资者可以积极择股买入。 参考 https://baike.baidu.com/item/乖离率/420286","categories":[],"tags":[]},{"title":"","slug":"alg/finance/macd","date":"2019-06-27T15:43:36.269Z","updated":"2019-07-01T01:31:59.159Z","comments":true,"path":"2019/06/27/alg/finance/macd/","link":"","permalink":"http://yoursite.com/2019/06/27/alg/finance/macd/","excerpt":"","text":"MACD 指标MACD ( Moving Average Convergence / Divergence ) 称为异同移动平均线, 是从双指数移动平均线发展而来的，由快的指数移动平均线（EMA12）减去慢的指数移动平均线（EMA26）得到快线DIF，再用2×（快线DIF-DIF的9日加权移动均线DEA）得到MACD柱. MACD的计算过程1、计算移动平均值（EMA） $S_n: 今日收盘价​$ 12日EMA的算式为 $EMA_{12}(n) = EMA_{12}(n - 1) \\frac{11}{13} + S_n \\frac{2}{13}​$ 26日EMA的算式为 $EMA_{26}(n) = EMA_{26}(n - 1) \\frac{25}{27} + S_n \\frac{2}{27}​$ 2、计算离差值（DIF） $DIF(n) = EMA_{12}(n) - EMA_{26}(n)​$ 3、计算DIF的9日EMA 根据离差值计算其9日的EMA，即离差平均值，是所求的MACD值。为了不与指标原名相混淆，此值又名DEA或DEM. $DEA(n) = DEA(n-1) \\frac{8}{10} + DIF(n)\\frac{2}{10}​$ 计算出的DIF和DEA的数值均为正值或负值。 $MACD柱状图 = (DIF - DEA) * 2​$ 可参考方案 当DIF和DEA均大于0(即在图形上表示为它们处于零线以上)并向上移动时，一般表示为行情处于多头行情中，可以买入开仓或多头持仓； 当DIF和DEA均小于0(即在图形上表示为它们处于零线以下)并向下移动时，一般表示为行情处于空头行情中，可以卖出开仓或观望。 当DIF和DEA均大于0(即在图形上表示为它们处于零线以上)但都向下移动时，一般表示为行情处于下跌阶段，可以卖出开仓和观望； 当DIF和DEA均小于0时(即在图形上表示为它们处于零线以下)但向上移动时，一般表示为行情即将上涨，股票将上涨，可以买入开仓或多头持仓。 其买卖原则为： DIF、DEA均为正，DIF向上突破DEA，买入信号参考。 DIF、DEA均为负，DIF向下跌破DEA，卖出信号参考。 DIF线与K线发生背离，行情可能出现反转信号。 DIF、DEA的值从正数变成负数，或者从负数变成正数并不是交易信号，因为它们落后于市场。 基本用法 MACD金叉：DIFF 由下向上突破 DEA，为买入信号。 MACD死叉：DIFF 由上向下突破 DEA，为卖出信号。 MACD 绿转红：MACD 值由负变正，市场由空头转为多头。 MACD 红转绿：MACD 值由正变负，市场由多头转为空头。 DIFF 与 DEA 均为正值,即都在零轴线以上时，大势属多头市场，DIFF 向上突破 DEA，可作买入信号。 DIFF 与 DEA 均为负值,即都在零轴线以下时，大势属空头市场，DIFF 向下跌破 DEA，可作卖出信号。 当 DEA 线与 K 线趋势发生背离时为反转信号。 DEA 在盘整局面时失误率较高,但如果配合RSI 及KDj指标可适当弥补缺点。 参考: MACD-百度百科","categories":[],"tags":[]},{"title":"","slug":"alg/finance/kdj","date":"2019-06-27T01:32:16.198Z","updated":"2019-06-30T14:24:49.914Z","comments":true,"path":"2019/06/27/alg/finance/kdj/","link":"","permalink":"http://yoursite.com/2019/06/27/alg/finance/kdj/","excerpt":"","text":"KDJ 指标KDJ指标又叫随机指标，是一种相当新颖、实用的技术分析指标，它起先用于期货市场的分析，后被广泛用于股市的中短期趋势分析，是期货和股票市场上最常用的技术分析工具。 计算方法$RSV(n) = \\frac{Cn - Ln}{Hn - Ln} * 100​$ 公式中，Cn为第n日收盘价；Ln为n日内的最低价；Hn为n日内的最高价 其次，计算K值与D值： $K(n) = \\frac{2}{3} K(n - 1) + \\frac{1}{3} RSV(n)​$ $D(n) = \\frac{2}{3} D(n-1) + \\frac{1}{3} K(n)​$ 若无前一日K 值与D值，则可分别用50来代替。 $J(n) = 3K(n) - 2D(n)​$ 使用技巧 K与D值永远介于0到100之间。D大于80时，行情呈现超买现象。D小于20时，行情呈现超卖现象。 上涨趋势中，K值大于D值，K线向上突破D线时，为买进信号。下跌趋势中，K值小于D值，K线向下跌破D线时，为卖出信号。 KD指标不仅能反映出市场的超买超卖程度，还能通过交叉突破发出买卖信号。 KD指标不适于发行量小、交易不活跃的股票，但是KD指标对大盘和热门大盘股有极高准确性。 当随机指标与股价出现背离时，一般为转势的信号。?? K值和D值上升或者下跌的速度减弱，倾斜度趋于平缓是短期转势的预警信号。 参考: KDJ-百度百科","categories":[],"tags":[]},{"title":"","slug":"alg/finance/cci","date":"2019-06-26T15:03:32.836Z","updated":"2019-06-27T01:24:45.557Z","comments":true,"path":"2019/06/26/alg/finance/cci/","link":"","permalink":"http://yoursite.com/2019/06/26/alg/finance/cci/","excerpt":"","text":"CCI 算法CCI（Commodity Channel lndex）顺势指标是测量股价是否已超出常态分布范围的一个指数。由唐纳德·R.兰伯特（DonaldLambert）所创，属于超买超卖类指标中较特殊的一种，波动于正无限大和负无限小之间。 计算公式系统默认n为14 $TP = \\frac{最高价 + 最低价 + 收盘价}{3}$ $MA = \\frac{\\sum\\limits_{k=1}^{n} TP(i)}{n}$ MD = 最近n日 (MA - TP)的绝对值的累计和 ÷ n 可能不太准确… $MD = \\frac{MA - TP}{n}​$ $CCI(n) = \\frac{TP - MA}{MD} * 0.015$ 使用方法1,观察CCI范围 当CCI从0~+100的正常范围内，由下往上突破+100时，股指或股价有可能出现强势上涨，是买入的时机；当CCI从+100之上，由上往下跌破+100，股指或股价短线有可能出现回调，是卖出的时机。当CCI从0~-100的正常范围内，由上往下跌破-100时，股指或股价有可能出现弱势下跌，是抛出的时机。当CCI从-100的下方，由下往上突破-100时，有可能出现反弹，可逢低买入。 2, CCI运用也可以用顶背离来判断短线头部的出现，用底背离来判断短线底部的到来 当股指或股价创出新高，而CCI没有同步创出新高时，顶背离出现，短线股指或股价有可能出现回挡，可逢高卖出；当股指或股价创出新低，而CCI没有同步创出新低时，底背离出现，短线股指或股价有可能出现反弹，可逢低买入。 应用技巧1、如果CCI指标一直上行突破了100的话,表示此时的股市进入了异常波动的阶段,可能伴随着较大的成交量,可以进行中短线的投资者,此时的买入信号比较明显. 2、反之如果CCI指标向下突破了-100,则代表此时的股市进入了新一轮的下跌趋势,此时可以选择不要操作,保持观望的态度面对市场. 3、如果CCI指标从上行突破100又回到100之内的正常范围,则代表股价这一阶段的上涨行情已经疲软,投资者可以在此时选择卖出.反之CCI突破-100又回到正常范围,则代表下跌趋势已经结束,观察一段时间可能有转折的信号出现,可以先少量买入. 注意CCI指标主要用来判断100到-100范围之外的行情趋势,在这之间的趋势分析应用 CCI指标没有作用和意义,可以选择KDJ指标来分析.另外CCI指标是进行短线操作的投资者比较实用的武器,可以很快帮助交易者找到准确的交易信号. [2] 参考： [CCI百度百科(https://baike.baidu.com/item/CCI%E9%A1%BA%E5%8A%BF%E6%8C%87%E6%A0%87/6982196)","categories":[],"tags":[]},{"title":"","slug":"alg/finance/alg_list","date":"2019-06-26T15:02:55.603Z","updated":"2019-07-02T15:06:55.577Z","comments":true,"path":"2019/06/26/alg/finance/alg_list/","link":"","permalink":"http://yoursite.com/2019/06/26/alg/finance/alg_list/","excerpt":"","text":"涉及的算法： 1. MACD 2. KDJ 3. RSI 4. BOLL 5. WR 6. DMI 7. BBIBOLL 8. ROC 9. PSY 10. OBV 11. WVAD 12. CCI 13. TRIX 14. DMA 15. EXPMA 16. BIAS 17. ASI 18. VR 19. EMV 20. BRAR","categories":[],"tags":[]},{"title":"gin 实现原理","slug":"backend/go/gin/gin实现原理","date":"2019-06-04T06:52:00.000Z","updated":"2019-06-04T06:53:37.235Z","comments":true,"path":"2019/06/04/backend/go/gin/gin实现原理/","link":"","permalink":"http://yoursite.com/2019/06/04/backend/go/gin/gin实现原理/","excerpt":"","text":"待写TODO(jx)","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"gin","slug":"gin","permalink":"http://yoursite.com/tags/gin/"}]},{"title":"fsm 笔记","slug":"backend/go/fsm/fsm理解","date":"2019-06-04T06:52:00.000Z","updated":"2019-06-04T07:21:28.280Z","comments":true,"path":"2019/06/04/backend/go/fsm/fsm理解/","link":"","permalink":"http://yoursite.com/2019/06/04/backend/go/fsm/fsm理解/","excerpt":"","text":"参考: https://www.cnblogs.com/21207-iHome/p/6085334.html 参考代码: https://godoc.org/github.com/docker/infrakit/pkg/fsm","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"fsm","slug":"fsm","permalink":"http://yoursite.com/tags/fsm/"}]},{"title":"","slug":"backend/go/echo/echo_learn","date":"2019-04-27T13:55:41.966Z","updated":"2019-04-27T13:59:37.357Z","comments":true,"path":"2019/04/27/backend/go/echo/echo_learn/","link":"","permalink":"http://yoursite.com/2019/04/27/backend/go/echo/echo_learn/","excerpt":"","text":"Learn EchoEcho 目的 High performance, extensible, minimalist Go web framework Feature OverviewOptimized HTTP router which smartly prioritize routesBuild robust and scalable RESTful APIsGroup APIsExtensible middleware frameworkDefine middleware at root, group or route levelData binding for JSON, XML and form payloadHandy functions to send variety of HTTP responsesCentralized HTTP error handlingTemplate rendering with any template engineDefine your format for the loggerHighly customizableAutomatic TLS via Let’s EncryptHTTP/2 support","categories":[],"tags":[]},{"title":"","slug":"build_own_x/data_base/build_simple_database/Part12_scanning_a_multi-level_B-tree","date":"2019-03-09T03:05:29.000Z","updated":"2019-03-09T04:52:36.441Z","comments":true,"path":"2019/03/09/build_own_x/data_base/build_simple_database/Part12_scanning_a_multi-level_B-tree/","link":"","permalink":"http://yoursite.com/2019/03/09/build_own_x/data_base/build_simple_database/Part12_scanning_a_multi-level_B-tree/","excerpt":"","text":"Part12 扫描多层 B 树我们现在支持构建一个多层的 B 树, 但是对于 select 语句确还不支持, 这是一个插入15条记录的然后打印它们的测试例子.12345678910111213141516171819202122232425262728+ it 'prints all rows in a multi-level tree' do+ script = []+ (1..15).each do |i|+ script &lt;&lt; \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"+ end+ script &lt;&lt; \"select\"+ script &lt;&lt; \".exit\"+ result = run_script(script)++ expect(result[15...result.length]).to match_array([+ \"db &gt; (1, user1, person1@example.com)\",+ \"(2, user2, person2@example.com)\",+ \"(3, user3, person3@example.com)\",+ \"(4, user4, person4@example.com)\",+ \"(5, user5, person5@example.com)\",+ \"(6, user6, person6@example.com)\",+ \"(7, user7, person7@example.com)\",+ \"(8, user8, person8@example.com)\",+ \"(9, user9, person9@example.com)\",+ \"(10, user10, person10@example.com)\",+ \"(11, user11, person11@example.com)\",+ \"(12, user12, person12@example.com)\",+ \"(13, user13, person13@example.com)\",+ \"(14, user14, person14@example.com)\",+ \"(15, user15, person15@example.com)\",+ \"Executed.\", \"db &gt; \",+ ])+ end 但是当我们跑这个例子的时候, 会发生下面这样的情况:123db &gt; select(2, user1, person1@example.com)Executed. 这太糟糕了, 仅打印了一条语句, 并且看起来这条记录好像损坏了. 这糟糕的情况是因为 execute_select() 方法在表开始的时候, 我们当前接口table_start() 返回 的是根节点. 但是现在根节点现在是一个中间节点,不包含任何行信息. 打印的数据必须在根节点为叶子时保留. execute_select() 应该返回第0个 cell 最左边的叶子节点. 所以我们需要改进下旧的实现.123456789101112-Cursor* table_start(Table* table) &#123;- Cursor* cursor = malloc(sizeof(Cursor));- cursor-&gt;table = table;- cursor-&gt;page_num = table-&gt;root_page_num;- cursor-&gt;cell_num = 0;-- void* root_node = get_page(table-&gt;pager, table-&gt;root_page_num);- uint32_t num_cells = *leaf_node_num_cells(root_node);- cursor-&gt;end_of_table = (num_cells == 0);-- return cursor;-&#125; 并添加一个新的实现, 如果第0个 key 不存在, 这个方法将会返回一个最低位置的指针回去.123456789+Cursor* table_start(Table* table) &#123;+ Cursor* cursor = table_find(table, 0);++ void* node = get_page(table-&gt;pager, cursor-&gt;page_num);+ uint32_t num_cells = *leaf_node_num_cells(node);+ cursor-&gt;end_of_table = (num_cells == 0);++ return cursor;+&#125; 通过这些改变,它依旧只会打印一个节点的行数据:12345678910db &gt; select(1, user1, person1@example.com)(2, user2, person2@example.com)(3, user3, person3@example.com)(4, user4, person4@example.com)(5, user5, person5@example.com)(6, user6, person6@example.com)(7, user7, person7@example.com)Executed.db &gt; 有15条数据, 那么就包含1个中间节点和两个叶子节点, 它看起来就像这样:structure of our btree 要扫描整个表，我们需要在到达第一个叶节点后跳转到第二个叶节点。为此，我们将在名为“next_leaf”的叶节点标题中保存一个新字段，该字段将保存右侧叶子的兄弟节点的页码。最右边的叶节点将具有next_leaf值0以表示没有兄弟（无论如何，页0都保留给表的根节点）。 更新叶节点标头格式以包含新字段: 12345678910 const uint32_t LEAF_NODE_NUM_CELLS_SIZE = sizeof(uint32_t); const uint32_t LEAF_NODE_NUM_CELLS_OFFSET = COMMON_NODE_HEADER_SIZE;-const uint32_t LEAF_NODE_HEADER_SIZE =- COMMON_NODE_HEADER_SIZE + LEAF_NODE_NUM_CELLS_SIZE;+const uint32_t LEAF_NODE_NEXT_LEAF_SIZE = sizeof(uint32_t);+const uint32_t LEAF_NODE_NEXT_LEAF_OFFSET =+ LEAF_NODE_NUM_CELLS_OFFSET + LEAF_NODE_NUM_CELLS_SIZE;+const uint32_t LEAF_NODE_HEADER_SIZE = COMMON_NODE_HEADER_SIZE ++ LEAF_NODE_NUM_CELLS_SIZE ++ LEAF_NODE_NEXT_LEAF_SIZE; 添加一个新的方法去访问新的文件:123+uint32_t* leaf_node_next_leaf(void* node) &#123;+ return node + LEAF_NODE_NEXT_LEAF_OFFSET;+&#125;","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 11 - Recursively Searching the B-Tree","slug":"build_own_x/data_base/build_simple_database/Part11_recursively_seaching_the_B_tree","date":"2019-02-24T14:08:35.000Z","updated":"2019-02-25T01:44:35.234Z","comments":true,"path":"2019/02/24/build_own_x/data_base/build_simple_database/Part11_recursively_seaching_the_B_tree/","link":"","permalink":"http://yoursite.com/2019/02/24/build_own_x/data_base/build_simple_database/Part11_recursively_seaching_the_B_tree/","excerpt":"","text":"上次我们插入第15行时出错:12db &gt; insert 15 user15 person15@example.comNeed to implement searching an internal node 首先，用新的函数调用替换代码存根. 12345678 if (get_node_type(root_node) == NODE_LEAF) &#123; return leaf_node_find(table, root_page_num, key); &#125; else &#123;- printf(\"Need to implement searching an internal node\\n\");- exit(EXIT_FAILURE);+ return internal_node_find(table, root_page_num, key); &#125; &#125; 此函数将执行二进制搜索以查找应包含给定键的子项。请记住，每个子指针右侧的键是该子项包含的最大键。 three-level btree 所以我们的二进制搜索比较了查找的键和子指针右侧的键:1234567891011121314151617+Cursor* internal_node_find(Table* table, uint32_t page_num, uint32_t key) &#123;+ void* node = get_page(table-&gt;pager, page_num);+ uint32_t num_keys = *internal_node_num_keys(node);++ /* Binary search to find index of child to search */+ uint32_t min_index = 0;+ uint32_t max_index = num_keys; /* there is one more child than key */++ while (min_index != max_index) &#123;+ uint32_t index = (min_index + max_index) / 2;+ uint32_t key_to_right = *internal_node_key(node, index);+ if (key_to_right &gt;= key) &#123;+ max_index = index;+ &#125; else &#123;+ min_index = index + 1;+ &#125;+ &#125; 还要记住，内部节点的子节点可以是叶节点或更多内部节点。找到正确的孩子后，在其上调用相应的搜索功能:123456789+ uint32_t child_num = *internal_node_child(node, min_index);+ void* child = get_page(table-&gt;pager, child_num);+ switch (get_node_type(child)) &#123;+ case NODE_LEAF:+ return leaf_node_find(table, child_num, key);+ case NODE_INTERNAL:+ return internal_node_find(table, child_num, key);+ &#125;+&#125; 测试现在，将密钥插入多节点btree不再导致错误。我们可以更新我们的测试:12345678 \" - 12\", \" - 13\", \" - 14\",- \"db &gt; Need to implement searching an internal node\",+ \"db &gt; Executed.\",+ \"db &gt; \", ]) end 我也认为是时候重新考虑另一个测试了。尝试插入1400行的那个。它仍然是错误，但错误消息是新的。现在，当程序崩溃时，我们的测试不能很好地处理它。如果发生这种情况，让我们使用我们迄今为止得到的输出: 123456789101112 raw_output = nil IO.popen(\"./db test.db\", \"r+\") do |pipe| commands.each do |command|- pipe.puts command+ begin+ pipe.puts command+ rescue Errno::EPIPE+ break+ end end pipe.close_write 这表明我们的1400行测试输出了这个错误： 123456789 end script &lt;&lt; \".exit\" result = run_script(script)- expect(result[-2]).to eq('db &gt; Error: Table full.')+ expect(result.last(2)).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; Need to implement updating parent after split\",+ ]) end 看起来就像我们的待办事项列表中的下一个!","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 10 - Splitting a Leaf Node","slug":"build_own_x/data_base/build_simple_database/Part10_splitting_a_leaf_node","date":"2019-02-23T13:33:19.000Z","updated":"2019-02-24T13:10:57.765Z","comments":true,"path":"2019/02/23/build_own_x/data_base/build_simple_database/Part10_splitting_a_leaf_node/","link":"","permalink":"http://yoursite.com/2019/02/23/build_own_x/data_base/build_simple_database/Part10_splitting_a_leaf_node/","excerpt":"","text":"Part 10 - 分割叶子节点我们的 B树现在仅有一个节点. 修复它, 我们需要一些代码去分割一个叶子节点. 在哪之后我们需要去创建一个中间节点作为两个叶子节点的中间节点.基本上我们这篇文章的目标就是从这样:one-node btree 到这样:two-level btree 第一步, 先让我们移除叶子节点填充完的错误.1234567891011void leaf_node_insert(Cursor* cursor, uint32_t key, Row* value) &#123; void* node = get_page(cursor-&gt;table-&gt;pager, cursor-&gt;page_num); uint32_t num_cells = *leaf_node_num_cells(node); if (num_cells &gt;= LEAF_NODE_MAX_CELLS) &#123; // Node full- printf(\"Need to implement splitting a leaf node.\\n\");- exit(EXIT_FAILURE);+ leaf_node_split_and_insert(cursor, key, value);+ return; &#125; 123456789ExecuteResult execute_insert(Statement* statement, Table* table) &#123; void* node = get_page(table-&gt;pager, table-&gt;root_page_num); uint32_t num_cells = (*leaf_node_num_cells(node));- if (num_cells &gt;= LEAF_NODE_MAX_CELLS) &#123;- return EXECUTE_TABLE_FULL;- &#125; Row* row_to_insert = &amp;(statement-&gt;row_to_insert); uint32_t key_to_insert = row_to_insert-&gt;id; 切分算法简单的部分结束了. 从 sqlite 官网获得的一些描述信息: https://play.google.com/store/books/details/Sibsankar_Haldar_SQLite_Database_System_Design_and?id=9Z6IQQnX1JEC&amp;hl=en If there is no space on the leaf node, we would split the existing entries residing there and the new one (being inserted) into two equal halves: lower and upper halves. (Keys on the upper half are strictly greater than those on the lower half.) We allocate a new leaf node, and move the upper half into the new node. 如果叶子节点没有空间了, 我们会将驻留在那里的现有条目和新的条目（被插入）分成两半：下半部分和上半部分. (上半部分的键严格大于下半部分的键.) 我们分配一个新的叶子节点，并将上半部分移动到新节点. 让我来处理旧的节点并且创建一个新的节点:1234567891011+void leaf_node_split_and_insert(Cursor* cursor, uint32_t key, Row* value) &#123;+ /*+ Create a new node and move half the cells over.+ Insert the new value in one of the two nodes.+ Update parent or create a new parent.+ */++ void* old_node = get_page(cursor-&gt;table-&gt;pager, cursor-&gt;page_num);+ uint32_t new_page_num = get_unused_page_num(cursor-&gt;table-&gt;pager);+ void* new_node = get_page(cursor-&gt;table-&gt;pager, new_page_num);+ initialize_leaf_node(new_node); 下一步, 拷贝每一个 cell 到新的地方: 1234567891011121314151617181920212223+ /*+ All existing keys plus new key should be divided+ evenly between old (left) and new (right) nodes.+ Starting from the right, move each key to correct position.+ */+ for (int32_t i = LEAF_NODE_MAX_CELLS; i &gt;= 0; i--) &#123;+ void* destination_node;+ if (i &gt;= LEAF_NODE_LEFT_SPLIT_COUNT) &#123;+ destination_node = new_node;+ &#125; else &#123;+ destination_node = old_node;+ &#125;+ uint32_t index_within_node = i % LEAF_NODE_LEFT_SPLIT_COUNT;+ void* destination = leaf_node_cell(destination_node, index_within_node);++ if (i == cursor-&gt;cell_num) &#123;+ serialize_row(value, destination);+ &#125; else if (i &gt; cursor-&gt;cell_num) &#123;+ memcpy(destination, leaf_node_cell(old_node, i - 1), LEAF_NODE_CELL_SIZE);+ &#125; else &#123;+ memcpy(destination, leaf_node_cell(old_node, i), LEAF_NODE_CELL_SIZE);+ &#125;+ &#125; 更新 cell 的数量在每一个节点的头部:123+ /* Update cell count on both leaf nodes */+ *(leaf_node_num_cells(old_node)) = LEAF_NODE_LEFT_SPLIT_COUNT;+ *(leaf_node_num_cells(new_node)) = LEAF_NODE_RIGHT_SPLIT_COUNT; 然后我们需要更新节点的父节点. 如果原节点是一个根节点就没有父节点了. 在这种情况下, 新建一个根节点去作为父节点. 我们先去除其它情况:1234567+ if (is_node_root(old_node)) &#123;+ return create_new_root(cursor-&gt;table, new_page_num);+ &#125; else &#123;+ printf(\"Need to implement updating parent after split\\n\");+ exit(EXIT_FAILURE);+ &#125;+&#125; 分配新的页定义一些新的函数和常量. 当我们创建一个新的叶子节点的时, 我们将其放在由get_unused_page_num() 决定的页面中.12345+/*+Until we start recycling free pages, new pages will always+go onto the end of the database file+*/+uint32_t get_unused_page_num(Pager* pager) &#123; return pager-&gt;num_pages; &#125; 现在我们假设数据库现在有 N 页, 从 0 到 N -1 被分配完了. 我们总是能分配第 N 页. 最终我们实行删除后, 一些页面可能变成空并且他们的页码将不可用. 为了高效, 我们可以重新分配这些页面. 叶子节点的大小为了让树保持平衡, 我们在两个新节点之间均匀分配cells. 如果一个叶子节点能保存 N 个 cell, 然后在分割的时候需要在两个节点间分配 N+1 的 cells. (N 为原始单元加一个新的单元). 如果 N+1 是一个基数, 我随意选择左节点再获得一个单元格.123+const uint32_t LEAF_NODE_RIGHT_SPLIT_COUNT = (LEAF_NODE_MAX_CELLS + 1) / 2;+const uint32_t LEAF_NODE_LEFT_SPLIT_COUNT =+ (LEAF_NODE_MAX_CELLS + 1) - LEAF_NODE_RIGHT_SPLIT_COUNT; 创建一个新的根节点以下是SQLite数据库系统如何解释创建新根节点的过程: https://play.google.com/store/books/details/Sibsankar_Haldar_SQLite_Database_System_Design_and?id=9Z6IQQnX1JEC&amp;hl=en Let N be the root node. First allocate two nodes, say L and R. Move lower half of N into L and the upper half into R. Now N is empty. Add 〈L, K,R〉 in N, where K is the max key in L. Page N remains the root. Note that the depth of the tree has increased by one, but the new tree remains height balanced without violating any B+-tree property. 设N为根节点. 首先, 分配两个节点 L 和 R. 移动低一半的 N 到 L 和 高一半到 R 中. 现在 N 是空的了. 在 N 中, 增加 &lt;L, K, R&gt;. 这里的 K 是 L 中的最大 key . 第 N 页依旧是根. 请注意，树的深度增加了1，但新树保持高度平衡而不违反任何B + tree属性。 在这一点上，我们已经分配了正确的孩子，并将上半部分移入其中. 我们的函数将正确的子项作为输入，并分配一个新页面来存储左子项. 12345678910111213+void create_new_root(Table* table, uint32_t right_child_page_num) &#123;+ /*+ Handle splitting the root.+ Old root copied to new page, becomes left child.+ Address of right child passed in.+ Re-initialize root page to contain the new root node.+ New root node points to two children.+ */++ void* root = get_page(table-&gt;pager, table-&gt;root_page_num);+ void* right_child = get_page(table-&gt;pager, right_child_page_num);+ uint32_t left_child_page_num = get_unused_page_num(table-&gt;pager);+ void* left_child = get_page(table-&gt;pager, left_child_page_num); 旧的根数据被拷贝到左子项, 所以我能重用根页.123+ /* Left child has data copied from old root */+ memcpy(left_child, root, PAGE_SIZE);+ set_node_root(left_child, false); 最后,我们初始化一个根页为有两个孩子的中间节点.123456789+ /* Root node is a new internal node with one key and two children */+ initialize_internal_node(root);+ set_node_root(root, true);+ *internal_node_num_keys(root) = 1;+ *internal_node_child(root, 0) = left_child_page_num;+ uint32_t left_child_max_key = get_node_max_key(left_child);+ *internal_node_key(root, 0) = left_child_max_key;+ *internal_node_right_child(root) = right_child_page_num;+&#125; 中间节点的格式现在我们终于创建了一个内部节点, 我们现在去定义他的layout. 它一开始是一个普通的头, 然后是包含的键的数量, 然后是最右边孩子的页码. 内部节点总是有一个子指针而不是它们的键, 额外的指针存储在header 中.1234567891011+/*+ * Internal Node Header Layout+ */+const uint32_t INTERNAL_NODE_NUM_KEYS_SIZE = sizeof(uint32_t);+const uint32_t INTERNAL_NODE_NUM_KEYS_OFFSET = COMMON_NODE_HEADER_SIZE;+const uint32_t INTERNAL_NODE_RIGHT_CHILD_SIZE = sizeof(uint32_t);+const uint32_t INTERNAL_NODE_RIGHT_CHILD_OFFSET =+ INTERNAL_NODE_NUM_KEYS_OFFSET + INTERNAL_NODE_NUM_KEYS_SIZE;+const uint32_t INTERNAL_NODE_HEADER_SIZE = COMMON_NODE_HEADER_SIZE ++ INTERNAL_NODE_NUM_KEYS_SIZE ++ INTERNAL_NODE_RIGHT_CHILD_SIZE; 内容时一个cells 的数组, 每一个 cell 包含一个子指针和一个键. 每个键应该是左侧子项中包含的最大键.1234567+/*+ * Internal Node Body Layout+ */+const uint32_t INTERNAL_NODE_KEY_SIZE = sizeof(uint32_t);+const uint32_t INTERNAL_NODE_CHILD_SIZE = sizeof(uint32_t);+const uint32_t INTERNAL_NODE_CELL_SIZE =+ INTERNAL_NODE_CHILD_SIZE + INTERNAL_NODE_KEY_SIZE; 基于这些常量, 以下是内部节点的布局: Our internal node format 注意我们巨大的变化. 因为每一个子指针和键值对都很小, 我们能够填充510 key 和511 个子指针,在每一个中间节点. 这意味着我们永远不必遍历树的许多层来找到给定的key. # internal node layers max # leaf nodes Size of all leaf nodes 0 511^0 = 1 4 KB 1 511^1 = 512 ~2 MB 2 511^2 = 261,121 ~1 GB 3 511^3 = 133,432,831 ~550 GB 实际上，由于头部信息，key和浪费空间的开销，我们无法为每个叶节点存储完整的4 KB数据。但是我们可以通过从磁盘加载仅4页来搜索500 GB的数据。这就是B-Tree是数据库的有用数据结构的原因。以下是读取和写入内部节点的方法:123456789101112131415161718192021222324252627+uint32_t* internal_node_num_keys(void* node) &#123;+ return node + INTERNAL_NODE_NUM_KEYS_OFFSET;+&#125;++uint32_t* internal_node_right_child(void* node) &#123;+ return node + INTERNAL_NODE_RIGHT_CHILD_OFFSET;+&#125;++uint32_t* internal_node_cell(void* node, uint32_t cell_num) &#123;+ return node + INTERNAL_NODE_HEADER_SIZE + cell_num * INTERNAL_NODE_CELL_SIZE;+&#125;++uint32_t* internal_node_child(void* node, uint32_t child_num) &#123;+ uint32_t num_keys = *internal_node_num_keys(node);+ if (child_num &gt; num_keys) &#123;+ printf(\"Tried to access child_num %d &gt; num_keys %d\\n\", child_num, num_keys);+ exit(EXIT_FAILURE);+ &#125; else if (child_num == num_keys) &#123;+ return internal_node_right_child(node);+ &#125; else &#123;+ return internal_node_cell(node, child_num);+ &#125;+&#125;++uint32_t* internal_node_key(void* node, uint32_t key_num) &#123;+ return internal_node_cell(node, key_num) + INTERNAL_NODE_CHILD_SIZE;+&#125; 对于内部节点，最大密钥始终是其右键。对于叶节点，它是最大索引处的键:12345678+uint32_t get_node_max_key(void* node) &#123;+ switch (get_node_type(node)) &#123;+ case NODE_INTERNAL:+ return *internal_node_key(node, *internal_node_num_keys(node) - 1);+ case NODE_LEAF:+ return *leaf_node_key(node, *leaf_node_num_cells(node) - 1);+ &#125;+&#125; 跟踪 Root我们最终在公共节点头中使用了is_root字段。回想一下，我们使用它来决定如何拆分叶节点: 123456789+bool is_node_root(void* node) &#123;+ uint8_t value = *((uint8_t*)(node + IS_ROOT_OFFSET));+ return (bool)value;+&#125;++void set_node_root(void* node, bool is_root) &#123;+ uint8_t value = is_root;+ *((uint8_t*)(node + IS_ROOT_OFFSET)) = value;+&#125; 以下是getter 和 setter 方法:123456789+bool is_node_root(void* node) &#123;+ uint8_t value = *((uint8_t*)(node + IS_ROOT_OFFSET));+ return (bool)value;+&#125;++void set_node_root(void* node, bool is_root) &#123;+ uint8_t value = is_root;+ *((uint8_t*)(node + IS_ROOT_OFFSET)) = value;+&#125; 初始化两种类型的节点应该默认将is_root设置为false：1234567891011void initialize_leaf_node(void* node) &#123; set_node_type(node, NODE_LEAF);+ set_node_root(node, false); *leaf_node_num_cells(node) = 0; &#125;+void initialize_internal_node(void* node) &#123;+ set_node_type(node, NODE_INTERNAL);+ set_node_root(node, false);+ *internal_node_num_keys(node) = 0;+&#125; 我们应该在创建表的第一个节点时将is_root设置为true: 1234567 // New database file. Initialize page 0 as leaf node. void* root_node = get_page(pager, 0); initialize_leaf_node(root_node);+ set_node_root(root_node, true); &#125; return table; 打印树为了帮助我们可视化数据库的状态，我们应该更新.btree metacommand以打印多级树.我要替换当前的print_leaf_node（）函数.12345678-void print_leaf_node(void* node) &#123;- uint32_t num_cells = *leaf_node_num_cells(node);- printf(\"leaf (size %d)\\n\", num_cells);- for (uint32_t i = 0; i &lt; num_cells; i++) &#123;- uint32_t key = *leaf_node_key(node, i);- printf(\" - %d : %d\\n\", i, key);- &#125;-&#125; 使用一个新的递归函数，它接受任何节点，然后打印它及其子节点。它将缩进级别作为参数，随着每次递归调用而增加。我还添加了一个小的辅助函数来缩进。123456789101112131415161718192021222324252627282930313233343536+void indent(uint32_t level) &#123;+ for (uint32_t i = 0; i &lt; level; i++) &#123;+ printf(\" \");+ &#125;+&#125;++void print_tree(Pager* pager, uint32_t page_num, uint32_t indentation_level) &#123;+ void* node = get_page(pager, page_num);+ uint32_t num_keys, child;++ switch (get_node_type(node)) &#123;+ case (NODE_LEAF):+ num_keys = *leaf_node_num_cells(node);+ indent(indentation_level);+ printf(\"- leaf (size %d)\\n\", num_keys);+ for (uint32_t i = 0; i &lt; num_keys; i++) &#123;+ indent(indentation_level + 1);+ printf(\"- %d\\n\", *leaf_node_key(node, i));+ &#125;+ break;+ case (NODE_INTERNAL):+ num_keys = *internal_node_num_keys(node);+ indent(indentation_level);+ printf(\"- internal (size %d)\\n\", num_keys);+ for (uint32_t i = 0; i &lt; num_keys; i++) &#123;+ child = *internal_node_child(node, i);+ print_tree(pager, child, indentation_level + 1);++ indent(indentation_level);+ printf(\"- key %d\\n\", *internal_node_key(node, i));+ &#125;+ child = *internal_node_right_child(node);+ print_tree(pager, child, indentation_level + 1);+ break;+ &#125;+&#125; 并更新对print函数的调用，将缩进级别传递给零. 12345 &#125; else if (strcmp(input_buffer-&gt;buffer, \".btree\") == 0) &#123; printf(\"Tree:\\n\");- print_leaf_node(get_page(table-&gt;pager, 0));+ print_tree(table-&gt;pager, 0, 0); return META_COMMAND_SUCCESS; 这是新打印功能的测试用例1234567891011121314151617181920212223242526272829303132+ it 'allows printing out the structure of a 3-leaf-node btree' do+ script = (1..14).map do |i|+ \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"+ end+ script &lt;&lt; \".btree\"+ script &lt;&lt; \"insert 15 user15 person15@example.com\"+ script &lt;&lt; \".exit\"+ result = run_script(script)++ expect(result[14...(result.length)]).to match_array([+ \"db &gt; Tree:\",+ \"- internal (size 1)\",+ \" - leaf (size 7)\",+ \" - 1\",+ \" - 2\",+ \" - 3\",+ \" - 4\",+ \" - 5\",+ \" - 6\",+ \" - 7\",+ \"- key 7\",+ \" - leaf (size 7)\",+ \" - 8\",+ \" - 9\",+ \" - 10\",+ \" - 11\",+ \" - 12\",+ \" - 13\",+ \" - 14\",+ \"db &gt; Need to implement searching an internal node\",+ ])+ end 新格式有点简化，所以我们需要更新现有的.btree测试:1234567891011121314 \"db &gt; Executed.\", \"db &gt; Executed.\", \"db &gt; Tree:\",- \"leaf (size 3)\",- \" - 0 : 1\",- \" - 1 : 2\",- \" - 2 : 3\",+ \"- leaf (size 3)\",+ \" - 1\",+ \" - 2\",+ \" - 3\", \"db &gt; \" ]) end 这是新测试的.btree输出：12345678910111213141516171819Tree:- internal (size 1) - leaf (size 7) - 1 - 2 - 3 - 4 - 5 - 6 - 7 - key 7 - leaf (size 7) - 8 - 9 - 10 - 11 - 12 - 13 - 14 主要问题如果你一直密切关注，你可能会注意到我们错过了一些大事。看看如果我们尝试插入另一行会发生什么.12db &gt; insert 15 user15 person15@example.comNeed to implement searching an internal node","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 9 - Binary Search and Duplicate Keys","slug":"build_own_x/data_base/build_simple_database/Part9_binary_search_and_duplicate_keys","date":"2019-02-23T10:10:54.000Z","updated":"2019-02-23T12:52:42.043Z","comments":true,"path":"2019/02/23/build_own_x/data_base/build_simple_database/Part9_binary_search_and_duplicate_keys/","link":"","permalink":"http://yoursite.com/2019/02/23/build_own_x/data_base/build_simple_database/Part9_binary_search_and_duplicate_keys/","excerpt":"","text":"二叉搜索和唯一键上一章节我们注意到, 我们仍然按未排序的顺序存储密钥. 我们将会 fix 这个问题, 加检测并且拒绝唯一键.现在, 我们 execute_insert() 方法总是插入到表的末尾. 因此,我们应该搜索表insert 到正确的地方. 如果键已经存在返回错误. 123456789101112131415161718192021ExecuteResult execute_insert(Statement* statement, Table* table) &#123; void* node = get_page(table-&gt;pager, table-&gt;root_page_num);- if ((*leaf_node_num_cells(node) &gt;= LEAF_NODE_MAX_CELLS)) &#123;+ uint32_t num_cells = (*leaf_node_num_cells(node));+ if (num_cells &gt;= LEAF_NODE_MAX_CELLS) &#123; return EXECUTE_TABLE_FULL; &#125; Row* row_to_insert = &amp;(statement-&gt;row_to_insert);- Cursor* cursor = table_end(table);+ uint32_t key_to_insert = row_to_insert-&gt;id;+ Cursor* cursor = table_find(table, key_to_insert);++ if (cursor-&gt;cell_num &lt; num_cells) &#123;+ uint32_t key_at_index = *leaf_node_key(node, cursor-&gt;cell_num);+ if (key_at_index == key_to_insert) &#123;+ return EXECUTE_DUPLICATE_KEY;+ &#125;+ &#125; leaf_node_insert(cursor, row_to_insert-&gt;id, row_to_insert); 我们不需要 table_end() 方法.123456789101112-Cursor* table_end(Table* table) &#123;- Cursor* cursor = malloc(sizeof(Cursor));- cursor-&gt;table = table;- cursor-&gt;page_num = table-&gt;root_page_num;-- void* root_node = get_page(table-&gt;pager, table-&gt;root_page_num);- uint32_t num_cells = *leaf_node_num_cells(root_node);- cursor-&gt;cell_num = num_cells;- cursor-&gt;end_of_table = true;-- return cursor;-&#125; 我们将会有一个替代方法, 给定一个 key 搜索树. 12345678910111213141516+/*+Return the position of the given key.+If the key is not present, return the position+where it should be inserted+*/+Cursor* table_find(Table* table, uint32_t key) &#123;+ uint32_t root_page_num = table-&gt;root_page_num;+ void* root_node = get_page(table-&gt;pager, root_page_num);++ if (get_node_type(root_node) == NODE_LEAF) &#123;+ return leaf_node_find(table, root_page_num, key);+ &#125; else &#123;+ printf(\"Need to implement searching an internal node\\n\");+ exit(EXIT_FAILURE);+ &#125;+&#125; 我忽略了内部节点的分支,因为我们还没有实现内部节点. 我们可以通过二分查找来搜索叶子节点. 12345678910111213141516171819202122232425262728+Cursor* leaf_node_find(Table* table, uint32_t page_num, uint32_t key) &#123;+ void* node = get_page(table-&gt;pager, page_num);+ uint32_t num_cells = *leaf_node_num_cells(node);++ Cursor* cursor = malloc(sizeof(Cursor));+ cursor-&gt;table = table;+ cursor-&gt;page_num = page_num;++ // Binary search+ uint32_t min_index = 0;+ uint32_t one_past_max_index = num_cells;+ while (one_past_max_index != min_index) &#123;+ uint32_t index = (min_index + one_past_max_index) / 2;+ uint32_t key_at_index = *leaf_node_key(node, index);+ if (key == key_at_index) &#123;+ cursor-&gt;cell_num = index;+ return cursor;+ &#125;+ if (key &lt; key_at_index) &#123;+ one_past_max_index = index;+ &#125; else &#123;+ min_index = index + 1;+ &#125;+ &#125;++ cursor-&gt;cell_num = min_index;+ return cursor;+&#125; 这就会返回 key 的位置 如果我们想插入新 key, 返回的是下一个我们想要移动的位置 最后一个 key 的位置 因为我们现在需要检查节点的类型, 需要方法来获取和设置一个节点的值. 123456789+NodeType get_node_type(void* node) &#123;+ uint8_t value = *((uint8_t*)(node + NODE_TYPE_OFFSET));+ return (NodeType)value;+&#125;++void set_node_type(void* node, NodeType type) &#123;+ uint8_t value = type;+ *((uint8_t*)(node + NODE_TYPE_OFFSET)) = value;+&#125; 我们首先需要转换为 uint8_t ,确保它被序列化为单个字节.我们也需要初始化节点类型. 12345-void initialize_leaf_node(void* node) &#123; *leaf_node_num_cells(node) = 0; &#125;+void initialize_leaf_node(void* node) &#123;+ set_node_type(node, NODE_LEAF);+ *leaf_node_num_cells(node) = 0;+&#125; 最后, 我们需要一个新的错误并捕获它. 123456-enum ExecuteResult_t &#123; EXECUTE_SUCCESS, EXECUTE_TABLE_FULL &#125;;+enum ExecuteResult_t &#123;+ EXECUTE_SUCCESS,+ EXECUTE_DUPLICATE_KEY,+ EXECUTE_TABLE_FULL+&#125;; 123456789 case (EXECUTE_SUCCESS): printf(\"Executed.\\n\"); break;+ case (EXECUTE_DUPLICATE_KEY):+ printf(\"Error: Duplicate key.\\n\");+ break; case (EXECUTE_TABLE_FULL): printf(\"Error: Table full.\\n\"); break; 随着这些改变, 我们可以改变测试来检测订单的排序. 123456789101112 \"db &gt; Executed.\", \"db &gt; Tree:\", \"leaf (size 3)\",- \" - 0 : 3\",- \" - 1 : 1\",- \" - 2 : 2\",+ \" - 0 : 1\",+ \" - 1 : 2\",+ \" - 2 : 3\", \"db &gt; \" ]) end 我们也可以为唯一键添加一个新的测试. 12345678910111213141516+ it 'prints an error message if there is a duplicate id' do+ script = [+ \"insert 1 user1 person1@example.com\",+ \"insert 1 user1 person1@example.com\",+ \"select\",+ \".exit\",+ ]+ result = run_script(script)+ expect(result).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; Error: Duplicate key.\",+ \"db &gt; (1, user1, person1@example.com)\",+ \"Executed.\",+ \"db &gt; \",+ ])+ end 下一个,我们将实现分叶子节点和创建中间节点.","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 8 - B-Tree Leaf Node Format","slug":"build_own_x/data_base/build_simple_database/Part8_B_tree_left_node_format","date":"2019-02-08T01:02:03.000Z","updated":"2019-02-23T06:10:57.201Z","comments":true,"path":"2019/02/08/build_own_x/data_base/build_simple_database/Part8_B_tree_left_node_format/","link":"","permalink":"http://yoursite.com/2019/02/08/build_own_x/data_base/build_simple_database/Part8_B_tree_left_node_format/","excerpt":"","text":"B 树叶子节点格式我们将table 中未排序的行数据变成B树形状, 这是一个非常大的改变需要多个章节才能完成.在文章结束的时候,我们将定义叶子节点层,并且支持插入键值对到单节点树. 但是首先让我们回忆下选择树型结构的原因. 替换表的结构使用当前格式，每个页面仅存储行（没有元数据），因此它非常节省空间。插入也很快，因为我们只是追加到最后。但是，只能通过扫描整个表来查找特定行。如果我们想要删除一行，我们必须通过移动它后面的每一行来填充这个洞。 如果我们将表存储为数组，但保留按id排序的行，我们可以使用二进制搜索来查找特定的id。但是，插入会很慢，因为我们必须移动很多行来腾出空间。 相反，我们将采用树形结构。树中的每个节点都可以包含可变数量的行，因此我们必须在每个节点中存储一些信息以跟踪它包含的行数。此外，所有内部节点的存储开销都不存储任何行。作为更大的数据库文件的交换，我们可以快速插入，删除和查找。 name Unsorted Array of rows Sorted Array of rows Tree of nodes Pages contain only data only data metadata, primary keys, and data Rows per page more more fewer Insertion O(1) O(n) O(log(n)) Deletion O(n) O(n) O(log(n)) Lookup by id O(n) O(log(n)) O(log(n)) 节点的头部格式叶子节点和中间节点在不同的层上,声明一个枚举类型来跟踪节点类型: 12+enum NodeType_t &#123; NODE_INTERNAL, NODE_LEAF &#125;;+typedef enum NodeType_t NodeType; 每个节点都对应一页. 内部节点将通过存储存储子项的页码来指向其子项。B树 向寻呼机询问特定页码并返回指向页面缓存的指针。页面按页码顺序依次存储在数据库文件中。 节点需要在页面开头的标题中存储一些元数据. 每个节点将存储它是什么类型的节点，它是否是根节点，以及指向其父节点的指针（以允许查找节点的兄弟节点）.我为每个标题字段的大小和偏移量定义常量:1234567891011+/*+ * Common Node Header Layout+ */+const uint32_t NODE_TYPE_SIZE = sizeof(uint8_t);+const uint32_t NODE_TYPE_OFFSET = 0;+const uint32_t IS_ROOT_SIZE = sizeof(uint8_t);+const uint32_t IS_ROOT_OFFSET = NODE_TYPE_SIZE;+const uint32_t PARENT_POINTER_SIZE = sizeof(uint32_t);+const uint32_t PARENT_POINTER_OFFSET = IS_ROOT_OFFSET + IS_ROOT_SIZE;+const uint8_t COMMON_NODE_HEADER_SIZE =+ NODE_TYPE_SIZE + IS_ROOT_SIZE + PARENT_POINTER_SIZE; 叶子节点格式除了这些常见的头字段,叶子节点还需要存储包含有多少”cells”. 一个”Cell” 包含着一个 key/value 对.1234567+/*+ * Leaf Node Header Layout+ */+const uint32_t LEAF_NODE_NUM_CELLS_SIZE = sizeof(uint32_t);+const uint32_t LEAF_NODE_NUM_CELLS_OFFSET = COMMON_NODE_HEADER_SIZE;+const uint32_t LEAF_NODE_HEADER_SIZE =+ COMMON_NODE_HEADER_SIZE + LEAF_NODE_NUM_CELLS_SIZE; 叶子节点的内容是一个 cells 的数组, 每一个 cell 包含一个键与值(序列化的一行).123456789101112+/*+ * Leaf Node Body Layout+ */+const uint32_t LEAF_NODE_KEY_SIZE = sizeof(uint32_t);+const uint32_t LEAF_NODE_KEY_OFFSET = 0;+const uint32_t LEAF_NODE_VALUE_SIZE = ROW_SIZE;+const uint32_t LEAF_NODE_VALUE_OFFSET =+ LEAF_NODE_KEY_OFFSET + LEAF_NODE_KEY_SIZE;+const uint32_t LEAF_NODE_CELL_SIZE = LEAF_NODE_KEY_SIZE + LEAF_NODE_VALUE_SIZE;+const uint32_t LEAF_NODE_SPACE_FOR_CELLS = PAGE_SIZE - LEAF_NODE_HEADER_SIZE;+const uint32_t LEAF_NODE_MAX_CELLS =+ LEAF_NODE_SPACE_FOR_CELLS / LEAF_NODE_CELL_SIZE; 基于这些常量的定义, 叶子节点格式看起来就像这样:Our leaf node format 在表头中使用一个字节来存储一个 bool 位是及其浪费空间的, 但是这样可以简化代码去访问这些值.注意,在尾部也浪费了一些空间. 在头部后, 我们存储尽可能多的 cells , 但是剩余的空间可能无法容纳一个完整的 cell. 我们将其留空为了避免 cells 拆分到不同的节点. 访问叶子节点文件访问keys , values 和 元数据的代码都涉及使用我们刚刚定义的常量. 123456789101112131415161718+uint32_t* leaf_node_num_cells(void* node) &#123;+ return (char *)node + LEAF_NODE_NUM_CELLS_OFFSET;+&#125;++void* leaf_node_cell(void* node, uint32_t cell_num) &#123;+ return (char *)node + LEAF_NODE_HEADER_SIZE + cell_num * LEAF_NODE_CELL_SIZE;+&#125;++uint32_t* leaf_node_key(void* node, uint32_t cell_num) &#123;+ return leaf_node_cell(node, cell_num);+&#125;++void* leaf_node_value(void* node, uint32_t cell_num) &#123;+ return leaf_node_cell(node, cell_num) + LEAF_NODE_KEY_SIZE;+&#125;++void initialize_leaf_node(void* node) &#123; *leaf_node_num_cells(node) = 0; &#125;+ 这些方法返回一个指向 value 的一个指针, 所以他们可以用在获取或者设置上. 改变 Parger 和 table 对象每个节点仅占用一页, 即使没有填满. 这也意味着, 我们的 pager 不再需要支持读/写部分页面.1234567891011121314-void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123;+void pager_flush(Pager* pager, uint32_t page_num) &#123; if (pager-&gt;pages[page_num] == NULL) &#123; printf(\"Tried to flush null page\\n\"); exit(EXIT_FAILURE);@@ -242,7 +337,7 @@ void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123; &#125; ssize_t bytes_written =- write(pager-&gt;file_descriptor, pager-&gt;pages[page_num], size);+ write(pager-&gt;file_descriptor, pager-&gt;pages[page_num], PAGE_SIZE); if (bytes_written == -1) &#123; printf(\"Error writing: %d\\n\", errno); 123456789101112131415161718192021222324252627282930void db_close(Table* table) &#123; Pager* pager = table-&gt;pager;- uint32_t num_full_pages = table-&gt;num_rows / ROWS_PER_PAGE; - for (uint32_t i = 0; i &lt; num_full_pages; i++) &#123;+ for (uint32_t i = 0; i &lt; pager-&gt;num_pages; i++) &#123; if (pager-&gt;pages[i] == NULL) &#123; continue; &#125;- pager_flush(pager, i, PAGE_SIZE);+ pager_flush(pager, i); free(pager-&gt;pages[i]); pager-&gt;pages[i] = NULL; &#125; - // There may be a partial page to write to the end of the file- // This should not be needed after we switch to a B-tree- uint32_t num_additional_rows = table-&gt;num_rows % ROWS_PER_PAGE;- if (num_additional_rows &gt; 0) &#123;- uint32_t page_num = num_full_pages;- if (pager-&gt;pages[page_num] != NULL) &#123;- pager_flush(pager, page_num, num_additional_rows * ROW_SIZE);- free(pager-&gt;pages[page_num]);- pager-&gt;pages[page_num] = NULL;- &#125;- &#125;- int result = close(pager-&gt;file_descriptor); if (result == -1) &#123; printf(\"Error closing db file.\\n\"); 在数据库中存储页码会比存储行数更加有用. 页码应该关联上 pager 对象, 而不是 table, 因为这是数据库使用的页码, 而不是特定的表. 一个 B树定义了一个根节点页码, 所以表需要追踪这些信息. 12345678910111213141516171819const uint32_t PAGE_SIZE = 4096; const uint32_t TABLE_MAX_PAGES = 100;-const uint32_t ROWS_PER_PAGE = PAGE_SIZE / ROW_SIZE;-const uint32_t TABLE_MAX_ROWS = ROWS_PER_PAGE * TABLE_MAX_PAGES; struct Pager_t &#123; int file_descriptor; uint32_t file_length;+ uint32_t num_pages; void* pages[TABLE_MAX_PAGES]; &#125;; typedef struct Pager_t Pager; struct Table_t &#123; Pager* pager;- uint32_t num_rows;+ uint32_t root_page_num; &#125;; typedef struct Table_t Table; 1234567891011@@ -127,6 +200,10 @@ void* get_page(Pager* pager, uint32_t page_num) &#123; &#125; pager-&gt;pages[page_num] = page;++ if (page_num &gt;= pager-&gt;num_pages) &#123;+ pager-&gt;num_pages = page_num + 1;+ &#125; &#125; return pager-&gt;pages[page_num]; 12345678910111213@@ -184,6 +269,12 @@ Pager* pager_open(const char* filename) &#123; Pager* pager = malloc(sizeof(Pager)); pager-&gt;file_descriptor = fd; pager-&gt;file_length = file_length;+ pager-&gt;num_pages = (file_length / PAGE_SIZE);++ if (file_length % PAGE_SIZE != 0) &#123;+ printf(\"Db file is not a whole number of pages. Corrupt file.\\n\");+ exit(EXIT_FAILURE);+ &#125; for (uint32_t i = 0; i &lt; TABLE_MAX_PAGES; i++) &#123; pager-&gt;pages[i] = NULL; 游标类的改变一个游标代表了表中的一个位置. 当我们的 table 是一个简单的数据行元素的时候, 我们可以仅通过行号来访问一行数据. 现在这个一棵树, 我们通过节点的页码来确定位置. 并且 cell 的个数在节点中. 12345678 struct Cursor_t &#123; Table* table;- uint32_t row_num;+ uint32_t page_num;+ uint32_t cell_num; bool end_of_table; // Indicates a position one past the last element &#125;; typedef struct Cursor_t Cursor; 1234567891011121314 Cursor* table_start(Table* table) &#123; Cursor* cursor = malloc(sizeof(Cursor)); cursor-&gt;table = table;- cursor-&gt;row_num = 0;- cursor-&gt;end_of_table = (table-&gt;num_rows == 0);+ cursor-&gt;page_num = table-&gt;root_page_num;+ cursor-&gt;cell_num = 0;++ void* root_node = get_page(table-&gt;pager, table-&gt;root_page_num);+ uint32_t num_cells = *leaf_node_num_cells(root_node);+ cursor-&gt;end_of_table = (num_cells == 0); return cursor; &#125; 12345678910111213 Cursor* table_end(Table* table) &#123; Cursor* cursor = malloc(sizeof(Cursor)); cursor-&gt;table = table;- cursor-&gt;row_num = table-&gt;num_rows;+ cursor-&gt;page_num = table-&gt;root_page_num;++ void* root_node = get_page(table-&gt;pager, table-&gt;root_page_num);+ uint32_t num_cells = *leaf_node_num_cells(root_node);+ cursor-&gt;cell_num = num_cells; cursor-&gt;end_of_table = true; return cursor; &#125; 12345678910 void* cursor_value(Cursor* cursor) &#123;- uint32_t row_num = cursor-&gt;row_num;- uint32_t page_num = row_num / ROWS_PER_PAGE;+ uint32_t page_num = cursor-&gt;page_num; void* page = get_page(cursor-&gt;table-&gt;pager, page_num);- uint32_t row_offset = row_num % ROWS_PER_PAGE;- uint32_t byte_offset = row_offset * ROW_SIZE;- return page + byte_offset;+ return leaf_node_value(page, cursor-&gt;cell_num); &#125; 1234567891011 void cursor_advance(Cursor* cursor) &#123;- cursor-&gt;row_num += 1;- if (cursor-&gt;row_num &gt;= cursor-&gt;table-&gt;num_rows) &#123;+ uint32_t page_num = cursor-&gt;page_num;+ void* node = get_page(cursor-&gt;table-&gt;pager, page_num);++ cursor-&gt;cell_num += 1;+ if (cursor-&gt;cell_num &gt;= (*leaf_node_num_cells(node))) &#123; cursor-&gt;end_of_table = true; &#125; &#125; 插入叶子节点在本文中，我们将只实现足以获得单节点树. 回想一下上一篇文章，树开始是一个空叶节点:empty btree 键值对可以增加直到叶子节点填满: 当我们第一打开数据库的时候, 数据库文件将会是一个空的文件, 所以我们初始化页码为0为东的叶子节点(根节点):1234567891011121314151617 Table* db_open(const char* filename) &#123; Pager* pager = pager_open(filename);- uint32_t num_rows = pager-&gt;file_length / ROW_SIZE; Table* table = malloc(sizeof(Table)); table-&gt;pager = pager;- table-&gt;num_rows = num_rows;+ table-&gt;root_page_num = 0;++ if (pager-&gt;num_pages == 0) &#123;+ // New database file. Initialize page 0 as leaf node.+ void* root_node = get_page(pager, 0);+ initialize_leaf_node(root_node);+ &#125; return table; &#125; 下一步我们将写一个函数插入键值对到叶子节点. 它将会有一个游标代表插入的位置. 1234567891011121314151617181920212223+void leaf_node_insert(Cursor* cursor, uint32_t key, Row* value) &#123;+ void* node = get_page(cursor-&gt;table-&gt;pager, cursor-&gt;page_num);++ uint32_t num_cells = *leaf_node_num_cells(node);+ if (num_cells &gt;= LEAF_NODE_MAX_CELLS) &#123;+ // Node full+ printf(\"Need to implement splitting a leaf node.\\n\");+ exit(EXIT_FAILURE);+ &#125;++ if (cursor-&gt;cell_num &lt; num_cells) &#123;+ // Make room for new cell+ for (uint32_t i = num_cells; i &gt; cursor-&gt;cell_num; i--) &#123;+ memcpy(leaf_node_cell(node, i), leaf_node_cell(node, i - 1),+ LEAF_NODE_CELL_SIZE);+ &#125;+ &#125;++ *(leaf_node_num_cells(node)) += 1;+ *(leaf_node_key(node, cursor-&gt;cell_num)) = key;+ serialize_row(value, leaf_node_value(node, cursor-&gt;cell_num));+&#125;+ 我们并没有实现切分, 所以如果节点满了将会报错. 下一步, 我们将 cells 向右移动一个空间, 为新的 cell 腾出空间,然后写一个新的键值对到空的空间中. 因为我们的树目前仅有一个节点, 我们的 execute_insert() 方法仅需要调用这么帮助方法:123456789101112131415ExecuteResult execute_insert(Statement* statement, Table* table) &#123;- if (table-&gt;num_rows &gt;= TABLE_MAX_ROWS) &#123;+ void* node = get_page(table-&gt;pager, table-&gt;root_page_num);+ if ((*leaf_node_num_cells(node) &gt;= LEAF_NODE_MAX_CELLS)) &#123; return EXECUTE_TABLE_FULL; &#125; Row* row_to_insert = &amp;(statement-&gt;row_to_insert); Cursor* cursor = table_end(table); - serialize_row(row_to_insert, cursor_value(cursor));- table-&gt;num_rows += 1;+ leaf_node_insert(cursor, row_to_insert-&gt;id, row_to_insert); free(cursor); 随着这些改变,我们的数据应该是还能向以前一样工作. 异常现在会返回一个”Table Full” , 因为我们没有切分根节点. 叶子节点可以容纳多少行呢? 打印常量的命令我添加了一个新的命令打印一些常量.1234567891011121314151617181920+void print_constants() &#123;+ printf(\"ROW_SIZE: %d\\n\", ROW_SIZE);+ printf(\"COMMON_NODE_HEADER_SIZE: %d\\n\", COMMON_NODE_HEADER_SIZE);+ printf(\"LEAF_NODE_HEADER_SIZE: %d\\n\", LEAF_NODE_HEADER_SIZE);+ printf(\"LEAF_NODE_CELL_SIZE: %d\\n\", LEAF_NODE_CELL_SIZE);+ printf(\"LEAF_NODE_SPACE_FOR_CELLS: %d\\n\", LEAF_NODE_SPACE_FOR_CELLS);+ printf(\"LEAF_NODE_MAX_CELLS: %d\\n\", LEAF_NODE_MAX_CELLS);+&#125;+@@ -294,6 +376,14 @@ MetaCommandResult do_meta_command(InputBuffer* input_buffer, Table* table) &#123; if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; db_close(table); exit(EXIT_SUCCESS);+ &#125; else if (strcmp(input_buffer-&gt;buffer, \".constants\") == 0) &#123;+ printf(\"Constants:\\n\");+ print_constants();+ return META_COMMAND_SUCCESS; &#125; else &#123; return META_COMMAND_UNRECOGNIZED_COMMAND; &#125; 添加了一个单元测试 123456789101112131415161718+ it 'prints constants' do+ script = [+ \".constants\",+ \".exit\",+ ]+ result = run_script(script)++ expect(result).to match_array([+ \"db &gt; Constants:\",+ \"ROW_SIZE: 293\",+ \"COMMON_NODE_HEADER_SIZE: 6\",+ \"LEAF_NODE_HEADER_SIZE: 10\",+ \"LEAF_NODE_CELL_SIZE: 297\",+ \"LEAF_NODE_SPACE_FOR_CELLS: 4086\",+ \"LEAF_NODE_MAX_CELLS: 13\",+ \"db &gt; \",+ ])+ end 所以现在表能放下13行数据. 树的可视化为了帮助我们调试和可视化, 我添加了一个命令打印我们目前的B树. 123456789+void print_leaf_node(void* node) &#123;+ uint32_t num_cells = *leaf_node_num_cells(node);+ printf(\"leaf (size %d)\\n\", num_cells);+ for (uint32_t i = 0; i &lt; num_cells; i++) &#123;+ uint32_t key = *leaf_node_key(node, i);+ printf(\" - %d : %d\\n\", i, key);+ &#125;+&#125;+ 123456789101112131415@@ -294,6 +376,14 @@ MetaCommandResult do_meta_command(InputBuffer* input_buffer, Table* table) &#123; if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; db_close(table); exit(EXIT_SUCCESS);+ &#125; else if (strcmp(input_buffer-&gt;buffer, \".btree\") == 0) &#123;+ printf(\"Tree:\\n\");+ print_leaf_node(get_page(table-&gt;pager, 0));+ return META_COMMAND_SUCCESS; &#125; else if (strcmp(input_buffer-&gt;buffer, \".constants\") == 0) &#123; printf(\"Constants:\\n\"); print_constants(); return META_COMMAND_SUCCESS; &#125; else &#123; return META_COMMAND_UNRECOGNIZED_COMMAND; &#125; 和一个测试 1234567891011121314151617181920+ it 'allows printing out the structure of a one-node btree' do+ script = [3, 1, 2].map do |i|+ \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"+ end+ script &lt;&lt; \".btree\"+ script &lt;&lt; \".exit\"+ result = run_script(script)++ expect(result).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; Executed.\",+ \"db &gt; Executed.\",+ \"db &gt; Tree:\",+ \"leaf (size 3)\",+ \" - 0 : 3\",+ \" - 1 : 1\",+ \" - 2 : 2\",+ \"db &gt; \"+ ])+ end 我们目前依旧没有按排序顺序存储rows. 我们将注意到 execute_insert() 插入到叶子节点在table_end() 返回的时候. 所以行按插入顺序存储，就像之前一样. 下一讲完整的改动123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316const uint32_t PAGE_SIZE = 4096; const uint32_t TABLE_MAX_PAGES = 100;-const uint32_t ROWS_PER_PAGE = PAGE_SIZE / ROW_SIZE;-const uint32_t TABLE_MAX_ROWS = ROWS_PER_PAGE * TABLE_MAX_PAGES; struct Pager_t &#123; int file_descriptor; uint32_t file_length;+ uint32_t num_pages; void* pages[TABLE_MAX_PAGES]; &#125;; typedef struct Pager_t Pager; struct Table_t &#123; Pager* pager;- uint32_t num_rows;+ uint32_t root_page_num; &#125;; typedef struct Table_t Table; struct Cursor_t &#123; Table* table;- uint32_t row_num;+ uint32_t page_num;+ uint32_t cell_num; bool end_of_table; // Indicates a position one past the last element &#125;; typedef struct Cursor_t Cursor;@@ -88,6 +88,77 @@ void print_row(Row* row) &#123; printf(\"(%d, %s, %s)\\n\", row-&gt;id, row-&gt;username, row-&gt;email); &#125; +enum NodeType_t &#123; NODE_INTERNAL, NODE_LEAF &#125;;+typedef enum NodeType_t NodeType;++/*+ * Common Node Header Layout+ */+const uint32_t NODE_TYPE_SIZE = sizeof(uint8_t);+const uint32_t NODE_TYPE_OFFSET = 0;+const uint32_t IS_ROOT_SIZE = sizeof(uint8_t);+const uint32_t IS_ROOT_OFFSET = NODE_TYPE_SIZE;+const uint32_t PARENT_POINTER_SIZE = sizeof(uint32_t);+const uint32_t PARENT_POINTER_OFFSET = IS_ROOT_OFFSET + IS_ROOT_SIZE;+const uint8_t COMMON_NODE_HEADER_SIZE =+ NODE_TYPE_SIZE + IS_ROOT_SIZE + PARENT_POINTER_SIZE;++/*+ * Leaf Node Header Layout+ */+const uint32_t LEAF_NODE_NUM_CELLS_SIZE = sizeof(uint32_t);+const uint32_t LEAF_NODE_NUM_CELLS_OFFSET = COMMON_NODE_HEADER_SIZE;+const uint32_t LEAF_NODE_HEADER_SIZE =+ COMMON_NODE_HEADER_SIZE + LEAF_NODE_NUM_CELLS_SIZE;++/*+ * Leaf Node Body Layout+ */+const uint32_t LEAF_NODE_KEY_SIZE = sizeof(uint32_t);+const uint32_t LEAF_NODE_KEY_OFFSET = 0;+const uint32_t LEAF_NODE_VALUE_SIZE = ROW_SIZE;+const uint32_t LEAF_NODE_VALUE_OFFSET =+ LEAF_NODE_KEY_OFFSET + LEAF_NODE_KEY_SIZE;+const uint32_t LEAF_NODE_CELL_SIZE = LEAF_NODE_KEY_SIZE + LEAF_NODE_VALUE_SIZE;+const uint32_t LEAF_NODE_SPACE_FOR_CELLS = PAGE_SIZE - LEAF_NODE_HEADER_SIZE;+const uint32_t LEAF_NODE_MAX_CELLS =+ LEAF_NODE_SPACE_FOR_CELLS / LEAF_NODE_CELL_SIZE;++uint32_t* leaf_node_num_cells(void* node) &#123;+ return node + LEAF_NODE_NUM_CELLS_OFFSET;+&#125;++void* leaf_node_cell(void* node, uint32_t cell_num) &#123;+ return node + LEAF_NODE_HEADER_SIZE + cell_num * LEAF_NODE_CELL_SIZE;+&#125;++uint32_t* leaf_node_key(void* node, uint32_t cell_num) &#123;+ return leaf_node_cell(node, cell_num);+&#125;++void* leaf_node_value(void* node, uint32_t cell_num) &#123;+ return leaf_node_cell(node, cell_num) + LEAF_NODE_KEY_SIZE;+&#125;++void print_constants() &#123;+ printf(\"ROW_SIZE: %d\\n\", ROW_SIZE);+ printf(\"COMMON_NODE_HEADER_SIZE: %d\\n\", COMMON_NODE_HEADER_SIZE);+ printf(\"LEAF_NODE_HEADER_SIZE: %d\\n\", LEAF_NODE_HEADER_SIZE);+ printf(\"LEAF_NODE_CELL_SIZE: %d\\n\", LEAF_NODE_CELL_SIZE);+ printf(\"LEAF_NODE_SPACE_FOR_CELLS: %d\\n\", LEAF_NODE_SPACE_FOR_CELLS);+ printf(\"LEAF_NODE_MAX_CELLS: %d\\n\", LEAF_NODE_MAX_CELLS);+&#125;++void print_leaf_node(void* node) &#123;+ uint32_t num_cells = *leaf_node_num_cells(node);+ printf(\"leaf (size %d)\\n\", num_cells);+ for (uint32_t i = 0; i &lt; num_cells; i++) &#123;+ uint32_t key = *leaf_node_key(node, i);+ printf(\" - %d : %d\\n\", i, key);+ &#125;+&#125;+ void serialize_row(Row* source, void* destination) &#123; memcpy(destination + ID_OFFSET, &amp;(source-&gt;id), ID_SIZE); memcpy(destination + USERNAME_OFFSET, &amp;(source-&gt;username), USERNAME_SIZE);@@ -100,6 +171,8 @@ void deserialize_row(void* source, Row* destination) &#123; memcpy(&amp;(destination-&gt;email), source + EMAIL_OFFSET, EMAIL_SIZE); &#125; +void initialize_leaf_node(void* node) &#123; *leaf_node_num_cells(node) = 0; &#125;+ void* get_page(Pager* pager, uint32_t page_num) &#123; if (page_num &gt; TABLE_MAX_PAGES) &#123; printf(\"Tried to fetch page number out of bounds. %d &gt; %d\\n\", page_num,@@ -127,6 +200,10 @@ void* get_page(Pager* pager, uint32_t page_num) &#123; &#125; pager-&gt;pages[page_num] = page;++ if (page_num &gt;= pager-&gt;num_pages) &#123;+ pager-&gt;num_pages = page_num + 1;+ &#125; &#125; return pager-&gt;pages[page_num];@@ -135,8 +212,12 @@ void* get_page(Pager* pager, uint32_t page_num) &#123; Cursor* table_start(Table* table) &#123; Cursor* cursor = malloc(sizeof(Cursor)); cursor-&gt;table = table;- cursor-&gt;row_num = 0;- cursor-&gt;end_of_table = (table-&gt;num_rows == 0);+ cursor-&gt;page_num = table-&gt;root_page_num;+ cursor-&gt;cell_num = 0;++ void* root_node = get_page(table-&gt;pager, table-&gt;root_page_num);+ uint32_t num_cells = *leaf_node_num_cells(root_node);+ cursor-&gt;end_of_table = (num_cells == 0); return cursor; &#125;@@ -144,24 +225,28 @@ Cursor* table_start(Table* table) &#123; Cursor* table_end(Table* table) &#123; Cursor* cursor = malloc(sizeof(Cursor)); cursor-&gt;table = table;- cursor-&gt;row_num = table-&gt;num_rows;+ cursor-&gt;page_num = table-&gt;root_page_num;++ void* root_node = get_page(table-&gt;pager, table-&gt;root_page_num);+ uint32_t num_cells = *leaf_node_num_cells(root_node);+ cursor-&gt;cell_num = num_cells; cursor-&gt;end_of_table = true; return cursor; &#125; void* cursor_value(Cursor* cursor) &#123;- uint32_t row_num = cursor-&gt;row_num;- uint32_t page_num = row_num / ROWS_PER_PAGE;+ uint32_t page_num = cursor-&gt;page_num; void* page = get_page(cursor-&gt;table-&gt;pager, page_num);- uint32_t row_offset = row_num % ROWS_PER_PAGE;- uint32_t byte_offset = row_offset * ROW_SIZE;- return page + byte_offset;+ return leaf_node_value(page, cursor-&gt;cell_num); &#125; void cursor_advance(Cursor* cursor) &#123;- cursor-&gt;row_num += 1;- if (cursor-&gt;row_num &gt;= cursor-&gt;table-&gt;num_rows) &#123;+ uint32_t page_num = cursor-&gt;page_num;+ void* node = get_page(cursor-&gt;table-&gt;pager, page_num);++ cursor-&gt;cell_num += 1;+ if (cursor-&gt;cell_num &gt;= (*leaf_node_num_cells(node))) &#123; cursor-&gt;end_of_table = true; &#125; &#125;@@ -184,6 +269,12 @@ Pager* pager_open(const char* filename) &#123; Pager* pager = malloc(sizeof(Pager)); pager-&gt;file_descriptor = fd; pager-&gt;file_length = file_length;+ pager-&gt;num_pages = (file_length / PAGE_SIZE);++ if (file_length % PAGE_SIZE != 0) &#123;+ printf(\"Db file is not a whole number of pages. Corrupt file.\\n\");+ exit(EXIT_FAILURE);+ &#125; for (uint32_t i = 0; i &lt; TABLE_MAX_PAGES; i++) &#123; pager-&gt;pages[i] = NULL;@@ -194,11 +285,15 @@ Pager* pager_open(const char* filename) &#123; Table* db_open(const char* filename) &#123; Pager* pager = pager_open(filename);- uint32_t num_rows = pager-&gt;file_length / ROW_SIZE; Table* table = malloc(sizeof(Table)); table-&gt;pager = pager;- table-&gt;num_rows = num_rows;+ table-&gt;root_page_num = 0;++ if (pager-&gt;num_pages == 0) &#123;+ // New database file. Initialize page 0 as leaf node.+ void* root_node = get_page(pager, 0);+ initialize_leaf_node(root_node);+ &#125; return table; &#125;@@ -228,7 +323,7 @@ void read_input(InputBuffer* input_buffer) &#123; input_buffer-&gt;buffer[bytes_read - 1] = 0; &#125; -void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123;+void pager_flush(Pager* pager, uint32_t page_num) &#123; if (pager-&gt;pages[page_num] == NULL) &#123; printf(\"Tried to flush null page\\n\"); exit(EXIT_FAILURE);@@ -242,7 +337,7 @@ void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123; &#125; ssize_t bytes_written =- write(pager-&gt;file_descriptor, pager-&gt;pages[page_num], size);+ write(pager-&gt;file_descriptor, pager-&gt;pages[page_num], PAGE_SIZE); if (bytes_written == -1) &#123; printf(\"Error writing: %d\\n\", errno);@@ -252,29 +347,16 @@ void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123; void db_close(Table* table) &#123; Pager* pager = table-&gt;pager;- uint32_t num_full_pages = table-&gt;num_rows / ROWS_PER_PAGE; - for (uint32_t i = 0; i &lt; num_full_pages; i++) &#123;+ for (uint32_t i = 0; i &lt; pager-&gt;num_pages; i++) &#123; if (pager-&gt;pages[i] == NULL) &#123; continue; &#125;- pager_flush(pager, i, PAGE_SIZE);+ pager_flush(pager, i); free(pager-&gt;pages[i]); pager-&gt;pages[i] = NULL; &#125; - // There may be a partial page to write to the end of the file- // This should not be needed after we switch to a B-tree- uint32_t num_additional_rows = table-&gt;num_rows % ROWS_PER_PAGE;- if (num_additional_rows &gt; 0) &#123;- uint32_t page_num = num_full_pages;- if (pager-&gt;pages[page_num] != NULL) &#123;- pager_flush(pager, page_num, num_additional_rows * ROW_SIZE);- free(pager-&gt;pages[page_num]);- pager-&gt;pages[page_num] = NULL;- &#125;- &#125;- int result = close(pager-&gt;file_descriptor); if (result == -1) &#123; printf(\"Error closing db file.\\n\");@@ -294,6 +376,14 @@ MetaCommandResult do_meta_command(InputBuffer* input_buffer, Table* table) &#123; if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; db_close(table); exit(EXIT_SUCCESS);+ &#125; else if (strcmp(input_buffer-&gt;buffer, \".btree\") == 0) &#123;+ printf(\"Tree:\\n\");+ print_leaf_node(get_page(table-&gt;pager, 0));+ return META_COMMAND_SUCCESS;+ &#125; else if (strcmp(input_buffer-&gt;buffer, \".constants\") == 0) &#123;+ printf(\"Constants:\\n\");+ print_constants();+ return META_COMMAND_SUCCESS; &#125; else &#123; return META_COMMAND_UNRECOGNIZED_COMMAND; &#125;@@ -342,16 +432,39 @@ PrepareResult prepare_statement(InputBuffer* input_buffer, return PREPARE_UNRECOGNIZED_STATEMENT; &#125; +void leaf_node_insert(Cursor* cursor, uint32_t key, Row* value) &#123;+ void* node = get_page(cursor-&gt;table-&gt;pager, cursor-&gt;page_num);++ uint32_t num_cells = *leaf_node_num_cells(node);+ if (num_cells &gt;= LEAF_NODE_MAX_CELLS) &#123;+ // Node full+ printf(\"Need to implement splitting a leaf node.\\n\");+ exit(EXIT_FAILURE);+ &#125;++ if (cursor-&gt;cell_num &lt; num_cells) &#123;+ // Make room for new cell+ for (uint32_t i = num_cells; i &gt; cursor-&gt;cell_num; i--) &#123;+ memcpy(leaf_node_cell(node, i), leaf_node_cell(node, i - 1),+ LEAF_NODE_CELL_SIZE);+ &#125;+ &#125;++ *(leaf_node_num_cells(node)) += 1;+ *(leaf_node_key(node, cursor-&gt;cell_num)) = key;+ serialize_row(value, leaf_node_value(node, cursor-&gt;cell_num));+&#125;+ ExecuteResult execute_insert(Statement* statement, Table* table) &#123;- if (table-&gt;num_rows &gt;= TABLE_MAX_ROWS) &#123;+ void* node = get_page(table-&gt;pager, table-&gt;root_page_num);+ if ((*leaf_node_num_cells(node) &gt;= LEAF_NODE_MAX_CELLS)) &#123; return EXECUTE_TABLE_FULL; &#125; Row* row_to_insert = &amp;(statement-&gt;row_to_insert); Cursor* cursor = table_end(table); - serialize_row(row_to_insert, cursor_value(cursor));- table-&gt;num_rows += 1;+ leaf_node_insert(cursor, row_to_insert-&gt;id, row_to_insert); free(cursor); specs 改动 12345678910111213141516171819202122232425262728293031323334353637383940+ it 'allows printing out the structure of a one-node btree' do+ script = [3, 1, 2].map do |i|+ \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"+ end+ script &lt;&lt; \".btree\"+ script &lt;&lt; \".exit\"+ result = run_script(script)++ expect(result).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; Executed.\",+ \"db &gt; Executed.\",+ \"db &gt; Tree:\",+ \"leaf (size 3)\",+ \" - 0 : 3\",+ \" - 1 : 1\",+ \" - 2 : 2\",+ \"db &gt; \"+ ])+ end++ it 'prints constants' do+ script = [+ \".constants\",+ \".exit\",+ ]+ result = run_script(script)++ expect(result).to match_array([+ \"db &gt; Constants:\",+ \"ROW_SIZE: 293\",+ \"COMMON_NODE_HEADER_SIZE: 6\",+ \"LEAF_NODE_HEADER_SIZE: 10\",+ \"LEAF_NODE_CELL_SIZE: 297\",+ \"LEAF_NODE_SPACE_FOR_CELLS: 4086\",+ \"LEAF_NODE_MAX_CELLS: 13\",+ \"db &gt; \",+ ])+ end end","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 6 - B树介绍","slug":"build_own_x/data_base/build_simple_database/Part7_introduction_b_tree","date":"2019-02-03T10:08:34.000Z","updated":"2019-02-08T01:00:44.691Z","comments":true,"path":"2019/02/03/build_own_x/data_base/build_simple_database/Part7_introduction_b_tree/","link":"","permalink":"http://yoursite.com/2019/02/03/build_own_x/data_base/build_simple_database/Part7_introduction_b_tree/","excerpt":"","text":"介绍 B 树B树在SQLite中同时代表了表和索引, 这是一个非常棒的idea. 这一篇文章仅仅介绍数据结构, 所以不涉及代码的改动. 为什么 B 树对于数据库是一个非常棒的结构. 搜索一部分内容非常快(时间复杂度是 log 基本) 插入和删除一个值你也会发现相等的快(重新平衡是常数时间). 便利一个范围的数据也是非常快(当然不能和 map 比). B 树不像二叉树, B树的 “B”可能代表发现者的名称, 但是也有平衡的意思.下图是一个 B 树的例子:example B-Tree (https://en.wikipedia.org/wiki/File:B-tree.svg) 不像二叉树, B树的每个节点可以有 m 个孩子, 这里 m 叫树的 “order”. 为了保证树尽可能的平衡, 我们不得不控制节点个数在 m/2 的数量下. 一些例外: 叶子节点有0个孩子 根节点可能可能有少于 m 个节点,但是至少是有两个的 如果根节点是一个叶子节点,他就会有0个孩子. 上图是一个B树,在 Sqlite 中被用于存储索引, 为了存储表数据 Sqlite 用了一个 B+ 树. title B-tree B+ tree Pronounced “Bee Tree” “Bee Plus Tree” Used to store Indexes Tables Internal nodes store keys Yes Yes Internal nodes store values Yes No Number of children per node Less More Internal nodes vs. leaf nodes Same structure Different structure 在我们开始实现索引之前，我将仅讨论B +树，但我只是将其称为B树或b树 带子节点的节点称为“内部”节点。内部节点和叶节点的结构不同： For an order-m tree… Internal Node Leaf Node Stores keys and pointers to children keys and values Number of keys up to m-1 as many as will fit Number of pointers number of keys + 1 none Number of values none number of keys Key purpose used for routing paired with value Stores values? No Yes 让我们通过一个例子来看下B树在插入元素后是如何增长的. 为了简单, 树的 order 是3. 这也意味着: 每个内部节点最多有三个孩子 每一个内部节点最多两个键. 每个内部节点至少有2个子节点 每个内部节点至少有一个key 一个空的B树就一个单节点: 根节点. 根节点开始于叶子接口存在0个键值对:empty btree 如果我们插入一个键值对, 它们将按顺序存储在叶子节点中. one-node btree 假设叶节点的容量是两个键/值对。当我们插入另一个时，我们必须拆分叶节点并在每个节点中放置一半对。两个节点都成为新内部节点的子节点，现在它将成为根节点。 two-level btree 内部节点有1个键和2个指向子节点的指针。如果我们想要查找小于或等于5的键，我们会查看左边的孩子。如果我们想要查找大于5的密钥，我们会找到合适的孩子。","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 5 - 游标的抽象化","slug":"build_own_x/data_base/build_simple_database/Part6_the_cursor_abstrction","date":"2019-02-03T09:18:34.000Z","updated":"2019-02-03T09:54:43.881Z","comments":true,"path":"2019/02/03/build_own_x/data_base/build_simple_database/Part6_the_cursor_abstrction/","link":"","permalink":"http://yoursite.com/2019/02/03/build_own_x/data_base/build_simple_database/Part6_the_cursor_abstrction/","excerpt":"","text":"Part 5 - 游标的抽象化这应该是最短的一章了, 我们仅仅是重构了一点,为了更好的开始 B 树的抽象化. 我们将会添加一个 Cursor 类, 标识数据在表的位置. 你可能需要做的事情: 在表开始之前创建游标 在表结束之后创建游标 访问光标指向的行 将光标前进到下一行 基于上面的行为,我们需要将会实现下面的一些东西: 通过游标删除行点 通过游标修改行点 通过给你的 ID 搜索表, 通过行的 ID 创建游标点. 游标的类型:123456+struct Cursor_t &#123;+ Table* table;+ uint32_t row_num;+ bool end_of_table; // Indicates a position one past the last element+&#125;;+typedef struct Cursor_t Cursor; 根据我们当前的表数据结构，您需要在表中标识位置的所有内容都是行号。一个游标当然还有对表的应用.最后有一个布尔类型的标识end_of_table, 所以我们可以代表这是表的末尾 table_start() 和 table_end() 会创建一些新的游标. 1234567891011121314151617+Cursor* table_start(Table* table) &#123;+ Cursor* cursor = malloc(sizeof(Cursor));+ cursor-&gt;table = table;+ cursor-&gt;row_num = 0;+ cursor-&gt;end_of_table = (table-&gt;num_rows == 0);++ return cursor;+&#125;++Cursor* table_end(Table* table) &#123;+ Cursor* cursor = malloc(sizeof(Cursor));+ cursor-&gt;table = table;+ cursor-&gt;row_num = table-&gt;num_rows;+ cursor-&gt;end_of_table = true;++ return cursor;+&#125; 我们的row_slot() 方法将会变为cursor_value() 它返回一个指向光标所描述位置的指针. 12345678910-void* row_slot(Table* table, uint32_t row_num) &#123;+void* cursor_value(Cursor* cursor) &#123;+ uint32_t row_num = cursor-&gt;row_num; uint32_t page_num = row_num / ROWS_PER_PAGE;- void* page = get_page(table-&gt;pager, page_num);+ void* page = get_page(cursor-&gt;table-&gt;pager, page_num); uint32_t row_offset = row_num % ROWS_PER_PAGE; uint32_t byte_offset = row_offset * ROW_SIZE; return page + byte_offset; &#125; 在我们当前的表结构中推进游标就像递增行号一样简单. 这在 B 树中会更加复杂 123456+void cursor_advance(Cursor* cursor) &#123;+ cursor-&gt;row_num += 1;+ if (cursor-&gt;row_num &gt;= cursor-&gt;table-&gt;num_rows) &#123;+ cursor-&gt;end_of_table = true;+ &#125;+&#125; 最后,我们可以改变虚拟机方法来使用游标抽象, 当我们查出一行数据, 我们将在表的尾部开一个游标, 将地址写入, 然后关闭游标.1234567891011 Row* row_to_insert = &amp;(statement-&gt;row_to_insert);+ Cursor* cursor = table_end(table);- serialize_row(row_to_insert, row_slot(table, table-&gt;num_rows));+ serialize_row(row_to_insert, cursor_value(cursor)); table-&gt;num_rows += 1;+ free(cursor);+ return EXECUTE_SUCCESS; &#125; 当我们 select 所有的行的时候, 我们在表开始的地方开一个游标, 打印行,然后移动游标到下一行, 一直重复直到行末. 12345678910111213141516ExecuteResult execute_select(Statement* statement, Table* table) &#123;+ Cursor* cursor = table_start(table);+ Row row;- for (uint32_t i = 0; i &lt; table-&gt;num_rows; i++) &#123;- deserialize_row(row_slot(table, i), &amp;row);+ while (!(cursor-&gt;end_of_table)) &#123;+ deserialize_row(cursor_value(cursor), &amp;row); print_row(&amp;row);+ cursor_advance(cursor); &#125;++ free(cursor);+ return EXECUTE_SUCCESS; &#125; 正如我所讲的, 这是一个简短的重构,为了将我们的table 数据重新写到 B 树中.execute_select() 和 execute_insert() 可以完全通过游标与表进行交互，而无需假设表的存储方式。 下面是完整的代码改动: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687 &#125;; typedef struct Table_t Table; +struct Cursor_t &#123;+ Table* table;+ uint32_t row_num;+ bool end_of_table; // Indicates a position one past the last element+&#125;;+typedef struct Cursor_t Cursor;+ void print_row(Row* row) &#123; printf(\"(%d, %s, %s)\\n\", row-&gt;id, row-&gt;username, row-&gt;email); &#125;@@ -125,14 +132,40 @@ void* get_page(Pager* pager, uint32_t page_num) &#123; return pager-&gt;pages[page_num]; &#125; -void* row_slot(Table* table, uint32_t row_num) &#123;+Cursor* table_start(Table* table) &#123;+ Cursor* cursor = malloc(sizeof(Cursor));+ cursor-&gt;table = table;+ cursor-&gt;row_num = 0;+ cursor-&gt;end_of_table = (table-&gt;num_rows == 0);++ return cursor;+&#125;++Cursor* table_end(Table* table) &#123;+ Cursor* cursor = malloc(sizeof(Cursor));+ cursor-&gt;table = table;+ cursor-&gt;row_num = table-&gt;num_rows;+ cursor-&gt;end_of_table = true;++ return cursor;+&#125;++void* cursor_value(Cursor* cursor) &#123;+ uint32_t row_num = cursor-&gt;row_num; uint32_t page_num = row_num / ROWS_PER_PAGE;- void* page = get_page(table-&gt;pager, page_num);+ void* page = get_page(cursor-&gt;table-&gt;pager, page_num); uint32_t row_offset = row_num % ROWS_PER_PAGE; uint32_t byte_offset = row_offset * ROW_SIZE; return page + byte_offset; &#125; +void cursor_advance(Cursor* cursor) &#123;+ cursor-&gt;row_num += 1;+ if (cursor-&gt;row_num &gt;= cursor-&gt;table-&gt;num_rows) &#123;+ cursor-&gt;end_of_table = true;+ &#125;+&#125;+ Pager* pager_open(const char* filename) &#123; int fd = open(filename, O_RDWR | // Read/Write mode@@ -315,19 +348,28 @@ ExecuteResult execute_insert(Statement* statement, Table* table) &#123; &#125; Row* row_to_insert = &amp;(statement-&gt;row_to_insert);+ Cursor* cursor = table_end(table); - serialize_row(row_to_insert, row_slot(table, table-&gt;num_rows));+ serialize_row(row_to_insert, cursor_value(cursor)); table-&gt;num_rows += 1; + free(cursor);+ return EXECUTE_SUCCESS; &#125; ExecuteResult execute_select(Statement* statement, Table* table) &#123;+ Cursor* cursor = table_start(table);+ Row row;- for (uint32_t i = 0; i &lt; table-&gt;num_rows; i++) &#123;- deserialize_row(row_slot(table, i), &amp;row);+ while (!(cursor-&gt;end_of_table)) &#123;+ deserialize_row(cursor_value(cursor), &amp;row); print_row(&amp;row);+ cursor_advance(cursor); &#125;++ free(cursor);+ return EXECUTE_SUCCESS; &#125;","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 5 - 持久化到硬盘","slug":"build_own_x/data_base/build_simple_database/Part5_persistence_to_disk","date":"2019-01-28T14:30:00.000Z","updated":"2019-02-01T13:41:25.414Z","comments":true,"path":"2019/01/28/build_own_x/data_base/build_simple_database/Part5_persistence_to_disk/","link":"","permalink":"http://yoursite.com/2019/01/28/build_own_x/data_base/build_simple_database/Part5_persistence_to_disk/","excerpt":"","text":"Part 5 - 持久化到硬盘 “Nothing in the world can take the place of persistence.” – Calvin Coolidge 我们的数据库允许你插入数据并且取回数据, 但是仅仅是在程序运行的时候.如果你 kill 程序或者重启它, 你的数据将会丢失. 这个spec单元测试类可以模拟这个情况: 12345678910111213141516171819it 'keeps data after closing connection' do result1 = run_script([ \"insert 1 user1 person1@example.com\", \".exit\", ]) expect(result1).to match_array([ \"db &gt; Executed.\", \"db &gt; \", ]) result2 = run_script([ \"select\", \".exit\", ]) expect(result2).to match_array([ \"db &gt; (1, user1, person1@example.com)\", \"Executed.\", \"db &gt; \", ])end 就行 Sqlite 一样, 我们将持久化数据到一个文件中. 我们已经将行数据序列化行数据到内存块中了, 添加序列化, 我们可以简单的将内存块数据到文件中, 并且在下次程序启动时读取文件到内存中. 为了使其更加简单,我们将定义一个抽象的pager , 我们可以向 pager 获取页面 x 的内容, 可以简单的将内存块写到文件中. 它首先会在缓存中查看, 如果缓存中没有再从硬盘从拷贝数据. How our program matches up with SQLite architecture Pager 访问页面缓存和文件, Tabel 通过 pager 请求页面数据. 123456789101112+struct Pager_t &#123;+ int file_descriptor;+ uint32_t file_length;+ void* pages[TABLE_MAX_PAGES];+&#125;;+typedef struct Pager_t Pager;+ struct Table_t &#123;- void* pages[TABLE_MAX_PAGES];+ Pager* pager; uint32_t num_rows; &#125;; 我重新命名下 new_table() 为 db_open() , 它现在有打开数据库的效果了, 通过打开一个连接, 我的意思是: 打开数据库文件 初始化一页数据 初始化一个 table 的结构 123456789101112-Table* new_table() &#123;+Table* db_open(const char* filename) &#123;+ Pager* pager = pager_open(filename);+ uint32_t num_rows = pager-&gt;file_length / ROW_SIZE;+ Table* table = malloc(sizeof(Table));- table-&gt;num_rows = 0;+ table-&gt;pager = pager;+ table-&gt;num_rows = num_rows; return table; &#125; db_open() 方法调用的是 pager_open() 方法, 将打开数据库文件并且跟踪它的大小, 同时初始化page 的缓存为 NULL. 12345678910111213141516171819202122232425+Pager* pager_open(const char* filename) &#123;+ int fd = open(filename,+ O_RDWR | // Read/Write mode+ O_CREAT, // Create file if it does not exist+ S_IWUSR | // User write permission+ S_IRUSR // User read permission+ );++ if (fd == -1) &#123;+ printf(\"Unable to open file\\n\");+ exit(EXIT_FAILURE);+ &#125;++ off_t file_length = lseek(fd, 0, SEEK_END);++ Pager* pager = malloc(sizeof(Pager));+ pager-&gt;file_descriptor = fd;+ pager-&gt;file_length = file_length;++ for (uint32_t i = 0; i &lt; TABLE_MAX_PAGES; i++) &#123;+ pager-&gt;pages[i] = NULL;+ &#125;++ return pager;+&#125; 随着我们新的抽象, 我们需要将我们获取页数据的代码移动到新的方法中. 123456789101112 void* row_slot(Table* table, uint32_t row_num) &#123; uint32_t page_num = row_num / ROWS_PER_PAGE;- void* page = table-&gt;pages[page_num];- if (!page) &#123;- // Allocate memory only when we try to access page- page = table-&gt;pages[page_num] = malloc(PAGE_SIZE);- &#125;+ void* page = get_page(table-&gt;pager, page_num); uint32_t row_offset = row_num % ROWS_PER_PAGE; uint32_t byte_offset = row_offset * ROW_SIZE; return page + byte_offset; &#125; get_page() 方法中存在一个逻辑是处理丢失的缓存问题. 我们假设页面在数据库文件中一个接一个地保存：第0页的偏移量是0, 第一页的偏移量是4096, 第二页的偏移量是8192,等等. 如果请求的页面超出了文件边界值, 我们知道将会是空白的. 所以我们仅分配一些内存并且返回它. 当我 flush 缓存数据到硬盘后, 添加到文件中. 12345678910111213141516171819202122232425262728293031+void* get_page(Pager* pager, uint32_t page_num) &#123;+ if (page_num &gt; TABLE_MAX_PAGES) &#123;+ printf(\"Tried to fetch page number out of bounds. %d &gt; %d\\n\", page_num,+ TABLE_MAX_PAGES);+ exit(EXIT_FAILURE);+ &#125;++ if (pager-&gt;pages[page_num] == NULL) &#123;+ // Cache miss. Allocate memory and load from file.+ void* page = malloc(PAGE_SIZE);+ uint32_t num_pages = pager-&gt;file_length / PAGE_SIZE;++ // We might save a partial page at the end of the file+ if (pager-&gt;file_length % PAGE_SIZE) &#123;+ num_pages += 1;+ &#125;++ if (page_num &lt;= num_pages) &#123;+ lseek(pager-&gt;file_descriptor, page_num * PAGE_SIZE, SEEK_SET);+ ssize_t bytes_read = read(pager-&gt;file_descriptor, page, PAGE_SIZE);+ if (bytes_read == -1) &#123;+ printf(\"Error reading file: %d\\n\", errno);+ exit(EXIT_FAILURE);+ &#125;+ &#125;++ pager-&gt;pages[page_num] = page;+ &#125;++ return pager-&gt;pages[page_num];+&#125; 现在我们将等待缓存flush 到硬盘, 直到用户关闭了数据库连接, 当用户退出后,我们会去调用db_close() 方法 flush 页面缓存到硬盘 关闭数据库文件 释放 pager 和 table 的内存 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+void db_close(Table* table) &#123;+ Pager* pager = table-&gt;pager;+ uint32_t num_full_pages = table-&gt;num_rows / ROWS_PER_PAGE;++ for (uint32_t i = 0; i &lt; num_full_pages; i++) &#123;+ if (pager-&gt;pages[i] == NULL) &#123;+ continue;+ &#125;+ pager_flush(pager, i, PAGE_SIZE);+ free(pager-&gt;pages[i]);+ pager-&gt;pages[i] = NULL;+ &#125;++ // There may be a partial page to write to the end of the file+ // This should not be needed after we switch to a B-tree+ uint32_t num_additional_rows = table-&gt;num_rows % ROWS_PER_PAGE;+ if (num_additional_rows &gt; 0) &#123;+ uint32_t page_num = num_full_pages;+ if (pager-&gt;pages[page_num] != NULL) &#123;+ pager_flush(pager, page_num, num_additional_rows * ROW_SIZE);+ free(pager-&gt;pages[page_num]);+ pager-&gt;pages[page_num] = NULL;+ &#125;+ &#125;++ int result = close(pager-&gt;file_descriptor);+ if (result == -1) &#123;+ printf(\"Error closing db file.\\n\");+ exit(EXIT_FAILURE);+ &#125;+ for (uint32_t i = 0; i &lt; TABLE_MAX_PAGES; i++) &#123;+ void* page = pager-&gt;pages[i];+ if (page) &#123;+ free(page);+ pager-&gt;pages[i] = NULL;+ &#125;+ &#125;+ free(pager);+&#125;+-MetaCommandResult do_meta_command(InputBuffer* input_buffer) &#123;+MetaCommandResult do_meta_command(InputBuffer* input_buffer, Table* table) &#123; if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123;+ db_close(table); exit(EXIT_SUCCESS); &#125; else &#123; return META_COMMAND_UNRECOGNIZED_COMMAND; 在我们当前的设计中, 文件的长度取决于有多少数据在数据库中. 所以我们需要写一个局部的文件在文件的尾部. 这就是为啥pager_flush() 同时需要一个页面和文件大小.这不是最好的设计, 当我们使用 B 树后, 这个会变好的. 123456789101112131415161718192021+void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123;+ if (pager-&gt;pages[page_num] == NULL) &#123;+ printf(\"Tried to flush null page\\n\");+ exit(EXIT_FAILURE);+ &#125;++ off_t offset = lseek(pager-&gt;file_descriptor, page_num * PAGE_SIZE, SEEK_SET);++ if (offset == -1) &#123;+ printf(\"Error seeking: %d\\n\", errno);+ exit(EXIT_FAILURE);+ &#125;++ ssize_t bytes_written =+ write(pager-&gt;file_descriptor, pager-&gt;pages[page_num], size);++ if (bytes_written == -1) &#123;+ printf(\"Error writing: %d\\n\", errno);+ exit(EXIT_FAILURE);+ &#125;+&#125; 最后, 我们需要从命令行接收文件名的参数, 别忘了添加扩展参数到do_meta_command方法中. 123456789101112131415161718int main(int argc, char* argv[]) &#123;- Table* table = new_table();+ if (argc &lt; 2) &#123;+ printf(\"Must supply a database filename.\\n\");+ exit(EXIT_FAILURE);+ &#125;++ char* filename = argv[1];+ Table* table = db_open(filename);+ InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt(); read_input(input_buffer); if (input_buffer-&gt;buffer[0] == '.') &#123;- switch (do_meta_command(input_buffer)) &#123;+ switch (do_meta_command(input_buffer, table)) &#123; 通过这些改变, 我们的数据库可以关闭重新打开, 我们的数据依旧存在着 1234567891011121314~ ./db mydb.dbdb &gt; insert 1 cstack foo@bar.comExecuted.db &gt; insert 2 voltorb volty@example.comExecuted.db &gt; .exit~~ ./db mydb.dbdb &gt; select(1, cstack, foo@bar.com)(2, voltorb, volty@example.com)Executed.db &gt; .exit~ 为找一些有趣的事, 我们来看下 mydb.db 文件 看看我们的数据是如何存储的. 我们将使用 vim 的16进制编辑器打开它. 12vim mydb.db:%!xxd 第一行的4个字节是我们的 ID (4个字节是因为我们存储了一个 uint32_t). 它以little-endian字节顺序存储，因此最低有效字节首先出现（01）,随后跟的是高位字节(00 00 00). 我们使用memcpy()方法将 Row 结构的中的数据拷贝到 page 缓存中, 所以这个也意味着这个结构在内存中也是底字节序的. 这个属性是我们汇编程序所决定的. 如果我们写了一个小端序的数据库文件,然后在大端序的机器上打开的, 我们需要修改serialize_now() 和 deserialize_now()方法保证读取和存储都是相同的顺序. 下一个33字节存储的是用户名, 并且一个终止符结束. 显示出了 “cstack” 在 ASCII 码 在16进制 63 73 74 61 63 6b, 紧随其后的是的一个空字符(00). 剩下的33个字节是没有用的 下一个256字节存储的是邮箱,用的同样的方式. 这里我们能看见一堆随机码在空字符后面.这个很可能是在Row结构没有初始化的内存. 我们拷贝了整个256字节的邮件 buffer 到文件中, 包含了在字符串结束后的内容. 当我们分配该结构时，内存中的内容仍然存在. 但由于我们使用终止空字符，因此它对行为没有影响。 总结好的,我们已经持久化了, 但是现在他并不是最好的. 例如, 如果你 kill 进程没有使用 .exit 命令, 你将会丢失你的修改. 另外我们写了所有的 page 到磁盘中, 甚至自从我们从磁盘读取它们以来没有改变的页面。 下一步我们将介绍游标, 这会使实现 B 树更加简单. 完整的修改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298+#include &lt;errno.h&gt;+#include &lt;fcntl.h&gt; #include &lt;stdbool.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt;+#include &lt;unistd.h&gt; struct InputBuffer_t &#123; char* buffer;@@ -61,8 +64,15 @@ const uint32_t TABLE_MAX_PAGES = 100; const uint32_t ROWS_PER_PAGE = PAGE_SIZE / ROW_SIZE; const uint32_t TABLE_MAX_ROWS = ROWS_PER_PAGE * TABLE_MAX_PAGES; -struct Table_t &#123;+struct Pager_t &#123;+ int file_descriptor;+ uint32_t file_length; void* pages[TABLE_MAX_PAGES];+&#125;;+typedef struct Pager_t Pager;++struct Table_t &#123;+ Pager* pager; uint32_t num_rows; &#125;; typedef struct Table_t Table;@@ -83,21 +93,79 @@ void deserialize_row(void* source, Row* destination) &#123; memcpy(&amp;(destination-&gt;email), source + EMAIL_OFFSET, EMAIL_SIZE); &#125; +void* get_page(Pager* pager, uint32_t page_num) &#123;+ if (page_num &gt; TABLE_MAX_PAGES) &#123;+ printf(\"Tried to fetch page number out of bounds. %d &gt; %d\\n\", page_num,+ TABLE_MAX_PAGES);+ exit(EXIT_FAILURE);+ &#125;++ if (pager-&gt;pages[page_num] == NULL) &#123;+ // Cache miss. Allocate memory and load from file.+ void* page = malloc(PAGE_SIZE);+ uint32_t num_pages = pager-&gt;file_length / PAGE_SIZE;++ // We might save a partial page at the end of the file+ if (pager-&gt;file_length % PAGE_SIZE) &#123;+ num_pages += 1;+ &#125;++ if (page_num &lt;= num_pages) &#123;+ lseek(pager-&gt;file_descriptor, page_num * PAGE_SIZE, SEEK_SET);+ ssize_t bytes_read = read(pager-&gt;file_descriptor, page, PAGE_SIZE);+ if (bytes_read == -1) &#123;+ printf(\"Error reading file: %d\\n\", errno);+ exit(EXIT_FAILURE);+ &#125;+ &#125;++ pager-&gt;pages[page_num] = page;+ &#125;++ return pager-&gt;pages[page_num];+&#125;+ void* row_slot(Table* table, uint32_t row_num) &#123; uint32_t page_num = row_num / ROWS_PER_PAGE;- void* page = table-&gt;pages[page_num];- if (!page) &#123;- // Allocate memory only when we try to access page- page = table-&gt;pages[page_num] = malloc(PAGE_SIZE);- &#125;+ void* page = get_page(table-&gt;pager, page_num); uint32_t row_offset = row_num % ROWS_PER_PAGE; uint32_t byte_offset = row_offset * ROW_SIZE; return page + byte_offset; &#125; -Table* new_table() &#123;+Pager* pager_open(const char* filename) &#123;+ int fd = open(filename,+ O_RDWR | // Read/Write mode+ O_CREAT, // Create file if it does not exist+ S_IWUSR | // User write permission+ S_IRUSR // User read permission+ );++ if (fd == -1) &#123;+ printf(\"Unable to open file\\n\");+ exit(EXIT_FAILURE);+ &#125;++ off_t file_length = lseek(fd, 0, SEEK_END);++ Pager* pager = malloc(sizeof(Pager));+ pager-&gt;file_descriptor = fd;+ pager-&gt;file_length = file_length;++ for (uint32_t i = 0; i &lt; TABLE_MAX_PAGES; i++) &#123;+ pager-&gt;pages[i] = NULL;+ &#125;++ return pager;+&#125;++Table* db_open(const char* filename) &#123;+ Pager* pager = pager_open(filename);+ uint32_t num_rows = pager-&gt;file_length / ROW_SIZE;+ Table* table = malloc(sizeof(Table));- table-&gt;num_rows = 0;+ table-&gt;pager = pager;+ table-&gt;num_rows = num_rows; return table; &#125;@@ -127,8 +195,71 @@ void read_input(InputBuffer* input_buffer) &#123; input_buffer-&gt;buffer[bytes_read - 1] = 0; &#125; -MetaCommandResult do_meta_command(InputBuffer* input_buffer) &#123;+void pager_flush(Pager* pager, uint32_t page_num, uint32_t size) &#123;+ if (pager-&gt;pages[page_num] == NULL) &#123;+ printf(\"Tried to flush null page\\n\");+ exit(EXIT_FAILURE);+ &#125;++ off_t offset = lseek(pager-&gt;file_descriptor, page_num * PAGE_SIZE, SEEK_SET);++ if (offset == -1) &#123;+ printf(\"Error seeking: %d\\n\", errno);+ exit(EXIT_FAILURE);+ &#125;++ ssize_t bytes_written =+ write(pager-&gt;file_descriptor, pager-&gt;pages[page_num], size);++ if (bytes_written == -1) &#123;+ printf(\"Error writing: %d\\n\", errno);+ exit(EXIT_FAILURE);+ &#125;+&#125;++void db_close(Table* table) &#123;+ Pager* pager = table-&gt;pager;+ uint32_t num_full_pages = table-&gt;num_rows / ROWS_PER_PAGE;++ for (uint32_t i = 0; i &lt; num_full_pages; i++) &#123;+ if (pager-&gt;pages[i] == NULL) &#123;+ continue;+ &#125;+ pager_flush(pager, i, PAGE_SIZE);+ free(pager-&gt;pages[i]);+ pager-&gt;pages[i] = NULL;+ &#125;++ // There may be a partial page to write to the end of the file+ // This should not be needed after we switch to a B-tree+ uint32_t num_additional_rows = table-&gt;num_rows % ROWS_PER_PAGE;+ if (num_additional_rows &gt; 0) &#123;+ uint32_t page_num = num_full_pages;+ if (pager-&gt;pages[page_num] != NULL) &#123;+ pager_flush(pager, page_num, num_additional_rows * ROW_SIZE);+ free(pager-&gt;pages[page_num]);+ pager-&gt;pages[page_num] = NULL;+ &#125;+ &#125;++ int result = close(pager-&gt;file_descriptor);+ if (result == -1) &#123;+ printf(\"Error closing db file.\\n\");+ exit(EXIT_FAILURE);+ &#125;+ for (uint32_t i = 0; i &lt; TABLE_MAX_PAGES; i++) &#123;+ void* page = pager-&gt;pages[i];+ if (page) &#123;+ free(page);+ pager-&gt;pages[i] = NULL;+ &#125;+ &#125;+ free(pager);+&#125;++MetaCommandResult do_meta_command(InputBuffer* input_buffer, Table* table) &#123; if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123;+ db_close(table); exit(EXIT_SUCCESS); &#125; else &#123; return META_COMMAND_UNRECOGNIZED_COMMAND;@@ -210,14 +341,21 @@ ExecuteResult execute_statement(Statement* statement, Table* table) &#123; &#125; int main(int argc, char* argv[]) &#123;- Table* table = new_table();+ if (argc &lt; 2) &#123;+ printf(\"Must supply a database filename.\\n\");+ exit(EXIT_FAILURE);+ &#125;++ char* filename = argv[1];+ Table* table = db_open(filename);+ InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt(); read_input(input_buffer); if (input_buffer-&gt;buffer[0] == '.') &#123;- switch (do_meta_command(input_buffer)) &#123;+ switch (do_meta_command(input_buffer, table)) &#123; case (META_COMMAND_SUCCESS): continue; case (META_COMMAND_UNRECOGNIZED_COMMAND):diff --git a/spec/main_spec.rb b/spec/main_spec.rbindex 21561ce..bc0180a 100644--- a/spec/main_spec.rb+++ b/spec/main_spec.rb@@ -1,7 +1,11 @@ describe 'database' do+ before do+ `rm -rf test.db`+ end+ def run_script(commands) raw_output = nil- IO.popen(\"./db\", \"r+\") do |pipe|+ IO.popen(\"./db test.db\", \"r+\") do |pipe| commands.each do |command| pipe.puts command end@@ -28,6 +32,27 @@ describe 'database' do ]) end + it 'keeps data after closing connection' do+ result1 = run_script([+ \"insert 1 user1 person1@example.com\",+ \".exit\",+ ])+ expect(result1).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; \",+ ])++ result2 = run_script([+ \"select\",+ \".exit\",+ ])+ expect(result2).to match_array([+ \"db &gt; (1, user1, person1@example.com)\",+ \"Executed.\",+ \"db &gt; \",+ ])+ end+ it 'prints error message when table is full' do script = (1..1401).map do |i| \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"And the diff to our tests: describe 'database' do+ before do+ `rm -rf test.db`+ end+ def run_script(commands) raw_output = nil- IO.popen(\"./db\", \"r+\") do |pipe|+ IO.popen(\"./db test.db\", \"r+\") do |pipe| commands.each do |command| pipe.puts command end@@ -28,6 +32,27 @@ describe 'database' do ]) end + it 'keeps data after closing connection' do+ result1 = run_script([+ \"insert 1 user1 person1@example.com\",+ \".exit\",+ ])+ expect(result1).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; \",+ ])++ result2 = run_script([+ \"select\",+ \".exit\",+ ])+ expect(result2).to match_array([+ \"db &gt; (1, user1, person1@example.com)\",+ \"Executed.\",+ \"db &gt; \",+ ])+ end+ it 'prints error message when table is full' do script = (1..1401).map do |i| \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 4 - 第一个单元测试类(和一些 Bugs)","slug":"build_own_x/data_base/build_simple_database/Part4_our_first_tests","date":"2019-01-28T08:11:20.000Z","updated":"2019-01-28T14:34:23.561Z","comments":true,"path":"2019/01/28/build_own_x/data_base/build_simple_database/Part4_our_first_tests/","link":"","permalink":"http://yoursite.com/2019/01/28/build_own_x/data_base/build_simple_database/Part4_our_first_tests/","excerpt":"","text":"Part 4 - 第一个单元测试类(和一些 Bugs) 我们可以插入一些行数据到我们的数据库中并且打印它们, 现在让我们花点时间测试下我们的代码吧. 我将会使用 rspec 来进行测试, 因为对它们比较熟悉, 并且具有可读性. 我定义了一个简短的帮助函数向 db 程序发送一个命令集合, 然后为输出做短语. 123456789101112131415161718192021222324252627282930describe 'database' do def run_script(commands) raw_output = nil IO.popen(\"./db\", \"r+\") do |pipe| commands.each do |command| pipe.puts command end pipe.close_write # Read entire output raw_output = pipe.gets(nil) end raw_output.split(\"\\n\") end it 'inserts and retreives a row' do result = run_script([ \"insert 1 user1 person1@example.com\", \"select\", \".exit\", ]) expect(result).to match_array([ \"db &gt; Executed.\", \"db &gt; (1, user1, person1@example.com)\", \"Executed.\", \"db &gt; \", ]) endend 这个简单的测试可以帮助我们确定输入和输出对应的内容. 12345bundle exec rspec.Finished in 0.00871 seconds (files took 0.09506 seconds to load)1 example, 0 failures 现在将大量的数据插入数据库中变的可行了: 12345678it 'prints error message when table is full' do script = (1..1401).map do |i| \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\" end script &lt;&lt; \".exit\" result = run_script(script) expect(result[-2]).to eq('db &gt; Error: Table full.')end 再次跑测试用例.. 12345bundle exec rspec..Finished in 0.01553 seconds (files took 0.08156 seconds to load)2 examples, 0 failures 美滋滋, 它是能正常工作的! 我们的 db 现在可以存错1400条数据, 因为我们设置了最大页面数是100, 且一页有 14 条数据. 阅读到这里, 我意识到我们可能没有办法正常的处理文本数据, 我们可以从下面的例子中体现出来. 12345678910111213141516it 'allows inserting strings that are the maximum length' do long_username = \"a\"*32 long_email = \"a\"*255 script = [ \"insert 1 #&#123;long_username&#125; #&#123;long_email&#125;\", \"select\", \".exit\", ] result = run_script(script) expect(result).to match_array([ \"db &gt; Executed.\", \"db &gt; (1, #&#123;long_username&#125;, #&#123;long_email&#125;)\", \"Executed.\", \"db &gt; \", ])end 测试失败了! 12345678910Failures: 1) database allows inserting strings that are the maximum length Failure/Error: raw_output.split(\"\\n\") ArgumentError: invalid byte sequence in UTF-8 # ./spec/main_spec.rb:14:in `split' # ./spec/main_spec.rb:14:in `run_script' # ./spec/main_spec.rb:48:in `block (2 levels) in &lt;top (required)&gt;' 如果我们手动重试呢? 当我们尝试打印出行时，我们会看到有一些奇怪的字符 123456db &gt; insert 1 aaaaa... aaaaa...Executed.db &gt; select(1, aaaaa...aaa\\�, aaaaa...aaa\\�)Executed.db &gt; 这是咋回事呢? 如果你看一下我们对Row的定义，我们只为用户名分配32个字节，为电子邮件分配255个字节. 但是C字符串应该以空字符结尾，我们没有为其分配空间。解决方案是分配一个额外的字节: 123456789const uint32_t COLUMN_EMAIL_SIZE = 255; struct Row_t &#123; uint32_t id;- char username[COLUMN_USERNAME_SIZE];- char email[COLUMN_EMAIL_SIZE];+ char username[COLUMN_USERNAME_SIZE + 1];+ char email[COLUMN_EMAIL_SIZE + 1]; &#125;; typedef struct Row_t Row; 确定一下我们确实修复了它:12345bundle exec rspec...Finished in 0.0188 seconds (files took 0.08516 seconds to load)3 examples, 0 failures 我们应该不允许插入过长的用户名和邮件, spec 看起来就像这样: 123456789101112131415it 'prints error message if strings are too long' do long_username = \"a\"*33 long_email = \"a\"*256 script = [ \"insert 1 #&#123;long_username&#125; #&#123;long_email&#125;\", \"select\", \".exit\", ] result = run_script(script) expect(result).to match_array([ \"db &gt; String is too long.\", \"db &gt; Executed.\", \"db &gt; \", ])end 因此我们需要升级下我们的解析器, 我们当前用的是 scanf() 方法: 12345678910if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123; statement-&gt;type = STATEMENT_INSERT; int args_assigned = sscanf( input_buffer-&gt;buffer, \"insert %d %s %s\", &amp;(statement-&gt;row_to_insert.id), statement-&gt;row_to_insert.username, statement-&gt;row_to_insert.email); if (args_assigned &lt; 3) &#123; return PREPARE_SYNTAX_ERROR; &#125; return PREPARE_SUCCESS;&#125; 但是 scanf 存在一些缺点. 如果读取的字符串大于缓冲区, 它将导致缓冲区溢出问题, 并且开始写到不期望的地方. 我们想检查下每一个字符串的长度在将数据拷贝到行结构之前. 我们需要使用空格去划分它. 我将使用 strtok() 方法, 我想这应该不难理解. 12345678910111213141516171819202122232425262728293031323334353637383940+PrepareResult prepare_insert(InputBuffer* input_buffer, Statement* statement) &#123;+ statement-&gt;type = STATEMENT_INSERT;++ char* keyword = strtok(input_buffer-&gt;buffer, \" \");+ char* id_string = strtok(NULL, \" \");+ char* username = strtok(NULL, \" \");+ char* email = strtok(NULL, \" \");++ if (id_string == NULL || username == NULL || email == NULL) &#123;+ return PREPARE_SYNTAX_ERROR;+ &#125;++ int id = atoi(id_string);+ if (strlen(username) &gt; COLUMN_USERNAME_SIZE) &#123;+ return PREPARE_STRING_TOO_LONG;+ &#125;+ if (strlen(email) &gt; COLUMN_EMAIL_SIZE) &#123;+ return PREPARE_STRING_TOO_LONG;+ &#125;++ statement-&gt;row_to_insert.id = id;+ strcpy(statement-&gt;row_to_insert.username, username);+ strcpy(statement-&gt;row_to_insert.email, email);++ return PREPARE_SUCCESS;+&#125;+ PrepareResult prepare_statement(InputBuffer* input_buffer, Statement* statement) &#123; if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123;+ return prepare_insert(input_buffer, statement);- statement-&gt;type = STATEMENT_INSERT;- int args_assigned = sscanf(- input_buffer-&gt;buffer, \"insert %d %s %s\", &amp;(statement-&gt;row_to_insert.id),- statement-&gt;row_to_insert.username, statement-&gt;row_to_insert.email);- if (args_assigned &lt; 3) &#123;- return PREPARE_SYNTAX_ERROR;- &#125;- return PREPARE_SUCCESS; &#125; 在输入缓冲区上连续调用strtok会在到达分隔符（在我们的例子中为空格）时通过插入空字符将其分解为子字符串。它返回指向子字符串开头的指针。 我们可以在每个文本值上调用strlen()来查看它是否太长。 我们可以像处理任何其他错误代码一样处理错误： 123456enum PrepareResult_t &#123; PREPARE_SUCCESS,+ PREPARE_STRING_TOO_LONG, PREPARE_SYNTAX_ERROR, PREPARE_UNRECOGNIZED_STATEMENT &#125;; 123456789switch (prepare_statement(input_buffer, &amp;statement)) &#123; case (PREPARE_SUCCESS): break;+ case (PREPARE_STRING_TOO_LONG):+ printf(\"String is too long.\\n\");+ continue; case (PREPARE_SYNTAX_ERROR): printf(\"Syntax error. Could not parse statement.\\n\"); continue; 使我们的测试用例通过 12345bundle exec rspec....Finished in 0.02284 seconds (files took 0.116 seconds to load)4 examples, 0 failures 虽然,我们在这里了,但是我们还有一个错误需要处理: 12345678910111213it 'prints an error message if id is negative' do script = [ \"insert -1 cstack foo@bar.com\", \"select\", \".exit\", ] result = run_script(script) expect(result).to match_array([ \"db &gt; ID must be positive.\", \"db &gt; Executed.\", \"db &gt; \", ])end 1234567891011121314151617181920212223242526enum PrepareResult_t &#123; PREPARE_SUCCESS,+ PREPARE_NEGATIVE_ID, PREPARE_STRING_TOO_LONG, PREPARE_SYNTAX_ERROR, PREPARE_UNRECOGNIZED_STATEMENT@@ -148,9 +147,6 @@ PrepareResult prepare_insert(InputBuffer* input_buffer, Statement* statement) &#123; &#125; int id = atoi(id_string);+ if (id &lt; 0) &#123;+ return PREPARE_NEGATIVE_ID;+ &#125; if (strlen(username) &gt; COLUMN_USERNAME_SIZE) &#123; return PREPARE_STRING_TOO_LONG; &#125;@@ -230,9 +226,6 @@ int main(int argc, char* argv[]) &#123; switch (prepare_statement(input_buffer, &amp;statement)) &#123; case (PREPARE_SUCCESS): break;+ case (PREPARE_NEGATIVE_ID):+ printf(\"ID must be positive.\\n\");+ continue; case (PREPARE_STRING_TOO_LONG): printf(\"String is too long.\\n\"); continue; 好的,现在应该测试的差不多了, 下一步,将是一个非常重要的特性: 持久化! 我们将保存我们的数据到一个文件中并且将其读回到内存中. 代码完整的修改部分: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980enum PrepareResult_t &#123; PREPARE_SUCCESS,+ PREPARE_NEGATIVE_ID,+ PREPARE_STRING_TOO_LONG, PREPARE_SYNTAX_ERROR, PREPARE_UNRECOGNIZED_STATEMENT &#125;;@@ -33,8 +35,8 @@ const uint32_t COLUMN_USERNAME_SIZE = 32; const uint32_t COLUMN_EMAIL_SIZE = 255; struct Row_t &#123; uint32_t id;- char username[COLUMN_USERNAME_SIZE];- char email[COLUMN_EMAIL_SIZE];+ char username[COLUMN_USERNAME_SIZE + 1];+ char email[COLUMN_EMAIL_SIZE + 1]; &#125;; typedef struct Row_t Row; @@ -133,17 +135,40 @@ MetaCommandResult do_meta_command(InputBuffer* input_buffer) &#123; &#125; &#125; +PrepareResult prepare_insert(InputBuffer* input_buffer, Statement* statement) &#123;+ statement-&gt;type = STATEMENT_INSERT;++ char* keyword = strtok(input_buffer-&gt;buffer, \" \");+ char* id_string = strtok(NULL, \" \");+ char* username = strtok(NULL, \" \");+ char* email = strtok(NULL, \" \");++ if (id_string == NULL || username == NULL || email == NULL) &#123;+ return PREPARE_SYNTAX_ERROR;+ &#125;++ int id = atoi(id_string);+ if (id &lt; 0) &#123;+ return PREPARE_NEGATIVE_ID;+ &#125;+ if (strlen(username) &gt; COLUMN_USERNAME_SIZE) &#123;+ return PREPARE_STRING_TOO_LONG;+ &#125;+ if (strlen(email) &gt; COLUMN_EMAIL_SIZE) &#123;+ return PREPARE_STRING_TOO_LONG;+ &#125;++ statement-&gt;row_to_insert.id = id;+ strcpy(statement-&gt;row_to_insert.username, username);+ strcpy(statement-&gt;row_to_insert.email, email);++ return PREPARE_SUCCESS;+&#125;+ PrepareResult prepare_statement(InputBuffer* input_buffer, Statement* statement) &#123; if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123;- statement-&gt;type = STATEMENT_INSERT;- int args_assigned = sscanf(- input_buffer-&gt;buffer, \"insert %d %s %s\", &amp;(statement-&gt;row_to_insert.id),- statement-&gt;row_to_insert.username, statement-&gt;row_to_insert.email);- if (args_assigned &lt; 3) &#123;- return PREPARE_SYNTAX_ERROR;- &#125;- return PREPARE_SUCCESS;+ return prepare_insert(input_buffer, statement); &#125; if (strcmp(input_buffer-&gt;buffer, \"select\") == 0) &#123; statement-&gt;type = STATEMENT_SELECT;@@ -205,6 +230,12 @@ int main(int argc, char* argv[]) &#123; switch (prepare_statement(input_buffer, &amp;statement)) &#123; case (PREPARE_SUCCESS): break;+ case (PREPARE_NEGATIVE_ID):+ printf(\"ID must be positive.\\n\");+ continue;+ case (PREPARE_STRING_TOO_LONG):+ printf(\"String is too long.\\n\");+ continue; case (PREPARE_SYNTAX_ERROR): printf(\"Syntax error. Could not parse statement.\\n\"); continue; 我们添加的单元测试: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586+describe 'database' do+ def run_script(commands)+ raw_output = nil+ IO.popen(\"./db\", \"r+\") do |pipe|+ commands.each do |command|+ pipe.puts command+ end++ pipe.close_write++ # Read entire output+ raw_output = pipe.gets(nil)+ end+ raw_output.split(\"\\n\")+ end++ it 'inserts and retreives a row' do+ result = run_script([+ \"insert 1 user1 person1@example.com\",+ \"select\",+ \".exit\",+ ])+ expect(result).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; (1, user1, person1@example.com)\",+ \"Executed.\",+ \"db &gt; \",+ ])+ end++ it 'prints error message when table is full' do+ script = (1..1401).map do |i|+ \"insert #&#123;i&#125; user#&#123;i&#125; person#&#123;i&#125;@example.com\"+ end+ script &lt;&lt; \".exit\"+ result = run_script(script)+ expect(result[-2]).to eq('db &gt; Error: Table full.')+ end++ it 'allows inserting strings that are the maximum length' do+ long_username = \"a\"*32+ long_email = \"a\"*255+ script = [+ \"insert 1 #&#123;long_username&#125; #&#123;long_email&#125;\",+ \"select\",+ \".exit\",+ ]+ result = run_script(script)+ expect(result).to match_array([+ \"db &gt; Executed.\",+ \"db &gt; (1, #&#123;long_username&#125;, #&#123;long_email&#125;)\",+ \"Executed.\",+ \"db &gt; \",+ ])+ end++ it 'prints error message if strings are too long' do+ long_username = \"a\"*33+ long_email = \"a\"*256+ script = [+ \"insert 1 #&#123;long_username&#125; #&#123;long_email&#125;\",+ \"select\",+ \".exit\",+ ]+ result = run_script(script)+ expect(result).to match_array([+ \"db &gt; String is too long.\",+ \"db &gt; Executed.\",+ \"db &gt; \",+ ])+ end++ it 'prints an error message if id is negative' do+ script = [+ \"insert -1 cstack foo@bar.com\",+ \"select\",+ \".exit\",+ ]+ result = run_script(script)+ expect(result).to match_array([+ \"db &gt; ID must be positive.\",+ \"db &gt; Executed.\",+ \"db &gt; \",+ ])+ end+end","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Let's Build a Simple Database","slug":"build_own_x/data_base/build_simple_database/Readme_Index","date":"2019-01-26T08:11:20.000Z","updated":"2019-01-28T01:37:45.967Z","comments":true,"path":"2019/01/26/build_own_x/data_base/build_simple_database/Readme_Index/","link":"","permalink":"http://yoursite.com/2019/01/26/build_own_x/data_base/build_simple_database/Readme_Index/","excerpt":"","text":"Let’s Build a Simple Database原文: https://cstack.github.io/db_tutorial/ 从 C 重新开始写 Sqlite 数据库是如何工作的? 在内存和磁盘上, 数据保存的格式是啥? 什么时候会从内存中移动到硬盘上? 为什么每个表仅有一个主键呢? 事务回滚是如何工作的呢? 索引是如何格式化? FIXME(Jx) (How are indexes formatted?) 啥时候全表扫描会发生呢? 保存前的预准备格式是啥样的呢? FIXME(Jx) (What format is a prepared statement saved in?) 总而言之, 数据库是如何工作的呢? 为了理解这个, 我将会用 C 重新构建一个 Sqlite , 并且会记录其过程. 目录 Part 1 - 介绍和设置 REPL Part 2 - 世上最简单的 SQL 编译器和虚拟机 Part 3 - 一个在内存, 仅追加的 单表数据库 Part 4 - 第一个单元测试类(和一些Bugs) Part 5 - 持久化到硬盘 Part 6 - 游标的抽象化 Part 7 - 介绍 B 树 Part 8 - B 树叶子接口格式化 Part 9 - 二分查找和重复键 Part 10 - 拆分叶子节点 Part 11 - 递归搜索 B 树 Part 12 - 扫描多层级的 B 树 Part 13 - 拆分后更新父节点 “What I cannot create, I do not understand.” – Richard Feynman Sqlite 架构图 Sqlite 架构图: https://www.sqlite.org/arch.html","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 2 - 世上最简单的 SQL 编译器和虚拟机","slug":"build_own_x/data_base/build_simple_database/Part2_worlds_simplest_sql_compiler_and_VM","date":"2019-01-26T08:11:20.000Z","updated":"2019-01-26T13:39:40.637Z","comments":true,"path":"2019/01/26/build_own_x/data_base/build_simple_database/Part2_worlds_simplest_sql_compiler_and_VM/","link":"","permalink":"http://yoursite.com/2019/01/26/build_own_x/data_base/build_simple_database/Part2_worlds_simplest_sql_compiler_and_VM/","excerpt":"","text":"Part 2 - 世上最简单的 SQL 编译器和虚拟机sqlite 的前端是一个 SQL 编辑器, 解析一个字符串和输出一个内部的字节编码. 这个字节编码通过虚拟机执行它. SQLite Architecture (https://www.sqlite.org/arch.html) 将整件事情分解为两步主要有两个优点: 减少每一块的复杂度(例如: 虚拟机不用去考虑语法的错误) 允许编译常见错误,并且缓存字节码以提高效率. 顺着这个思路, 让我重构一下主函数, 并且让其支持两个新的关键词:12345678910111213141516171819202122232425262728293031323334 int main(int argc, char* argv[]) &#123; InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt(); read_input(input_buffer);- if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123;- exit(EXIT_SUCCESS);- &#125; else &#123;- printf(\"Unrecognized command '%s'.\\n\", input_buffer-&gt;buffer);+ if (input_buffer-&gt;buffer[0] == '.') &#123;+ switch (do_meta_command(input_buffer)) &#123;+ case (META_COMMAND_SUCCESS):+ continue;+ case (META_COMMAND_UNRECOGNIZED_COMMAND):+ printf(\"Unrecognized command '%s'\\n\", input_buffer-&gt;buffer);+ continue;+ &#125; &#125;++ Statement statement;+ switch (prepare_statement(input_buffer, &amp;statement)) &#123;+ case (PREPARE_SUCCESS):+ break;+ case (PREPARE_UNRECOGNIZED_STATEMENT):+ printf(\"Unrecognized keyword at start of '%s'.\\n\",+ input_buffer-&gt;buffer);+ continue;+ &#125;++ execute_statement(&amp;statement);+ printf(\"Executed.\\n\"); &#125; &#125; .exit 不是 SQL 命令,被称为 “元命令”. 他们开始于 . 号, 所有我们需要先检查它们, 并在分离函数中处理他们. 下一步,我们添加一步将输入的行转换成内部的 statement. 这是我们前端的 hacky 版本. 最后,我们将预处理好的 statement 传给 execute_statement 函数, 这个函数最终将会变成我们的虚拟机. 注意, 这个新的函数均返回 enums 来表示成功或者失败:12345678enum MetaCommandResult_t &#123; META_COMMAND_SUCCESS, META_COMMAND_UNRECOGNIZED_COMMAND&#125;;typedef enum MetaCommandResult_t MetaCommandResult;enum PrepareResult_t &#123; PREPARE_SUCCESS, PREPARE_UNRECOGNIZED_STATEMENT &#125;;typedef enum PrepareResult_t PrepareResult; do_meta_command 函数仅仅是一个包装了退出函数,为更多的命令留下空间. 1234567MetaCommandResult do_meta_command(InputBuffer* input_buffer) &#123; if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; exit(EXIT_SUCCESS); &#125; else &#123; return META_COMMAND_UNRECOGNIZED_COMMAND; &#125;&#125; 我们的prepared statement枚举 现在仅包含两个值, 它将来将会包含更多的参数在声明中. 1234567enum StatementType_t &#123; STATEMENT_INSERT, STATEMENT_SELECT &#125;;typedef enum StatementType_t StatementType;struct Statement_t &#123; StatementType type;&#125;;typedef struct Statement_t Statement; prepare_statement (我们的 SQL 编译器) 现在并不能理解 SQL, 他现在仅仅能理解两个单词. 12345678910111213PrepareResult prepare_statement(InputBuffer* input_buffer, Statement* statement) &#123; if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123; statement-&gt;type = STATEMENT_INSERT; return PREPARE_SUCCESS; &#125; if (strcmp(input_buffer-&gt;buffer, \"select\") == 0) &#123; statement-&gt;type = STATEMENT_SELECT; return PREPARE_SUCCESS; &#125; return PREPARE_UNRECOGNIZED_STATEMENT;&#125; 注意,我们现在使用 strncmp 以 insert 关键词来匹配 insert 其后将会跟随着要插入的数据(例如: insert 1 cstack foo@bar.com) 最后 execute_statement 函数现在仅仅是打印了一些东西. 12345678910void execute_statement(Statement* statement) &#123; switch (statement-&gt;type) &#123; case (STATEMENT_INSERT): printf(\"This is where we would do an insert.\\n\"); break; case (STATEMENT_SELECT): printf(\"This is where we would do a select.\\n\"); break; &#125;&#125; 注意这里将不会返回任何错误码,因为这里没有啥错误可能产生 随着代码的开发,我们可以发现两个新的单词了. 12345678910111213~ ./dbdb &gt; insert foo barThis is where we would do an insert.Executed.db &gt; delete fooUnrecognized keyword at start of 'delete foo'.db &gt; selectThis is where we would do a select.Executed.db &gt; .tablesUnrecognized command '.tables'db &gt; .exit~ 我们的数据库的架子正在形成… 如果能存储数据将会更加友好? 这是下一章节的内容, 我们将会实现插入和 select, 创建世界上最差的数据库存储, 下面是本章修改的代码对照: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@@ -10,6 +10,23 @@ struct InputBuffer_t &#123; &#125;; typedef struct InputBuffer_t InputBuffer; +enum MetaCommandResult_t &#123;+ META_COMMAND_SUCCESS,+ META_COMMAND_UNRECOGNIZED_COMMAND+&#125;;+typedef enum MetaCommandResult_t MetaCommandResult;++enum PrepareResult_t &#123; PREPARE_SUCCESS, PREPARE_UNRECOGNIZED_STATEMENT &#125;;+typedef enum PrepareResult_t PrepareResult;++enum StatementType_t &#123; STATEMENT_INSERT, STATEMENT_SELECT &#125;;+typedef enum StatementType_t StatementType;++struct Statement_t &#123;+ StatementType type;+&#125;;+typedef struct Statement_t Statement;+ InputBuffer* new_input_buffer() &#123; InputBuffer* input_buffer = malloc(sizeof(InputBuffer)); input_buffer-&gt;buffer = NULL;@@ -35,16 +52,66 @@ void read_input(InputBuffer* input_buffer) &#123; input_buffer-&gt;buffer[bytes_read - 1] = 0; &#125; +MetaCommandResult do_meta_command(InputBuffer* input_buffer) &#123;+ if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123;+ exit(EXIT_SUCCESS);+ &#125; else &#123;+ return META_COMMAND_UNRECOGNIZED_COMMAND;+ &#125;+&#125;++PrepareResult prepare_statement(InputBuffer* input_buffer,+ Statement* statement) &#123;+ if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123;+ statement-&gt;type = STATEMENT_INSERT;+ return PREPARE_SUCCESS;+ &#125;+ if (strcmp(input_buffer-&gt;buffer, \"select\") == 0) &#123;+ statement-&gt;type = STATEMENT_SELECT;+ return PREPARE_SUCCESS;+ &#125;++ return PREPARE_UNRECOGNIZED_STATEMENT;+&#125;++void execute_statement(Statement* statement) &#123;+ switch (statement-&gt;type) &#123;+ case (STATEMENT_INSERT):+ printf(\"This is where we would do an insert.\\n\");+ break;+ case (STATEMENT_SELECT):+ printf(\"This is where we would do a select.\\n\");+ break;+ &#125;+&#125;+ int main(int argc, char* argv[]) &#123; InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt(); read_input(input_buffer); - if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123;- exit(EXIT_SUCCESS);- &#125; else &#123;- printf(\"Unrecognized command '%s'.\\n\", input_buffer-&gt;buffer);+ if (input_buffer-&gt;buffer[0] == '.') &#123;+ switch (do_meta_command(input_buffer)) &#123;+ case (META_COMMAND_SUCCESS):+ continue;+ case (META_COMMAND_UNRECOGNIZED_COMMAND):+ printf(\"Unrecognized command '%s'\\n\", input_buffer-&gt;buffer);+ continue;+ &#125; &#125;++ Statement statement;+ switch (prepare_statement(input_buffer, &amp;statement)) &#123;+ case (PREPARE_SUCCESS):+ break;+ case (PREPARE_UNRECOGNIZED_STATEMENT):+ printf(\"Unrecognized keyword at start of '%s'.\\n\",+ input_buffer-&gt;buffer);+ continue;+ &#125;++ execute_statement(&amp;statement);+ printf(\"Executed.\\n\"); &#125; &#125;","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 3 - 一个在内存, 仅追加的 单表数据库","slug":"build_own_x/data_base/build_simple_database/Part3_an_in-memory_append-only_single-table_database","date":"2019-01-26T08:11:20.000Z","updated":"2019-01-27T05:45:15.316Z","comments":true,"path":"2019/01/26/build_own_x/data_base/build_simple_database/Part3_an_in-memory_append-only_single-table_database/","link":"","permalink":"http://yoursite.com/2019/01/26/build_own_x/data_base/build_simple_database/Part3_an_in-memory_append-only_single-table_database/","excerpt":"","text":"Part 3 - 一个在内存, 仅追加的 单表数据库我们将继续为我们的数据库添加一些小功能, 通过在数据库中添加一些限制. 添加的功能如下: 支持两个操作: 插入新的一行数据 and 打印所有行数据 让其暂住在内存中(并没有存储到硬盘中) 支持单个硬编码表 我们的硬编码表主要用于存储用户信息, 看起来像这样 column type id integer username varchar(32) email varchar(255) 这是一个简单的 schema, 但是它支持多数据类型和多类型大小的文本类型. 插入语法现在看起来像这样:1insert 1 cstack foo@bar.com 这意味着我们需要去更新 prepare_statement 方法去解析参数. 1234567891011if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123; statement-&gt;type = STATEMENT_INSERT;+ int args_assigned = sscanf(+ input_buffer-&gt;buffer, \"insert %d %s %s\", &amp;(statement-&gt;row_to_insert.id),+ statement-&gt;row_to_insert.username, statement-&gt;row_to_insert.email);+ if (args_assigned &lt; 3) &#123;+ return PREPARE_SYNTAX_ERROR;+ &#125; return PREPARE_SUCCESS; &#125; if (strcmp(input_buffer-&gt;buffer, \"select\") == 0) &#123; 我们声明一个新的 Row 结构放在 statement 下, 并将传入的参数放在其中. 1234567891011121314+const uint32_t COLUMN_USERNAME_SIZE = 32;+const uint32_t COLUMN_EMAIL_SIZE = 255;+struct Row_t &#123;+ uint32_t id;+ char username[COLUMN_USERNAME_SIZE];+ char email[COLUMN_EMAIL_SIZE];+&#125;;+typedef struct Row_t Row;+ struct Statement_t &#123; StatementType type;+ Row row_to_insert; // only used by insert statement &#125;; typedef struct Statement_t Statement; 现在我们需要将传入的数据复制到 Row 中, 以此来代替表. Sqlite 使用 B 树来快速的查询,插入和删除. 我们将从简单的事情开始, 像 B 树结构是将数据行进行分组到页中, 但是在这里我们将用数组来代替 B 树. 这是我的计划: 将行存在在内存块中, 将其称为页面 每一个页面都用行数据填充 每一行都将序列化为紧凑形式 页面仅根据需要分配 保持固定大小的页面指针数组 第一, 我们将定义一个紧凑的行表示. 123456789+#define size_of_attribute(Struct, Attribute) sizeof(((Struct*)0)-&gt;Attribute)++const uint32_t ID_SIZE = size_of_attribute(Row, id);+const uint32_t USERNAME_SIZE = size_of_attribute(Row, username);+const uint32_t EMAIL_SIZE = size_of_attribute(Row, email);+const uint32_t ID_OFFSET = 0;+const uint32_t USERNAME_OFFSET = ID_OFFSET + ID_SIZE;+const uint32_t EMAIL_OFFSET = USERNAME_OFFSET + USERNAME_SIZE;+const uint32_t ROW_SIZE = ID_SIZE + USERNAME_SIZE + EMAIL_SIZE; 这也意味着我们序列化行数据将会看起来像下面这样: column size (bytes) offset id 4 0 username 32 4 email 255 36 total 291 我们也需要使用代码将行数据转换成紧凑的形式 1234567891011+void serialize_row(Row* source, void* destination) &#123;+ memcpy(destination + ID_OFFSET, &amp;(source-&gt;id), ID_SIZE);+ memcpy(destination + USERNAME_OFFSET, &amp;(source-&gt;username), USERNAME_SIZE);+ memcpy(destination + EMAIL_OFFSET, &amp;(source-&gt;email), EMAIL_SIZE);+&#125;++void deserialize_row(void* source, Row* destination) &#123;+ memcpy(&amp;(destination-&gt;id), source + ID_OFFSET, ID_SIZE);+ memcpy(&amp;(destination-&gt;username), source + USERNAME_OFFSET, USERNAME_SIZE);+ memcpy(&amp;(destination-&gt;email), source + EMAIL_OFFSET, EMAIL_SIZE);+&#125; 下一步, 一个表结构记录着到 page 的指针和有多少条记录的 12345678910+const uint32_t PAGE_SIZE = 4096;+const uint32_t TABLE_MAX_PAGES = 100;+const uint32_t ROWS_PER_PAGE = PAGE_SIZE / ROW_SIZE;+const uint32_t TABLE_MAX_ROWS = ROWS_PER_PAGE * TABLE_MAX_PAGES;++struct Table_t &#123;+ void* pages[TABLE_MAX_PAGES];+ uint32_t num_rows;+&#125;;+typedef struct Table_t Table; 我定义了一页的大小为4千字节, 因为这个和虚拟内存系统框架的页大小刚好一样. 这也意味在数据库中的一页对应着操作系统中的一页. 操作系统也是整页数据的进行着操作. 我们随意的限制下页数为100页. 当我们使用数的结构的时候, 我们数据库最大的限制将会是文件的最大限制.(虽然我们依旧会去限制有多少页的数据驻留在内存中.) 行不应该超过页的限制, 因为页面之间可能不会彼此相邻, 这样会使得读写更加方便. 讲到这里, 我们将讲下如何计算特定的内存的位置. 1234567891011+void* row_slot(Table* table, uint32_t row_num) &#123;+ uint32_t page_num = row_num / ROWS_PER_PAGE;+ void* page = table-&gt;pages[page_num];+ if (!page) &#123;+ // Allocate memory only when we try to access page+ page = table-&gt;pages[page_num] = malloc(PAGE_SIZE);+ &#125;+ uint32_t row_offset = row_num % ROWS_PER_PAGE;+ uint32_t byte_offset = row_offset * ROW_SIZE;+ return page + byte_offset;+&#125; 现在, 我们可以让 execute_statement 方法可以从 table 结构中读写 1234567891011121314151617181920212223242526272829303132333435-void execute_statement(Statement* statement) &#123;+ExecuteResult execute_insert(Statement* statement, Table* table) &#123;+ if (table-&gt;num_rows &gt;= TABLE_MAX_ROWS) &#123;+ return EXECUTE_TABLE_FULL;+ &#125;++ Row* row_to_insert = &amp;(statement-&gt;row_to_insert);++ serialize_row(row_to_insert, row_slot(table, table-&gt;num_rows));+ table-&gt;num_rows += 1;++ return EXECUTE_SUCCESS;+&#125;++ExecuteResult execute_select(Statement* statement, Table* table) &#123;+ Row row;+ for (uint32_t i = 0; i &lt; table-&gt;num_rows; i++) &#123;+ deserialize_row(row_slot(table, i), &amp;row);+ print_row(&amp;row);+ &#125;+ return EXECUTE_SUCCESS;+&#125;++ExecuteResult execute_statement(Statement* statement, Table* table) &#123; switch (statement-&gt;type) &#123; case (STATEMENT_INSERT):- printf(\"This is where we would do an insert.\\n\");- break;+ return execute_insert(statement, table); case (STATEMENT_SELECT):- printf(\"This is where we would do a select.\\n\");- break;+ return execute_select(statement, table); &#125; &#125; 最后, 我们需要初始化table 并且处理一些错误的情况. 123456+ Table* new_table() &#123;+ Table* table = malloc(sizeof(Table));+ table-&gt;num_rows = 0;++ return table;+&#125; 123456789101112131415161718192021222324252627282930int main(int argc, char* argv[]) &#123;+ Table* table = new_table(); InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt();@@ -105,13 +203,22 @@ int main(int argc, char* argv[]) &#123; switch (prepare_statement(input_buffer, &amp;statement)) &#123; case (PREPARE_SUCCESS): break;+ case (PREPARE_SYNTAX_ERROR):+ printf(\"Syntax error. Could not parse statement.\\n\");+ continue; case (PREPARE_UNRECOGNIZED_STATEMENT): printf(\"Unrecognized keyword at start of '%s'.\\n\", input_buffer-&gt;buffer); continue; &#125;- execute_statement(&amp;statement);- printf(\"Executed.\\n\");+ switch (execute_statement(&amp;statement, table)) &#123;+ case (EXECUTE_SUCCESS):+ printf(\"Executed.\\n\");+ break;+ case (EXECUTE_TABLE_FULL):+ printf(\"Error: Table full.\\n\");+ break;+ &#125; &#125; &#125; 随着这些的修改,我们就能将数据保存到我们的数据库中了 12345678910111213~ ./dbdb &gt; insert 1 cstack foo@bar.comExecuted.db &gt; insert 2 bob bob@example.comExecuted.db &gt; select(1, cstack, foo@bar.com)(2, bob, bob@example.com)Executed.db &gt; insert foo bar 1Syntax error. Could not parse statement.db &gt; .exit~ 现在,我们可以写一些单元测试了, 原因有下面两点: 我们将大幅的改变数据存储到我们的 table中, 并回归它们. 还存在一些边缘情况我们还没有手动测试(如: 填满全表) 我们将在下一节中完善这些问题, 现在, 让我们看看整体的修改吧: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179typedef struct InputBuffer_t InputBuffer; +enum ExecuteResult_t &#123; EXECUTE_SUCCESS, EXECUTE_TABLE_FULL &#125;;+typedef enum ExecuteResult_t ExecuteResult;+ enum MetaCommandResult_t &#123; META_COMMAND_SUCCESS, META_COMMAND_UNRECOGNIZED_COMMAND &#125;; typedef enum MetaCommandResult_t MetaCommandResult; -enum PrepareResult_t &#123; PREPARE_SUCCESS, PREPARE_UNRECOGNIZED_STATEMENT &#125;;+enum PrepareResult_t &#123;+ PREPARE_SUCCESS,+ PREPARE_SYNTAX_ERROR,+ PREPARE_UNRECOGNIZED_STATEMENT+&#125;; typedef enum PrepareResult_t PrepareResult; enum StatementType_t &#123; STATEMENT_INSERT, STATEMENT_SELECT &#125;; typedef enum StatementType_t StatementType; +const uint32_t COLUMN_USERNAME_SIZE = 32;+const uint32_t COLUMN_EMAIL_SIZE = 255;+struct Row_t &#123;+ uint32_t id;+ char username[COLUMN_USERNAME_SIZE];+ char email[COLUMN_EMAIL_SIZE];+&#125;;+typedef struct Row_t Row;+ struct Statement_t &#123; StatementType type;+ Row row_to_insert; // only used by insert statement &#125;; typedef struct Statement_t Statement; +#define size_of_attribute(Struct, Attribute) sizeof(((Struct*)0)-&gt;Attribute)++const uint32_t ID_SIZE = size_of_attribute(Row, id);+const uint32_t USERNAME_SIZE = size_of_attribute(Row, username);+const uint32_t EMAIL_SIZE = size_of_attribute(Row, email);+const uint32_t ID_OFFSET = 0;+const uint32_t USERNAME_OFFSET = ID_OFFSET + ID_SIZE;+const uint32_t EMAIL_OFFSET = USERNAME_OFFSET + USERNAME_SIZE;+const uint32_t ROW_SIZE = ID_SIZE + USERNAME_SIZE + EMAIL_SIZE;++const uint32_t PAGE_SIZE = 4096;+const uint32_t TABLE_MAX_PAGES = 100;+const uint32_t ROWS_PER_PAGE = PAGE_SIZE / ROW_SIZE;+const uint32_t TABLE_MAX_ROWS = ROWS_PER_PAGE * TABLE_MAX_PAGES;++struct Table_t &#123;+ void* pages[TABLE_MAX_PAGES];+ uint32_t num_rows;+&#125;;+typedef struct Table_t Table;++void print_row(Row* row) &#123;+ printf(\"(%d, %s, %s)\\n\", row-&gt;id, row-&gt;username, row-&gt;email);+&#125;++void serialize_row(Row* source, void* destination) &#123;+ memcpy(destination + ID_OFFSET, &amp;(source-&gt;id), ID_SIZE);+ memcpy(destination + USERNAME_OFFSET, &amp;(source-&gt;username), USERNAME_SIZE);+ memcpy(destination + EMAIL_OFFSET, &amp;(source-&gt;email), EMAIL_SIZE);+&#125;++void deserialize_row(void* source, Row* destination) &#123;+ memcpy(&amp;(destination-&gt;id), source + ID_OFFSET, ID_SIZE);+ memcpy(&amp;(destination-&gt;username), source + USERNAME_OFFSET, USERNAME_SIZE);+ memcpy(&amp;(destination-&gt;email), source + EMAIL_OFFSET, EMAIL_SIZE);+&#125;++void* row_slot(Table* table, uint32_t row_num) &#123;+ uint32_t page_num = row_num / ROWS_PER_PAGE;+ void* page = table-&gt;pages[page_num];+ if (!page) &#123;+ // Allocate memory only when we try to access page+ page = table-&gt;pages[page_num] = malloc(PAGE_SIZE);+ &#125;+ uint32_t row_offset = row_num % ROWS_PER_PAGE;+ uint32_t byte_offset = row_offset * ROW_SIZE;+ return page + byte_offset;+&#125;++Table* new_table() &#123;+ Table* table = malloc(sizeof(Table));+ table-&gt;num_rows = 0;++ return table;+&#125;+ InputBuffer* new_input_buffer() &#123; InputBuffer* input_buffer = malloc(sizeof(InputBuffer)); input_buffer-&gt;buffer = NULL;@@ -64,6 +137,12 @@ PrepareResult prepare_statement(InputBuffer* input_buffer, Statement* statement) &#123; if (strncmp(input_buffer-&gt;buffer, \"insert\", 6) == 0) &#123; statement-&gt;type = STATEMENT_INSERT;+ int args_assigned = sscanf(+ input_buffer-&gt;buffer, \"insert %d %s %s\", &amp;(statement-&gt;row_to_insert.id),+ statement-&gt;row_to_insert.username, statement-&gt;row_to_insert.email);+ if (args_assigned &lt; 3) &#123;+ return PREPARE_SYNTAX_ERROR;+ &#125; return PREPARE_SUCCESS; &#125; if (strcmp(input_buffer-&gt;buffer, \"select\") == 0) &#123;@@ -74,18 +153,39 @@ PrepareResult prepare_statement(InputBuffer* input_buffer, return PREPARE_UNRECOGNIZED_STATEMENT; &#125; -void execute_statement(Statement* statement) &#123;+ExecuteResult execute_insert(Statement* statement, Table* table) &#123;+ if (table-&gt;num_rows &gt;= TABLE_MAX_ROWS) &#123;+ return EXECUTE_TABLE_FULL;+ &#125;++ Row* row_to_insert = &amp;(statement-&gt;row_to_insert);++ serialize_row(row_to_insert, row_slot(table, table-&gt;num_rows));+ table-&gt;num_rows += 1;++ return EXECUTE_SUCCESS;+&#125;++ExecuteResult execute_select(Statement* statement, Table* table) &#123;+ Row row;+ for (uint32_t i = 0; i &lt; table-&gt;num_rows; i++) &#123;+ deserialize_row(row_slot(table, i), &amp;row);+ print_row(&amp;row);+ &#125;+ return EXECUTE_SUCCESS;+&#125;++ExecuteResult execute_statement(Statement* statement, Table* table) &#123; switch (statement-&gt;type) &#123; case (STATEMENT_INSERT):- printf(\"This is where we would do an insert.\\n\");- break;+ return execute_insert(statement, table); case (STATEMENT_SELECT):- printf(\"This is where we would do a select.\\n\");- break;+ return execute_select(statement, table); &#125; &#125; int main(int argc, char* argv[]) &#123;+ Table* table = new_table(); InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt();@@ -105,13 +205,22 @@ int main(int argc, char* argv[]) &#123; switch (prepare_statement(input_buffer, &amp;statement)) &#123; case (PREPARE_SUCCESS): break;+ case (PREPARE_SYNTAX_ERROR):+ printf(\"Syntax error. Could not parse statement.\\n\");+ continue; case (PREPARE_UNRECOGNIZED_STATEMENT): printf(\"Unrecognized keyword at start of '%s'.\\n\", input_buffer-&gt;buffer); continue; &#125; - execute_statement(&amp;statement);- printf(\"Executed.\\n\");+ switch (execute_statement(&amp;statement, table)) &#123;+ case (EXECUTE_SUCCESS):+ printf(\"Executed.\\n\");+ break;+ case (EXECUTE_TABLE_FULL):+ printf(\"Error: Table full.\\n\");+ break;+ &#125; &#125; &#125;","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Part 1 - 介绍和设置 REPL","slug":"build_own_x/data_base/build_simple_database/Part1_Introduction_and_setting_up_the_REPL","date":"2019-01-26T08:11:20.000Z","updated":"2019-01-26T09:48:05.249Z","comments":true,"path":"2019/01/26/build_own_x/data_base/build_simple_database/Part1_Introduction_and_setting_up_the_REPL/","link":"","permalink":"http://yoursite.com/2019/01/26/build_own_x/data_base/build_simple_database/Part1_Introduction_and_setting_up_the_REPL/","excerpt":"","text":"Part 1 - 介绍和设置 REPL 下面涉及一些专业术语,不做具体翻译,第一次出现时可能会解释下. 作为一个 web 开发者, 在工作中每天都会使用到关系型数据库,但是它对于我就像是一个黑箱子一样. 我存在好多问题: 在内存和磁盘上, 数据保存的格式是啥? 什么时候会从内存中移动到硬盘上? 为什么每个表仅有一个主键呢? 事务回滚是如何工作的呢? 索引是如何格式化? FIXME(Jx) (How are indexes formatted?) 啥时候全表扫描会发生呢? 保存前的预准备格式是啥样的呢? FIXME(Jx) (What format is a prepared statement saved in?) 换而言之,它是如何工作的呢? 为了弄清这些事情,我从头写了一个数据库. 它是已 sqlite 为原型, 因为sqlite 的设计相对于 mysql 和 PostgreSQL 简单不少. 所以能够更好的理解它, 整个数据存储在单个文件中. SqliteSqlite 官网有许多内部设计文档 , 这里拷贝一份 Sqlite 数据库系统的设计和实现文档 sqlite architecture (https://www.sqlite.org/zipvfs/doc/trunk/www/howitworks.wiki) 一个查询是通过一条长链的组件来取回或者修改数据. 前端组件的组成: tokenizer (标记生成器) parser (解析器) code generator (代码生成器) 给前端输入一个 SQL 查询, 输出的是 Sqlite 虚拟机的字节码(本质上是一个可以在数据库上运行的编译程序) 后端组件的组成: virtual machine B-tree pager os interface virtual machine: 虚拟机接收前端传过来的字节码, 它能够操作一个或者多个表或者索引, 所有的这些都是存储在一个数据结构中, is B 树. VM 其本质其实是一个字节指令, 一个大的 switch 语句. B-tree: 每个 B 树都是有许多个节点组成的, 每个节点是一个页. B树可以通过向 pager 发送指令从硬盘中取回一页 或者是将数据保存回硬盘. pager: 接收指令读取或者写入一页数据. 它的主要责任是在适当的时候读或写数据库文件. 同时会在内存中保存一份最近读取的页, 并且确定在什么时候需要就这页数据回写到硬盘. os interface: 根据操作系统的不同会有很大的不同, 在这份教程中, 不会去支持多操作系统. 千里之行始于足下, so 让我们从第一步开始吧: the REPL 制作一个简单的 REPLSqlite 开始于 read-execute-print(读取-执行-打印) 的循环, 从命令行开始吧:12345678910~ sqlite3SQLite version 3.16.0 2016-11-04 19:09:39Enter \".help\" for usage hints.Connected to a transient in-memory database.Use \".open FILENAME\" to reopen on a persistent database.sqlite&gt; create table users (id int, username varchar(255), email varchar(255));sqlite&gt; .tablesuserssqlite&gt; .exit~ 要做到这一点我们需要在主程序中用一个无限循环打印提示, 获取一行输入, 然后处理这行输入. 12345678910111213int main(int argc, char* argv[]) &#123; InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt(); read_input(input_buffer); if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; exit(EXIT_SUCCESS); &#125; else &#123; printf(\"Unrecognized command '%s'.\\n\", input_buffer-&gt;buffer); &#125; &#125;&#125; 我们将定义一个 InputBuffer 使用一个简单的包装器, 需要存储 getline() 的信息. 123456789101112131415struct InputBuffer_t &#123; char* buffer; size_t buffer_length; ssize_t input_length;&#125;;typedef struct InputBuffer_t InputBuffer;InputBuffer* new_input_buffer() &#123; InputBuffer* input_buffer = malloc(sizeof(InputBuffer)); input_buffer-&gt;buffer = NULL; input_buffer-&gt;buffer_length = 0; input_buffer-&gt;input_length = 0; return input_buffer;&#125; 下一步打印提示, 在每一行输入之前都需要打印它 1void print_prompt() &#123; printf(\"db &gt; \"); &#125; 为了读取一行输入,需要使用到getline(): 1ssize_t getline(char **lineptr, size_t *n, FILE *stream); buffer 开始的时候是 null 的, 所以在 getline 分配足够的内存来保存输入的内容. 12345678910111213void read_input(InputBuffer* input_buffer) &#123; ssize_t bytes_read = getline(&amp;(input_buffer-&gt;buffer), &amp;(input_buffer-&gt;buffer_length), stdin); if (bytes_read &lt;= 0) &#123; printf(\"Error reading input\\n\"); exit(EXIT_FAILURE); &#125; // Ignore trailing newline(忽略换行符) input_buffer-&gt;input_length = bytes_read - 1; input_buffer-&gt;buffer[bytes_read - 1] = 0;&#125; 最后,我们将执行命令, 在这仅有一个可解析的命令 .exit , 输入其它的内容都会继续循环. 12345if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; exit(EXIT_SUCCESS);&#125; else &#123; printf(\"Unrecognized command '%s'.\\n\", input_buffer-&gt;buffer);&#125; 编译运行下吧~12345~ ./dbdb &gt; .tablesUnrecognized command '.tables'.db &gt; .exit~ 完整实例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;stdbool.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;struct InputBuffer_t &#123; char* buffer; size_t buffer_length; ssize_t input_length;&#125;;typedef struct InputBuffer_t InputBuffer;InputBuffer* new_input_buffer() &#123; InputBuffer* input_buffer = malloc(sizeof(InputBuffer)); input_buffer-&gt;buffer = NULL; input_buffer-&gt;buffer_length = 0; input_buffer-&gt;input_length = 0; return input_buffer;&#125;void print_prompt() &#123; printf(\"db &gt; \"); &#125;void read_input(InputBuffer* input_buffer) &#123; ssize_t bytes_read = getline(&amp;(input_buffer-&gt;buffer), &amp;(input_buffer-&gt;buffer_length), stdin); if (bytes_read &lt;= 0) &#123; printf(\"Error reading input\\n\"); exit(EXIT_FAILURE); &#125; // Ignore trailing newline input_buffer-&gt;input_length = bytes_read - 1; input_buffer-&gt;buffer[bytes_read - 1] = 0;&#125;int main(int argc, char* argv[]) &#123; InputBuffer* input_buffer = new_input_buffer(); while (true) &#123; print_prompt(); read_input(input_buffer); if (strcmp(input_buffer-&gt;buffer, \".exit\") == 0) &#123; exit(EXIT_SUCCESS); &#125; else &#123; printf(\"Unrecognized command '%s'.\\n\", input_buffer-&gt;buffer); &#125; &#125;&#125;","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"","slug":"build_own_x/data_base/build_simple_database_task","date":"2019-01-26T07:23:30.094Z","updated":"2019-01-26T13:24:26.646Z","comments":true,"path":"2019/01/26/build_own_x/data_base/build_simple_database_task/","link":"","permalink":"http://yoursite.com/2019/01/26/build_own_x/data_base/build_simple_database_task/","excerpt":"","text":"Taskone weak one Part 1. 翻译原文 Part 0 - Index readme Part 1 - Introduction and Setting up the REPL Part 2 - World’s Simplest SQL Compiler and Virtual Machine Part 3 - An In-Memory, Append-Only, Single-Table Database Part 4 - Our First Tests (and Bugs) Part 5 - Persistence to Disk Part 6 - The Cursor Abstraction Part 7 - Introduction to the B-Tree Part 8 - B-Tree Leaf Node Format Part 9 - Binary Search and Duplicate Keys Part 10 - Splitting a Leaf Node Part 11 - Recursively Searching the B-Tree Part 12 - Scanning a Multi-Level B-Tree Part 13 - Updating Parent Node After a Split 2. 基础总结 Part 1 - Introduction and Setting up the REPL Part 2 - World’s Simplest SQL Compiler and Virtual Machine Part 3 - An In-Memory, Append-Only, Single-Table Database Part 4 - Our First Tests (and Bugs) Part 5 - Persistence to Disk Part 6 - The Cursor Abstraction Part 7 - Introduction to the B-Tree Part 8 - B-Tree Leaf Node Format Part 9 - Binary Search and Duplicate Keys Part 10 - Splitting a Leaf Node Part 11 - Recursively Searching the B-Tree Part 12 - Scanning a Multi-Level B-Tree Part 13 - Updating Parent Node After a Split 3. follow it write a simple DB Part 1 - Introduction and Setting up the REPL Part 2 - World’s Simplest SQL Compiler and Virtual Machine Part 3 - An In-Memory, Append-Only, Single-Table Database Part 4 - Our First Tests (and Bugs) Part 5 - Persistence to Disk Part 6 - The Cursor Abstraction Part 7 - Introduction to the B-Tree Part 8 - B-Tree Leaf Node Format Part 9 - Binary Search and Duplicate Keys Part 10 - Splitting a Leaf Node Part 11 - Recursively Searching the B-Tree Part 12 - Scanning a Multi-Level B-Tree Part 13 - Updating Parent Node After a Split","categories":[],"tags":[]},{"title":"关于 Raft 的 think","slug":"alg/raft/raft_think","date":"2018-12-10T11:54:15.000Z","updated":"2018-12-10T15:12:13.451Z","comments":true,"path":"2018/12/10/alg/raft/raft_think/","link":"","permalink":"http://yoursite.com/2018/12/10/alg/raft/raft_think/","excerpt":"","text":"日志复制问题由 leader 发送日志给 follower 心跳和日志拷贝是在一起的. TK: 日志复制的二段提交问题???? 日志复制是二段提交的: 发送日志给各个 follower, 超过一半的 follower 接收成功了, 就发起一个 commit 提交. 如果leader的任期到期后会自动转换成 follower 等待下次选举的开始. 应该做个时序图??","categories":[{"name":"alg","slug":"alg","permalink":"http://yoursite.com/categories/alg/"}],"tags":[{"name":"raft think","slug":"raft-think","permalink":"http://yoursite.com/tags/raft-think/"}]},{"title":"","slug":"alg/raft/ReadRaft","date":"2018-12-09T14:31:08.000Z","updated":"2018-12-22T09:08:57.877Z","comments":true,"path":"2018/12/09/alg/raft/ReadRaft/","link":"","permalink":"http://yoursite.com/2018/12/09/alg/raft/ReadRaft/","excerpt":"","text":"参考: https://github.com/shishujuan/mit6.824-2017-raft.git raft.go @Make 初始化 rf 123state=Follower // 初始化成 Folloerrf.heartbeatInterval = time.Duration(HeartbeatInterval) * time.Millisecond // 50 ms 启动 bot 123456789101112131415161718192021222324252627electionTimeout := getRandomElectionTimeout() // 范围 &#123;300 + [0,100)&#125;msswitch state &#123; case Follower: select &#123; case &lt;-rf.appendEntryCh: // 不用去处理接收的日志吗? case &lt;-rf.grantVoteCh: // ?? case &lt;-time.After(electionTimeout): // 选举超时, Follower -&gt; Candidate rf.mu.Lock() rf.convertToCandidate() rf.mu.Unlock() &#125; case Candidate: go rf.leaderElection() // 1. 发起选举 select &#123; case &lt;-rf.appendEntryCh: case &lt;-rf.grantVoteCh: case &lt;-rf.leaderCh: case &lt;-time.After(electionTimeout): rf.mu.Lock() rf.convertToCandidate() // 选举超时, 重新开始选举 rf.mu.Unlock() &#125; case Leader: rf.startAppendEntries() // 开始去追加日志 time.Sleep(rf.heartbeatInterval) // 心跳间隙&#125;","categories":[{"name":"alg","slug":"alg","permalink":"http://yoursite.com/categories/alg/"}],"tags":[{"name":"raft learn","slug":"raft-learn","permalink":"http://yoursite.com/tags/raft-learn/"}]},{"title":"搭建 shadowsocks 服务器","slug":"devops/shadowsocks_server","date":"2018-12-07T07:28:31.000Z","updated":"2019-07-03T04:51:50.471Z","comments":true,"path":"2018/12/07/devops/shadowsocks_server/","link":"","permalink":"http://yoursite.com/2018/12/07/devops/shadowsocks_server/","excerpt":"","text":"install12apt-get install python-pippip install shadowsocks start service1ssserver -p 443 -k password -m rc4-md5 如果要后台运行： 1sudo ssserver -p 443 -k password -m rc4-md5 --user nobody -d start 如果要停止： 1sudo ssserver -d stop 如果要检查日志： 1sudo less /var/log/shadowsocks.log 启动示例1ssserver -p 8837 -k passwd --user nobody -d start","categories":[{"name":"devops","slug":"devops","permalink":"http://yoursite.com/categories/devops/"}],"tags":[{"name":"shadowsocks 服务器","slug":"shadowsocks-服务器","permalink":"http://yoursite.com/tags/shadowsocks-服务器/"}]},{"title":"Learn flutter","slug":"frontend/flutter/flutter_learn_plan","date":"2018-12-06T11:41:59.000Z","updated":"2018-12-06T11:58:37.134Z","comments":true,"path":"2018/12/06/frontend/flutter/flutter_learn_plan/","link":"","permalink":"http://yoursite.com/2018/12/06/frontend/flutter/flutter_learn_plan/","excerpt":"","text":"基础 Widget widget概述-布局模型 Material 组件Widget 与 Material关系处理手势根据用户输入改变widget响应widget生命周期事件","categories":[{"name":"flutter","slug":"flutter","permalink":"http://yoursite.com/categories/flutter/"}],"tags":[{"name":"learn task","slug":"learn-task","permalink":"http://yoursite.com/tags/learn-task/"},{"name":"flutter","slug":"flutter","permalink":"http://yoursite.com/tags/flutter/"}]},{"title":"搭建 vpn 服务器","slug":"devops/build_vpn_server","date":"2018-12-03T14:33:29.000Z","updated":"2018-12-04T14:29:46.108Z","comments":true,"path":"2018/12/03/devops/build_vpn_server/","link":"","permalink":"http://yoursite.com/2018/12/03/devops/build_vpn_server/","excerpt":"","text":"Setp1. install OpenVPN12$ sudo apt-get update$ sudo apt-get install openvpn easy-rsa Setp2. 构建 CA(certificate authority) 目录使用make-cadir拷贝easy-rsa 的模板. 1$ make-cadir ~/openvpn-ca Setp3. 配置 CA 变量~/openvpn-ca/vars 自己喜欢填啥就填啥吧, 不可以空着就是了 1234567891011. . .export KEY_NAME=\"server\" # 服务器的名字export KEY_COUNTRY=\"US\"export KEY_PROVINCE=\"CA\"export KEY_CITY=\"SanFrancisco\"export KEY_ORG=\"Fort-Funston\"export KEY_EMAIL=\"me@myhost.mydomain\"export KEY_OU=\"MyOrganizationalUnit\". . . Setp4. Build the Certificate Authority1234$ cd ~/openvpn-ca$ source vars$ ./clean-all # 确保干净的环境中操作$ ./build-ca # 构建CA Setp5. 创建服务器证书,key和加密文件123$ ./build-key-server server$ ./build-dh$ openvpn --genkey --secret keys/ta.key Setp6. 创建客户端的证书和key pair12$ ./build-key client1 # 不需要密码版$ ./build-key-pass client1 # 需要密码版 Setp7. 配置 OpenVPN 服务Copy the Files to the OpenVPN Directory1234cd ~/openvpn-ca/keyssudo cp ca.crt server.crt server.key ta.key dh2048.pem /etc/openvpn# 拷贝 vpn 服务器gunzip -c /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz | sudo tee /etc/openvpn/server.conf 调整 OpenVPN 的配置Basic Configuration vi /etc/openvpn/server.conf 1234567891011121314151617181920tls-auth ta.key 0 # This file is secretkey-direction 0cipher AES-128-CBCauth SHA256user nobodygroup nogrouppush \"redirect-gateway def1 bypass-dhcp\"push \"dhcp-option DNS 208.67.222.222\"push \"dhcp-option DNS 208.67.220.220\"port 443proto tcpcert server.crtkey server.key Setp8. 调整网络的服务配置vi /etc/sysctl.conf 1net.ipv4.ip_forward=1 Adjust the UFW Rules to Masquerade Client Connections防火墙先不考虑 Setp9. 开始 OpenVPN 服务器12systemctl start openvpn@serversystemctl status openvpn@server Setp10. 创建客户端的配置和基础设施Creating the Client Config Directory Structure12mkdir -p ~/client-configs/fileschmod 700 ~/client-configs/files Creating a Base Configuration1cp /usr/share/doc/openvpn/examples/sample-config-files/client.conf ~/client-configs/base.conf 编辑~/client-configs/base.conf文件 12345678910111213141516171819remote &#123;server_IP_address&#125; &#123;1194&#125;proto udpuser nobodygroup nogroupca ca.crtcert client.crtkey client.keycipher AES-128-CBCauth SHA256key-direction 1# script-security 2# up /etc/openvpn/update-resolv-conf# down /etc/openvpn/update-resolv-conf Creating a Configuration Generation Scriptvi ~/client-configs/make_config.sh 内容如下: 12345678910111213141516171819#!/bin/bash# First argument: Client identifierKEY_DIR=~/openvpn-ca/keysOUTPUT_DIR=~/client-configs/filesBASE_CONFIG=~/client-configs/base.confcat $&#123;BASE_CONFIG&#125; \\ &lt;(echo -e '&lt;ca&gt;') \\ $&#123;KEY_DIR&#125;/ca.crt \\ &lt;(echo -e '&lt;/ca&gt;\\n&lt;cert&gt;') \\ $&#123;KEY_DIR&#125;/$&#123;1&#125;.crt \\ &lt;(echo -e '&lt;/cert&gt;\\n&lt;key&gt;') \\ $&#123;KEY_DIR&#125;/$&#123;1&#125;.key \\ &lt;(echo -e '&lt;/key&gt;\\n&lt;tls-auth&gt;') \\ $&#123;KEY_DIR&#125;/ta.key \\ &lt;(echo -e '&lt;/tls-auth&gt;') \\ &gt; $&#123;OUTPUT_DIR&#125;/$&#123;1&#125;.ovpn 1chmod 700 ~/client-configs/make_config.sh Step 11: Generate Client Configurations123cd ~/client-configs./make_config.sh client1ls ~/client-configs/files 将文件拷贝到目标系统中 参考: https://www.digitalocean.com/community/tutorials/how-to-set-up-an-openvpn-server-on-ubuntu-16-04","categories":[{"name":"devops","slug":"devops","permalink":"http://yoursite.com/categories/devops/"}],"tags":[{"name":"vpn 服务器","slug":"vpn-服务器","permalink":"http://yoursite.com/tags/vpn-服务器/"}]},{"title":"Mac 上防火墙的倒腾","slug":"mac/防火墙问题","date":"2018-11-30T07:03:26.000Z","updated":"2018-11-30T08:08:31.350Z","comments":true,"path":"2018/11/30/mac/防火墙问题/","link":"","permalink":"http://yoursite.com/2018/11/30/mac/防火墙问题/","excerpt":"","text":"80端口转8080端口123456789101112131415161718192021222324首先在 /etc/pf.anchors/ 新建一个 http 文件内容如下:rdr pass on lo0 inet proto tcp from any to any port 80 -&gt; 127.0.0.1 port 8080然后使用 pfctl 命令检测配置文件sudo pfctl -vnf /etc/pf.anchors/http如果没有报错(正确的打印了配置信息, 没有明显的出错信息), 即修改pf的主配置文件/etc/pf.conf, 来引入这个转发规则:在rdr-anchor &quot;com.apple/*&quot;下, 添加如下 anchor 声明:rdr-anchor &quot;http-forwarding&quot;pf.conf对指令的顺序有严格要求, 否则会报出 Rules must be in order: options, normalization, queueing, translation, filtering 的错误, 所以相同的指令需要放在一起.再在load anchor &quot;com.apple&quot; from &quot;/etc/pf.anchors/com.apple&quot;下, 添加 anchor 引入:load anchor &quot;http-forwarding&quot; from &quot;/etc/pf.anchors/http&quot;最后, 导入并允许运行 pfsudo pfctl -ef /etc/pf.conf如果需要开机启动, 则需要为 /System/Library/LaunchDaemons/com.apple.pfctl.plist 针对 pfctl 的启动项, 新增一个 -e (允许) 参数, 这样, pf 规则开机机器可以生效了. pf 的一些用法在网上发现的一些例子: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475vi /etc/pf.conf#对外的网络卡ext_if = \"sis0\"#对内的网络卡int_if = \"rl0\"#频宽控管#定义 std_out 总频宽 512Kb#altq on $ext_if cbq bandwidth 512Kb queue &#123; std_out &#125;#定义 std_out 队列频宽 256Kb，使用预设队列#queue std_out bandwith 256Kb cbq (default)#定义 std_in 总频宽 2Mb#altq on $int_if cbq bandwidth 2Mb queue &#123; std_in &#125;#假设频宽足够的话，可以从父队列借用额外的频宽#queue std_in bandwidth 768Kb cbq (brrrow)#对外开放的服务 open_services = \"&#123;80, 443&#125;\"#内部私有的 IPpriv_nets = \"&#123; 127.0.0.0/8, 192.168.0.0/16, 172.16.0.0/12, 10.0.0.0/8 &#125;\"# options#设定拒绝联机封包的处理 方式set block-policy return#set optimization aggressive#纪录 $ext_ifset loginterface $ext_if# scrub#整理封包scrub in all#nat#NAT 地址转译处理nat on $ext_if from $int_if:network to any -&gt; $ext_if#ftp-proxy#ftp-proxy 重新 导向rdr on $int_if proto tcp from any to any port 21 -&gt; 127.0.0.1 port 8021#rdr on $ext_if proto tcp from any to 140.111.152.13 port 21 -&gt; 192.168.13.253 port 21#Transparent Proxy Serverrdr on rl0 proto tcp from 192.168.13.0/24 to any 80 -&gt; 127.0.0.1 port 3128#阻挡可疑封包在 $ext_if 网卡进出antispoof log quick for $ext_if#阻挡所有进出的封包block all#开放 loopbackpass quick on lo0 all#拒绝内部私有 IP 对 $ext_if 网络卡联机block drop in quick on $ext_if from $priv_nets to anyblock drop out quick on $ext_if from any to $priv_nets#开放对外的 80, 443 埠pass in on $ext_if inet proto tcp from any to $ext_if port $open_services flags S/SA keep state#只容许 140.111.152.0/24 网段对本机做 22 埠联机pass in on $ext_if inet proto tcp from 140.111.152.0/24 to $ext_if port 22 flags S/SA keep state#开放内部网络对外联机#pass in on $inf_if proto rcp from any to any queue std_inpass in on $int_if from $int_if:network to any keep statepass out on $int_if from any to $int_if:network keep state#开放对外网络的联机#pass out $ext_if proto tcp from any to any queue std_outpass out on $ext_if proto tcp all modulate state flags S/SApass out on $ext_if proto &#123; udp, icmp &#125; all keep state启动 PF，并读取 pf 规则pfctl -e;pfctl -f /etc/pf.conf 参考: http://www.voidcn.com/article/p-bioqbvvf-cx.html https://my.oschina.net/china008/blog/343049 PF 防火墙详解: http://blog.chinaunix.net/uid-20674714-id-90862.html","categories":[{"name":"Mac","slug":"Mac","permalink":"http://yoursite.com/categories/Mac/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://yoursite.com/tags/Mac/"},{"name":"日常杂记","slug":"日常杂记","permalink":"http://yoursite.com/tags/日常杂记/"}]},{"title":"","slug":"backend/go/goStandardLib/log","date":"2018-11-29T09:31:17.960Z","updated":"2018-11-29T09:47:13.098Z","comments":true,"path":"2018/11/29/backend/go/goStandardLib/log/","link":"","permalink":"http://yoursite.com/2018/11/29/backend/go/goStandardLib/log/","excerpt":"","text":"log引用 log 包1log.Printf(\"hello log %s\", \"!!\") 源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# Printffunc Printf(format string, v ...interface&#123;&#125;) &#123; std.Output(2, fmt.Sprintf(format, v...))&#125;# std 启用的是系统标准错误流var std = New(os.Stderr, \"\", LstdFlags)func New(out io.Writer, prefix string, flag int) *Logger &#123; return &amp;Logger&#123;out: out, prefix: prefix, flag: flag&#125;&#125;# Logger type Logger struct &#123; mu sync.Mutex // ensures atomic writes; protects the following fields prefix string // prefix to write at beginning of each line flag int // properties out io.Writer // destination for output buf []byte // for accumulating text to write&#125;// Output writes the output for a logging event. The string s contains// the text to print after the prefix specified by the flags of the// Logger. A newline is appended if the last character of s is not// already a newline. Calldepth is used to recover the PC and is// provided for generality, although at the moment on all pre-defined// paths it will be 2.func (l *Logger) Output(calldepth int, s string) error &#123; now := time.Now() // get this early. var file string var line int l.mu.Lock() defer l.mu.Unlock() if l.flag&amp;(Lshortfile|Llongfile) != 0 &#123; // Release lock while getting caller info - it's expensive. l.mu.Unlock() var ok bool _, file, line, ok = runtime.Caller(calldepth) if !ok &#123; file = \"???\" line = 0 &#125; l.mu.Lock() &#125; l.buf = l.buf[:0] l.formatHeader(&amp;l.buf, now, file, line) l.buf = append(l.buf, s...) if len(s) == 0 || s[len(s)-1] != '\\n' &#123; l.buf = append(l.buf, '\\n') &#125; _, err := l.out.Write(l.buf) return err&#125;","categories":[],"tags":[]},{"title":"","slug":"backend/go/goStandardLib/sort","date":"2018-11-29T08:43:58.955Z","updated":"2018-11-29T09:09:43.117Z","comments":true,"path":"2018/11/29/backend/go/goStandardLib/sort/","link":"","permalink":"http://yoursite.com/2018/11/29/backend/go/goStandardLib/sort/","excerpt":"","text":"sort接口: 12345678910111213141516// A type, typically a collection, that satisfies sort.Interface can be// sorted by the routines in this package. The methods require that the// elements of the collection be enumerated by an integer index.// 元素集合的操作接口type Interface interface &#123; // Len is the number of elements in the collection. // 集合中元素的个数 Len() int // Less reports whether the element with // index i should sort before the element with index j. // 元素 i 是否应该在元素 j 之前 Less(i, j int) bool // Swap swaps the elements with indexes i and j. // 交换元素 i 和 j Swap(i, j int)&#125; Sort 接口Sort 用的是快排 1234func Sort(data Interface) &#123; n := data.Len() quickSort(data, 0, n, maxDepth(n))&#125; quickSort()1234567891011121314151617181920212223242526272829func quickSort(data Interface, a, b, maxDepth int) &#123; for b-a &gt; 12 &#123; // Use ShellSort for slices &lt;= 12 elements if maxDepth == 0 &#123; heapSort(data, a, b) return &#125; maxDepth-- mlo, mhi := doPivot(data, a, b) // Avoiding recursion on the larger subproblem guarantees // a stack depth of at most lg(b-a). if mlo-a &lt; b-mhi &#123; quickSort(data, a, mlo, maxDepth) a = mhi // i.e., quickSort(data, mhi, b) &#125; else &#123; quickSort(data, mhi, b, maxDepth) b = mlo // i.e., quickSort(data, a, mlo) &#125; &#125; if b-a &gt; 1 &#123; // Do ShellSort pass with gap 6 // It could be written in this simplified form cause b-a &lt;= 12 for i := a + 6; i &lt; b; i++ &#123; if data.Less(i, i-6) &#123; data.Swap(i, i-6) &#125; &#125; insertionSort(data, a, b) &#125;&#125; 大于12用快排,小于等于12插排, 为啥是12呢? (元素个数小于13时插入排序会比快排快吗?)","categories":[],"tags":[]},{"title":"","slug":"backend/go/cron/cron_source_code_read","date":"2018-11-29T02:48:10.074Z","updated":"2018-11-29T08:07:32.353Z","comments":true,"path":"2018/11/29/backend/go/cron/cron_source_code_read/","link":"","permalink":"http://yoursite.com/2018/11/29/backend/go/cron/cron_source_code_read/","excerpt":"","text":"cron source code readgithub: https://github.com/jakecoffman/cron 概念Cron ​ 控制板, 保存了所有的任务,有停止,添加,移除,snapshot 等操作通道. Entry ​ 任务项: 包含了一个 schedule 和一个需要执行的 func Schedule ​ 日程表: 描述了工作周期 使用示例步骤: new 控制板 添加任务项 启动任务 123456789101112131415161718192021// 1. new 控制板c := cron.New()// 2. 添加任务项c.AddFunc(\"0 5 * * * *\", func() &#123; fmt.Println(\"Every 5 minutes\") &#125;, \"Often\")c.AddFunc(\"@hourly\", func() &#123; fmt.Println(\"Every hour\") &#125;, \"Frequent\")c.AddFunc(\"@every 1h30m\", func() &#123; fmt.Println(\"Every hour thirty\") &#125;, \"Less Frequent\")// 3. 启动任务c.Start()..// Funcs are invoked in their own goroutine, asynchronously....// Funcs may also be added to a running Cronc.AddFunc(\"@daily\", func() &#123; fmt.Println(\"Every day\") &#125;, \"My Job\")..// Inspect the cron job entries' next and previous run times.inspect(c.Entries())..// Remove an entry from the cron by name.c.RemoveJob(\"My Job\")..c.Stop() // Stop the scheduler (does not stop any jobs already running). 详细解析newCron12345678910func New() *Cron &#123; return &amp;Cron&#123; entries: nil, add: make(chan *Entry), remove: make(chan string), stop: make(chan struct&#123;&#125;), snapshot: make(chan entries), running: false, &#125;&#125; AddFuncAddFunc -&gt; AddJob 123func (c *Cron) AddJob(spec string, cmd Job, name string) &#123; c.Schedule(Parse(spec), cmd, name)&#125; Parse 功能: 解析 spec 生成 schedule ,生成的schedule很有意思哦!! Schedule主要职能: new Entry 添加 entry 到 cron 的 entries 中 Startgo 程启动 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667func (c *Cron) Start() &#123; c.running = true go c.run()&#125;// for 中 select 了解下func (c *Cron) run() &#123; // Figure out the next activation times for each entry. now := time.Now().Local() for _, entry := range c.entries &#123; entry.Next = entry.Schedule.Next(now) &#125; for &#123; // Determine the next entry to run. sort.Sort(byTime(c.entries)) var effective time.Time if len(c.entries) == 0 || c.entries[0].Next.IsZero() &#123; // If there are no entries yet, just sleep - it still handles new entries // and stop requests. effective = now.AddDate(10, 0, 0) &#125; else &#123; effective = c.entries[0].Next &#125; select &#123; case now = &lt;-time.After(effective.Sub(now)): // Run every entry whose next time was this effective time. for _, e := range c.entries &#123; if e.Next != effective &#123; break &#125; go e.Job.Run() e.Prev = e.Next e.Next = e.Schedule.Next(effective) &#125; continue case newEntry := &lt;-c.add: i := c.entries.pos(newEntry.Name) if i != -1 &#123; break &#125; c.entries = append(c.entries, newEntry) newEntry.Next = newEntry.Schedule.Next(time.Now().Local()) case name := &lt;-c.remove: i := c.entries.pos(name) if i == -1 &#123; break &#125; c.entries = c.entries[:i+copy(c.entries[i:], c.entries[i+1:])] case &lt;-c.snapshot: c.snapshot &lt;- c.entrySnapshot() case &lt;-c.stop: return &#125; // 'now' should be updated after newEntry and snapshot cases. now = time.Now().Local() &#125;&#125; Next位比较来筛选出下一个执行的时间点, 了解下?","categories":[],"tags":[]},{"title":"","slug":"backend/go/goStandardLib/REDEME","date":"2018-11-10T01:46:46.584Z","updated":"2018-11-10T01:49:03.363Z","comments":true,"path":"2018/11/10/backend/go/goStandardLib/REDEME/","link":"","permalink":"http://yoursite.com/2018/11/10/backend/go/goStandardLib/REDEME/","excerpt":"","text":"golang Standard library","categories":[],"tags":[]},{"title":"","slug":"alg/raft/3_raft领导选取","date":"2018-10-25T10:35:09.100Z","updated":"2018-12-22T08:17:02.789Z","comments":true,"path":"2018/10/25/alg/raft/3_raft领导选取/","link":"","permalink":"http://yoursite.com/2018/10/25/alg/raft/3_raft领导选取/","excerpt":"","text":"leader选取问题触发条件： 一般情况下，追随者接到领导者的心跳时，把ElectionTimeout清零，不会触发； 领导者故障，追随者的ElectionTimeout超时发生时，会变成候选者，触发领导人选取； 候选操作过程： 追随者自增当前任期，转换为Candidate，对自己投票，并发起RequestVote RPC，等待下面三种情形发生； 获得超过半数服务器的投票，赢得选举，成为领导者； 另一台服务器赢得选举，并接收到对应的心跳，成为追随者； 选举超时，没有任何一台服务器赢得选举，自增当前任期，重新发起选举；","categories":[],"tags":[]},{"title":"","slug":"alg/raft/1_raft基础","date":"2018-10-25T10:33:24.559Z","updated":"2018-12-22T03:37:42.448Z","comments":true,"path":"2018/10/25/alg/raft/1_raft基础/","link":"","permalink":"http://yoursite.com/2018/10/25/alg/raft/1_raft基础/","excerpt":"","text":"raft 基础理论参考: https://www.jianshu.com/p/096ae57d1fe0 问题分解为：领导选取、日志复制、安全和成员变化 基础概念复制状态机 复制状态机通过复制日志来实现： 日志：每台机器保存一份日志，日志来自于客户端的请求，包含一系列的命令 状态机：状态机会按顺序执行这些命令 一致性模型：分布式环境下，保证多机的日志是一致的，这样回放到状态机中的状态是一致的 服务器状态每台服务器均有可能存在下面三种情况: 领导者 候选人 追随者 追随者只响应其他服务器的请求。如果追随者没有收到任何消息，它会成为一个候选人并且开始一次选举。收到大多数服务器投票的候选人会成为新的领导人。领导人在它们宕机之前会一直保持领导人的状态。 任期Raft 算法将时间划分成为任意不同长度的任期（term）。任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最多只有一个领导人。 RPCRaft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起，然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制。为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。 RPC有三种： RequestVote RPC：候选人在选举期间发起 AppendEntries RPC：领导人发起的一种心跳机制，复制日志也在该命令中完成 InstallSnapshot RPC: 领导者使用该RPC来发送快照给太落后的追随者。 超时设置： BroadcastTime : 领导者的心跳超时时间 Election Timeout: 追随者设置的候选超时时间 MTBT :指的是单个服务器发生故障的间隔时间的平均数 BroadcastTime &lt;&lt; ElectionTimeout &lt;&lt; MTBF 两个原则： BroadcastTime应该比ElectionTimeout小一个数量级，为的是使领导人能够持续发送心跳信息（heartbeat）来阻止追随者们开始选举； ElectionTimeout也要比MTBF小几个数量级，为的是使得系统稳定运行。 一般BroadcastTime大约为0.5毫秒到20毫秒，ElectionTimeout一般在10ms到500ms之间。大多数服务器的MTBF都在几个月甚至更长。 leader选取问题触发条件： 一般情况下，追随者接到领导者的心跳时，把ElectionTimeout清零，不会触发； 领导者故障，追随者的ElectionTimeout超时发生时，会变成候选者，触发领导人选取； 候选操作过程： 追随者自增当前任期，转换为Candidate，对自己投票，并发起RequestVote RPC，等待下面三种情形发生； 获得超过半数服务器的投票，赢得选举，成为领导者； 另一台服务器赢得选举，并接收到对应的心跳，成为追随者； 选举超时，没有任何一台服务器赢得选举，自增当前任期，重新发起选举； 注意事项： 服务器在一个任期内，最多能给一个候选人投票，采用先到先服务原则； 候选者等待投票时，可能会接收到来自其它声明为领导人的的AppendEntries RPC。如果该领导人的任期（RPC中有）比当前候选人的当前任期要大，则候选人认为该领导人合法，并转换成追随者；如果RPC中的任期小于候选人的当前任期，则候选人拒绝此次RPC，继续保持候选人状态； 候选人既没有赢得选举也没有输掉选举：如果许多追随者在同一时刻都成为了候选人，选票会被分散，可能没有候选人能获得大多数的选票。当这种情形发生时，每一个候选人都会超时，并且通过自增任期号和发起另一轮 RequestVote RPC 来开始新的选举。然而，如果没有其它手段来分配选票的话，这种情形可能会无限的重复下去。所以Raft使用的随机的选举超时时间（150~300ms之间），来避免这种情况发生。 问题探讨：为什么这里没有谈收到其他候选者的RequestVote RPC请求？ 可能的解释： 候选者已经给自己投票了，一个候选者在一个任期只会给一个人投票，不会给其他人再投票了； 也有可能算法本身设定候选者就拒绝所有的其他服务器的请求。 日志复制 接受命令的过程： 领导者接受客户端请求； 领导者把指令追加到日志； 发送AppendEntries RPC到追随者； 领导者收到大多数追随者的确认后，领导者Commit该日志，把日志在状态机中回放，并返回结果给客户端； 提交过程： 在下一个心跳阶段，领导者再次发送AppendEntries RPC给追随者，日志已经commited； 追随者收到Commited日志后，将日志在状态机中回放。 安全性到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令，例如：一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。 1. 领导者追加日志（Append-Only)领导者永远不会覆盖已经存在的日志条目；日志永远只有一个流向：从领导者到追随者； 2. 选举限制：投票阻止没有全部日志条目的服务器赢得选举如果投票者的日志比候选人的新，拒绝投票请求；这意味着要赢得选举，候选者的日志至少和大多数服务器的日志一样新，那么它一定包含全部的已经提交的日志条目。 3. 永远不提交任期之前的日志条目（只提交任期内的日志条目）在Raft算法中，当一个日志被安全的复制到绝大多数的机器上面，即AppendEntries RPC在绝大多数服务器正确返回了，那么这个日志就是被提交了，然后领导者会更新commit index。 如果允许提交任期之前的日志条目，那么在步骤c中，我们就会把之前任期为2的日志提交到其他服务器中去，并造成了大多数机器存在了日志为2的情况。所以造成了d中S5中任期为3的日志条目会覆盖掉已经提交的日志的情况。 Raft 从来不会通过计算复制的数目来提交之前人气的日志条目。只有领导人当前任期的日志条目才能通过计算数目来进行提交。一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配原则（Log Matching Property），之前的日志条目也都会被间接的提交。 论文中的这段话比较难理解，更加直观的说：由于Raft不会提交任期之前的日志条目，那么就不会从b过渡到c的情况，只能从b发生S5down机的情况下直接过渡到e，这样就产生的更新的任期，这样S5就没有机会被选为领导者了。 4. 候选者和追随者崩溃候选者和追随者崩溃的情况处理要简单的多。如果这类角色崩溃了，那么后续发送给他们的 RequestVote和AppendEntries的所有RCP都会失败，Raft算法中处理这类失败就是简单的无限重试的方式。 如果这些服务器重新可用，那么这些RPC就会成功返回。如果一个服务器完成了一个RPC，但是在响应Leader前崩溃了，那么当他再次可用的时候还会收到相同的RPC请求，此时接收服务器负责检查，比如如果收到了已经包含该条日志的RPC请求，可以直接忽略这个请求，确保对系统是无害的。 成员变化问题","categories":[],"tags":[]},{"title":"","slug":"alg/raft/goraft_read","date":"2018-10-24T13:25:59.811Z","updated":"2018-10-24T15:14:43.906Z","comments":true,"path":"2018/10/24/alg/raft/goraft_read/","link":"","permalink":"http://yoursite.com/2018/10/24/alg/raft/goraft_read/","excerpt":"","text":"GoRaft Read建议粗略的看一下原理：https://www.jianshu.com/p/096ae57d1fe0 整体文件目录结构raft ├── LICENSE ├── Makefile ├── README.md ├── append_entries.go ├── append_entries_test.go ├── command.go ├── commands.go ├── config.go ├── context.go ├── debug.go ├── event.go ├── event_dispatcher.go ├── event_dispatcher_test.go ├── http_transporter.go ├── http_transporter_test.go ├── log.go ├── log_entry.go ├── log_test.go ├── peer.go ├── protobuf │ ├── append_entries_request.pb.go │ …. ├── request_vote.go ├── server.go ├── server_test.go ├── snapshot.go ├── snapshot_test.go ├── statemachine.go ├── statemachine_test.go ├── test.go ├── transporter.go ├── util.go └── z_test.go 文件作用详解append_entries.go entries：项，日志中的一条指令？ 存在两个结构体： AppendEntriesRequest 12345678910// The request sent to a server to append entries to the log.// 这个请求是发送给服务端的增加一项到日志中type AppendEntriesRequest struct &#123; Term uint64 PrevLogIndex uint64 PrevLogTerm uint64 CommitIndex uint64 LeaderName string Entries []*protobuf.LogEntry&#125; AppendEntriesResponse 1234567// The response returned from a server appending entries to the log.// 从服务端返回的应答type AppendEntriesResponse struct &#123; pb *protobuf.AppendEntriesResponse peer string append bool&#125; command.go 一些和命令相关的接口定义: 123456789101112131415var commandTypes map[string]Commandfunc init() &#123; commandTypes = map[string]Command&#123;&#125;&#125;// Command represents an action to be taken on the replicated state machine.type Command interface &#123; CommandName() string&#125;// CommandApply represents the interface to apply a command to the server.type CommandApply interface &#123; Apply(Context) (interface&#123;&#125;, error)&#125; commands.go 定义了一些指令的接口和结构体 1234567891011121314151617181920212223242526// Join command interfacetype JoinCommand interface &#123; Command NodeName() string&#125;// Join commandtype DefaultJoinCommand struct &#123; Name string `json:\"name\"` ConnectionString string `json:\"connectionString\"`&#125;// Leave command interfacetype LeaveCommand interface &#123; Command NodeName() string&#125;// Leave commandtype DefaultLeaveCommand struct &#123; Name string `json:\"name\"`&#125;// NOP commandtype NOPCommand struct &#123;&#125; context.go context 12345678910111213141516171819// Context represents the current state of the server. It is passed into// a command when the command is being applied since the server methods// are locked.// Context表示服务器的当前状态。 由于服务器方法被锁定，因此在应用命令时将其传递给命令type Context interface &#123; Server() Server CurrentTerm() uint64 CurrentIndex() uint64 CommitIndex() uint64&#125;// context is the concrete implementation of Context.// context是Context的具体实现type context struct &#123; server Server currentIndex uint64 currentTerm uint64 commitIndex uint64&#125; event_dispatcher.go 事件调度者 12345678910111213141516// eventDispatcher is responsible for managing listeners for named events// and dispatching event notifications to those listeners.// eventDispatcher负责管理命名事件的侦听器并将事件通知分派给这些侦听器type eventDispatcher struct &#123; sync.RWMutex source interface&#123;&#125; listeners map[string]eventListeners&#125;// EventListener is a function that can receive event notifications.// EventListener 是一个函数,能够接受事件通知type EventListener func(Event)// EventListeners represents a collection of individual listeners.// EventListeners 一个监听器的收集器type eventListeners []EventListener event.go 定义了事件 123456789101112131415161718// Event represents an action that occurred within the Raft library.// Listeners can subscribe to event types by using the Server.AddEventListener() function.// Event 表示在Raft库中发生的操作。 监听器可以使用Server.AddEventListener（）函数订阅事件类型。type Event interface &#123; Type() string Source() interface&#123;&#125; Value() interface&#123;&#125; PrevValue() interface&#123;&#125;&#125;// event is the concrete implementation of the Event interface.// event 是 Event 接口的一个实现type event struct &#123; typ string source interface&#123;&#125; value interface&#123;&#125; prevValue interface&#123;&#125;&#125; http_transporter.go 1234567891011121314151617// An HTTPTransporter is a default transport layer used to communicate between// multiple servers.// HTTPTransporter 是用于在多个服务器之间进行通信的默认传输层type HTTPTransporter struct &#123; DisableKeepAlives bool prefix string appendEntriesPath string requestVotePath string snapshotPath string snapshotRecoveryPath string httpClient http.Client Transport *http.Transport&#125;type HTTPMuxer interface &#123; HandleFunc(string, func(http.ResponseWriter, *http.Request))&#125; log_entry.go 日志中的一项 12345678// A log entry stores a single item in the log.// 日志中的单独一项type LogEntry struct &#123; pb *protobuf.LogEntry Position int64 // position in the log file log *Log event *ev&#125; log.go 日志 12345678910111213141516171819// A log is a collection of log entries that are persisted to durable storage.// Log 是 log entries 的一个收集器, 可以持久存储到持久存储器type Log struct &#123; ApplyFunc func(*LogEntry, Command) (interface&#123;&#125;, error) file *os.File path string entries []*LogEntry commitIndex uint64 mutex sync.RWMutex startIndex uint64 // the index before the first entry in the Log entries startTerm uint64 initialized bool&#125;// The results of the applying a log entry.type logResult struct &#123; returnValue interface&#123;&#125; err error&#125; peer.go 123456789101112// A peer is a reference to another server involved in the consensus protocol.// Peer 是对共识协议中涉及的另一个服务器的引用type Peer struct &#123; server *server Name string `json:\"name\"` ConnectionString string `json:\"connectionString\"` prevLogIndex uint64 stopChan chan bool heartbeatInterval time.Duration lastActivity time.Time sync.RWMutex&#125; request_vote.go 123456789101112131415// The request sent to a server to vote for a candidate to become a leader.type RequestVoteRequest struct &#123; peer *Peer Term uint64 LastLogIndex uint64 LastLogTerm uint64 CandidateName string&#125;// The response returned from a server after a vote for a candidate to become a leader.type RequestVoteResponse struct &#123; peer *Peer Term uint64 VoteGranted bool&#125; server.go 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// A server is involved in the consensus protocol and can act as a follower,// candidate or a leader.type Server interface &#123; Name() string Context() interface&#123;&#125; StateMachine() StateMachine Leader() string State() string Path() string LogPath() string SnapshotPath(lastIndex uint64, lastTerm uint64) string Term() uint64 CommitIndex() uint64 VotedFor() string MemberCount() int QuorumSize() int IsLogEmpty() bool LogEntries() []*LogEntry LastCommandName() string GetState() string ElectionTimeout() time.Duration SetElectionTimeout(duration time.Duration) HeartbeatInterval() time.Duration SetHeartbeatInterval(duration time.Duration) Transporter() Transporter SetTransporter(t Transporter) AppendEntries(req *AppendEntriesRequest) *AppendEntriesResponse RequestVote(req *RequestVoteRequest) *RequestVoteResponse RequestSnapshot(req *SnapshotRequest) *SnapshotResponse SnapshotRecoveryRequest(req *SnapshotRecoveryRequest) *SnapshotRecoveryResponse AddPeer(name string, connectiongString string) error RemovePeer(name string) error Peers() map[string]*Peer Init() error Start() error Stop() Running() bool Do(command Command) (interface&#123;&#125;, error) TakeSnapshot() error LoadSnapshot() error AddEventListener(string, EventListener) FlushCommitIndex()&#125;type server struct &#123; *eventDispatcher name string path string state string transporter Transporter context interface&#123;&#125; currentTerm uint64 votedFor string log *Log leader string peers map[string]*Peer mutex sync.RWMutex syncedPeer map[string]bool stopped chan bool c chan *ev electionTimeout time.Duration heartbeatInterval time.Duration snapshot *Snapshot // PendingSnapshot is an unfinished snapshot. // After the pendingSnapshot is saved to disk, // it will be set to snapshot and also will be // set to nil. pendingSnapshot *Snapshot stateMachine StateMachine maxLogEntriesPerRequest uint64 connectionString string routineGroup sync.WaitGroup&#125;// An internal event to be processed by the server's event loop.type ev struct &#123; target interface&#123;&#125; returnValue interface&#123;&#125; c chan error&#125; snapshot.go 1234567891011121314151617181920212223242526272829303132333435363738// Snapshot represents an in-memory representation of the current state of the system.type Snapshot struct &#123; LastIndex uint64 `json:\"lastIndex\"` LastTerm uint64 `json:\"lastTerm\"` // Cluster configuration. Peers []*Peer `json:\"peers\"` State []byte `json:\"state\"` Path string `json:\"path\"`&#125;// The request sent to a server to start from the snapshot.type SnapshotRecoveryRequest struct &#123; LeaderName string LastIndex uint64 LastTerm uint64 Peers []*Peer State []byte&#125;// The response returned from a server appending entries to the log.type SnapshotRecoveryResponse struct &#123; Term uint64 Success bool CommitIndex uint64&#125;// The request sent to a server to start from the snapshot.type SnapshotRequest struct &#123; LeaderName string LastIndex uint64 LastTerm uint64&#125;// The response returned if the follower entered snapshot statetype SnapshotResponse struct &#123; Success bool `json:\"success\"`&#125; statemachine.go 1234567// StateMachine is the interface for allowing the host application to save and// recovery the state machine. This makes it possible to make snapshots// and compact the log.type StateMachine interface &#123; Save() ([]byte, error) Recovery([]byte) error&#125; transporter.go 12345678// Transporter is the interface for allowing the host application to transport// requests to other nodes.type Transporter interface &#123; SendVoteRequest(server Server, peer *Peer, req *RequestVoteRequest) *RequestVoteResponse SendAppendEntriesRequest(server Server, peer *Peer, req *AppendEntriesRequest) *AppendEntriesResponse SendSnapshotRequest(server Server, peer *Peer, req *SnapshotRequest) *SnapshotResponse SendSnapshotRecoveryRequest(server Server, peer *Peer, req *SnapshotRecoveryRequest) *SnapshotRecoveryResponse&#125;","categories":[],"tags":[]},{"title":"","slug":"build_own_x/os/How to create an OS from scratch","date":"2018-09-23T05:21:19.206Z","updated":"2018-12-07T06:15:22.113Z","comments":true,"path":"2018/09/23/build_own_x/os/How to create an OS from scratch/","link":"","permalink":"http://yoursite.com/2018/09/23/build_own_x/os/How to create an OS from scratch/","excerpt":"","text":"How to create an OS from scratch!参考: https://github.com/cfenollosa/os-tutorial","categories":[],"tags":[]},{"title":"服务的注册,发现","slug":"backend/go/grpc/服务的注册_发现","date":"2018-09-14T12:42:22.000Z","updated":"2018-09-15T02:22:59.561Z","comments":true,"path":"2018/09/14/backend/go/grpc/服务的注册_发现/","link":"","permalink":"http://yoursite.com/2018/09/14/backend/go/grpc/服务的注册_发现/","excerpt":"","text":"参考: https://juejin.im/post/5ad9b9596fb9a07acf55b550 微服务之服务的注册和发现服务的注册发现功能, 能够很好的解耦服务器之间的调用功能. 服务注册策略: 将服务注册到 kv 服务器中, 设置一个过期时间(50s ? ). 心跳续期 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func (er *etcdRegistry) Register(ctx context.Context, target string, update naming.Update, opts ...wrapper.RegistryOptions) (err error) &#123; var upBytes []byte if upBytes, err = json.Marshal(update); err != nil &#123; return status.Error(codes.InvalidArgument, err.Error()) &#125; ctx, cancel := context.WithTimeout(context.TODO(), resolverTimeOut) er.cancal = cancel rgOpt := wrapper.RegistryOption&#123;TTL: wrapper.DefaultRegInfTTL&#125; for _, opt := range opts &#123; opt(&amp;rgOpt) &#125; switch update.Op &#123; case naming.Add: lsRsp, err := er.lsCli.Grant(ctx, int64(rgOpt.TTL/time.Second)) if err != nil &#123; return err &#125; //Put服务信息到etcd,并设置key的值TTL,通过后面的KeepAlive接口 //对TTL进行续期,超过TTL的时间未收到续期请求,则说明服务可能挂了,从而清除服务信息 etcdOpts := []etcd.OpOption&#123;etcd.WithLease(lsRsp.ID)&#125; key := target + \"/\" + update.Addr _, err = er.cli.KV.Put(ctx, key, string(upBytes), etcdOpts...) if err != nil &#123; return err &#125; //保持心跳 lsRspChan, err := er.lsCli.KeepAlive(context.TODO(), lsRsp.ID) if err != nil &#123; return err &#125; go func() &#123; for &#123; _, ok := &lt;-lsRspChan if !ok &#123; grpclog.Fatalf(\"%v keepalive channel is closing\", key) break &#125; &#125; &#125;() case naming.Delete: _, err = er.cli.Delete(ctx, target+\"/\"+update.Addr) default: return status.Error(codes.InvalidArgument, \"unsupported op\") &#125; return nil&#125; 服务发现Resolve()接口1234567891011//用于生成Watcher,监听注册中心中的服务信息变化func (er *etcdRegistry) Resolve(target string) (naming.Watcher, error) &#123; ctx, cancel := context.WithTimeout(context.TODO(), resolverTimeOut) w := &amp;etcdWatcher&#123; cli: er.cli, target: target + \"/\", ctx: ctx, cancel: cancel, &#125; return w, nil&#125; Next() 接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//Next接口主要用于获取注册的服务信息,通过channel以及watch,当服务信息发生//变化时,Next接口会将变化返回给grpc框架从而实现服务信息变更.func (ew *etcdWatcher) Next() ([]*naming.Update, error) &#123; var updates []*naming.Update //初次获取时,创建监听channel,并返回获取到的服务信息 if ew.watchChan == nil &#123; //create new chan resp, err := ew.cli.Get(ew.ctx, ew.target, etcd.WithPrefix(), etcd.WithSerializable()) if err != nil &#123; return nil, err &#125; for _, kv := range resp.Kvs &#123; var upt naming.Update if err := json.Unmarshal(kv.Value, &amp;upt); err != nil &#123; continue &#125; updates = append(updates, &amp;upt) &#125; //创建etcd的watcher监听target(服务名)的信息. opts := []etcd.OpOption&#123;etcd.WithRev(resp.Header.Revision + 1), etcd.WithPrefix(), etcd.WithPrevKV()&#125; ew.watchChan = ew.cli.Watch(context.TODO(), ew.target, opts...) return updates, nil &#125; //阻塞监听,服务发生变化时才返回给上层 wrsp, ok := &lt;-ew.watchChan if !ok &#123; err := status.Error(codes.Unavailable, \"etcd watch closed\") return nil, err &#125; if wrsp.Err() != nil &#123; return nil, wrsp.Err() &#125; for _, e := range wrsp.Events &#123; var upt naming.Update var err error switch e.Type &#123; case etcd.EventTypePut: err = json.Unmarshal(e.Kv.Value, &amp;upt) upt.Op = naming.Add case etcd.EventTypeDelete: err = json.Unmarshal(e.PrevKv.Value, &amp;upt) upt.Op = naming.Delete &#125; if err != nil &#123; continue &#125; updates = append(updates, &amp;upt) &#125; return updates, nil&#125; 使用默认的grpc123456789101112cli, _ := clientv3.NewFromURL(\"http://127.0.0.1:2379\")rs := &amp;etcdnaming.GRPCResolver&#123;Client: cli&#125;b := grpc.RoundRobin(rs)dialOpts := []grpc.DialOption&#123;grpc.WithBalancer(b), grpc.WithInsecure()&#125;conn, err := grpc.Dial(\"jie-test\", dialOpts...)if err != nil &#123; log.Fatalf(\"did not connect: %v\", err)&#125;defer conn.Close()client := pb.NewGreeterClient(conn)","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"grpc","slug":"grpc","permalink":"http://yoursite.com/tags/grpc/"},{"name":"etcd","slug":"etcd","permalink":"http://yoursite.com/tags/etcd/"}]},{"title":"admin_manage_jie","slug":"frontend/learn_admin_manage/admin_manage_jie_learn","date":"2018-09-08T14:27:30.000Z","updated":"2018-09-08T14:29:56.856Z","comments":true,"path":"2018/09/08/frontend/learn_admin_manage/admin_manage_jie_learn/","link":"","permalink":"http://yoursite.com/2018/09/08/frontend/learn_admin_manage/admin_manage_jie_learn/","excerpt":"","text":"admin_manage_jiecopy from Material Dashboard React","categories":[{"name":"frontend","slug":"frontend","permalink":"http://yoursite.com/categories/frontend/"}],"tags":[{"name":"react","slug":"react","permalink":"http://yoursite.com/tags/react/"},{"name":"admin manage","slug":"admin-manage","permalink":"http://yoursite.com/tags/admin-manage/"}]},{"title":"个人软件安装记录(linux-ubuntu)","slug":"self_doc/个人软件安装记录-linux","date":"2018-09-04T01:51:07.000Z","updated":"2018-12-07T07:13:05.317Z","comments":true,"path":"2018/09/04/self_doc/个人软件安装记录-linux/","link":"","permalink":"http://yoursite.com/2018/09/04/self_doc/个人软件安装记录-linux/","excerpt":"","text":"1234567891011121314151617181920212223apt-get install -y gitapt-get install -y treeapt-get install -y wget## zshsh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"## zsh configplugins=( git z wd zsh-autosuggestions docker docker-compose)## zsh install zsh-autosuggestionsgit clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions## 持续增加中...","categories":[],"tags":[{"name":"tools安装","slug":"tools安装","permalink":"http://yoursite.com/tags/tools安装/"}]},{"title":"Learn CSS Grid","slug":"frontend/css/grid_learn/learn_css_grid","date":"2018-09-02T02:38:47.663Z","updated":"2018-09-02T11:42:15.520Z","comments":true,"path":"2018/09/02/frontend/css/grid_learn/learn_css_grid/","link":"","permalink":"http://yoursite.com/2018/09/02/frontend/css/grid_learn/learn_css_grid/","excerpt":"","text":"视频教程推荐(建议先看一些基础概念): https://scrimba.com/g/gR8PTE简单教程: https://medium.freecodecamp.org/learn-css-grid-in-5-minutes-f582e87b1228详细教程: https://learncssgrid.com/ 该内容主要来自:https://scrimba.com/g/gR8PTE and https://medium.freecodecamp.org/learn-css-grid-in-5-minutes-f582e87b1228 重要术语解释参考: https://www.jianshu.com/p/d183265a8dad 网格容器（Grid Container）元素应用display:grid，它是其所有网格项的父元素。下面例子container就是网格容器。 12345&lt;div class=\"container\"&gt; &lt;div class=\"item item-1\"&gt;&lt;/div&gt; &lt;div class=\"item item-2\"&gt;&lt;/div&gt; &lt;div class=\"item item-3\"&gt;&lt;/div&gt;&lt;/div&gt; 网格项（Grid Item） 网格容器的子元素，下面的item元素是网格项，但sub-item不是。1234567&lt;div class=\"container\"&gt; &lt;div class=\"item\"&gt;&lt;/div&gt; &lt;div class=\"item\"&gt; &lt;p class=\"sub-item\"&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=\"item\"&gt;&lt;/div&gt;&lt;/div&gt; 网格线（Grid Line） 组成网格线的分界线。它们可以是列网格线（column grid lines），也可以是行网格线（row grid lines）并且居于行或列的任意一侧，下面黄色线就是列网格线。 网格轨道（Grid Track）两个相邻的网格线之间为网格轨道。你可以认为它们是网格的列或行，下面在第二个和第三个网格线之间的黄色部分为网格轨道。 网格单元（Grid Cell）两个相邻的列网格线和两个相邻的行网格线组成的是网格单元，它是最小的网格单元。下面行网格线1（row grid lines 1）、行网格线2（row grid lines 2）和列网格线2（column grid lines 2）、列网格线3（column grid lines 3）组成的黄色区域为网格单元。 网格区（Grid Area）网格区是由任意数量网格单元组成，下面行网格线1（row grid lines 1）、行网格线3（row grid lines 3）和列网格线1（column grid lines 1）、列网格线3（column grid lines3）组成的黄色区域为网格区。 第一个 grid 布局 The two core ingredients of a CSS Grid are the wrapper (parent) and the items (children). The wrapper is the actual grid and the items are the content inside the grid.CSS Grid的两个核心组成部分是包装器（父）和项（子）。 包装器是实际网格，项目是网格内的内容。 12345678&lt;div class=\"wrapper\"&gt; &lt;div&gt;1&lt;/div&gt; &lt;div&gt;2&lt;/div&gt; &lt;div&gt;3&lt;/div&gt; &lt;div&gt;4&lt;/div&gt; &lt;div&gt;5&lt;/div&gt; &lt;div&gt;6&lt;/div&gt;&lt;/div&gt; 123.wrapper &#123; display: grid;&#125; result: Columns and rows12345.wrapper &#123; display: grid; grid-template-columns: 100px 100px 100px; grid-template-rows: 50px 50px;&#125; 12345.wrapper &#123; display: grid; grid-template-columns: 200px 50px 100px; grid-template-rows: 100px 30px;&#125; items1234.item1 &#123; grid-column-start: 1; grid-column-end: 4;&#125; 123.item1 &#123; grid-column: 1 / 4;&#125;","categories":[{"name":"frontend","slug":"frontend","permalink":"http://yoursite.com/categories/frontend/"},{"name":"learn notebook","slug":"frontend/learn-notebook","permalink":"http://yoursite.com/categories/frontend/learn-notebook/"}],"tags":[{"name":"css","slug":"css","permalink":"http://yoursite.com/tags/css/"},{"name":"css grid","slug":"css-grid","permalink":"http://yoursite.com/tags/css-grid/"}]},{"title":"markfile start learn","slug":"backend/tools/markfile_start_learn","date":"2018-09-01T07:37:28.000Z","updated":"2018-09-01T10:05:44.866Z","comments":true,"path":"2018/09/01/backend/tools/markfile_start_learn/","link":"","permalink":"http://yoursite.com/2018/09/01/backend/tools/markfile_start_learn/","excerpt":"","text":"参考: https://www.cnblogs.com/wang_yb/p/3990952.html Makefile 简介Makefile 是和 make 命令一起配合使用的. 很多大型项目的编译都是通过 Makefile 来组织的, 如果没有 Makefile, 那很多项目中各种库和代码之间的依赖关系不知会多复杂. Makefile的组织流程的能力如此之强, 不仅可以用来编译项目, 还可以用来组织我们平时的一些日常操作. 这个需要大家发挥自己的想象力. Makefile 主要的 5个部分 (显示规则, 隐晦规则, 变量定义, 文件指示, 注释)Makefile基本格式如下: 1234target ... : prerequisites ... command ... ... 其中, target - 目标文件, 可以是 Object File, 也可以是可执行文件 prerequisites - 生成 target 所需要的文件或者目标 command - make需要执行的命令 (任意的shell命令), Makefile中的命令必须以 [tab] 开头 显示规则 :: 说明如何生成一个或多个目标文件(包括 生成的文件, 文件的依赖文件, 生成的命令) 隐晦规则 :: make的自动推导功能所执行的规则 变量定义 :: Makefile中定义的变量 文件指示 :: Makefile中引用其他Makefile; 指定Makefile中有效部分; 定义一个多行命令 注释 :: Makefile只有行注释 “#”, 如果要使用或者输出”#”字符, 需要进行转义, “#“ 1.2 GNU make 的工作方式 读入主Makefile (主Makefile中可以引用其他Makefile) 读入被include的其他Makefile 初始化文件中的变量 推导隐晦规则, 并分析所有规则 为所有的目标文件创建依赖关系链 根据依赖关系, 决定哪些目标要重新生成 执行生成命令 实例解析","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://yoursite.com/tags/markdown/"},{"name":"build tools","slug":"build-tools","permalink":"http://yoursite.com/tags/build-tools/"}]},{"title":"apidoc start learn","slug":"backend/tools/apidoc_start_learn","date":"2018-08-31T08:02:53.000Z","updated":"2018-09-01T07:37:58.024Z","comments":true,"path":"2018/08/31/backend/tools/apidoc_start_learn/","link":"","permalink":"http://yoursite.com/2018/08/31/backend/tools/apidoc_start_learn/","excerpt":"","text":"参考: http://apidocjs.com/ DemoJavadoc-Style (can be used in C#, Go, Dart, Java, JavaScript, PHP, TypeScript and all other Javadoc capable languages): 12345678910/** * @api &#123;get&#125; /user/:id Request User information * @apiName GetUser * @apiGroup User * * @apiParam &#123;Number&#125; id Users unique ID. * * @apiSuccess &#123;String&#125; firstname Firstname of the User. * @apiSuccess &#123;String&#125; lastname Lastname of the User. */ install1npm install apidoc -g Run1apidoc -i myapp/ -o apidoc/ -t mytemplate/ Configuration (apidoc.json)ex:1234567&#123; \"name\": \"example\", \"version\": \"0.1.0\", \"description\": \"apiDoc basic example\", \"title\": \"Custom apiDoc browser title\", \"url\" : \"https://api.github.com/v1\"&#125; Header / Footer12345678910&#123; \"header\": &#123; \"title\": \"My own header title\", \"filename\": \"header.md\" &#125;, \"footer\": &#123; \"title\": \"My own footer title\", \"filename\": \"footer.md\" &#125;&#125; Basicapidoc.json 12345&#123; \"name\": \"example\", \"version\": \"0.1.0\", \"description\": \"A basic apiDoc example\"&#125; example.js 12345678910111213141516171819202122232425/** * @api &#123;get&#125; /user/:id Request User information * @apiName GetUser * @apiGroup User * * @apiParam &#123;Number&#125; id Users unique ID. * * @apiSuccess &#123;String&#125; firstname Firstname of the User. * @apiSuccess &#123;String&#125; lastname Lastname of the User. * * @apiSuccessExample Success-Response: * HTTP/1.1 200 OK * &#123; * \"firstname\": \"John\", * \"lastname\": \"Doe\" * &#125; * * @apiError UserNotFound The id of the User was not found. * * @apiErrorExample Error-Response: * HTTP/1.1 404 Not Found * &#123; * \"error\": \"UserNotFound\" * &#125; */ 继承12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @apiDefine UserNotFoundError * * @apiError UserNotFound The id of the User was not found. * * @apiErrorExample Error-Response: * HTTP/1.1 404 Not Found * &#123; * \"error\": \"UserNotFound\" * &#125; *//** * @api &#123;get&#125; /user/:id Request User information * @apiName GetUser * @apiGroup User * * @apiParam &#123;Number&#125; id Users unique ID. * * @apiSuccess &#123;String&#125; firstname Firstname of the User. * @apiSuccess &#123;String&#125; lastname Lastname of the User. * * @apiSuccessExample Success-Response: * HTTP/1.1 200 OK * &#123; * \"firstname\": \"John\", * \"lastname\": \"Doe\" * &#125; * * @apiUse UserNotFoundError *//** * @api &#123;put&#125; /user/ Modify User information * @apiName PutUser * @apiGroup User * * @apiParam &#123;Number&#125; id Users unique ID. * @apiParam &#123;String&#125; [firstname] Firstname of the User. * @apiParam &#123;String&#125; [lastname] Lastname of the User. * * @apiSuccessExample Success-Response: * HTTP/1.1 200 OK * * @apiUse UserNotFoundError */ Versioning1234567891011121314151617181920212223242526/** * @api &#123;get&#125; /user/:id Get User information * @apiVersion 0.1.0 * @apiName GetUser * @apiGroup User * * @apiParam &#123;Number&#125; id Users unique ID. * * @apiSuccess &#123;String&#125; firstname Firstname of the User. * @apiSuccess &#123;String&#125; lastname Lastname of the User. * * @apiSuccessExample Success-Response: * HTTP/1.1 200 OK * &#123; * \"firstname\": \"John\", * \"lastname\": \"Doe\" * &#125; * * @apiError UserNotFound The id of the User was not found. * * @apiErrorExample Error-Response: * HTTP/1.1 404 Not Found * &#123; * \"error\": \"UserNotFound\" * &#125; */ 123456789101112131415161718192021222324252627/** * @api &#123;get&#125; /user/:id Get User information and Date of Registration. * @apiVersion 0.2.0 * @apiName GetUser * @apiGroup User * * @apiParam &#123;Number&#125; id Users unique ID. * * @apiSuccess &#123;String&#125; firstname Firstname of the User. * @apiSuccess &#123;String&#125; lastname Lastname of the User. * @apiSuccess &#123;Date&#125; registered Date of Registration. * * @apiSuccessExample Success-Response: * HTTP/1.1 200 OK * &#123; * \"firstname\": \"John\", * \"lastname\": \"Doe\" * &#125; * * @apiError UserNotFound The id of the User was not found. * * @apiErrorExample Error-Response: * HTTP/1.1 404 Not Found * &#123; * \"error\": \"UserNotFound\" * &#125; */ 该版本可用于每个块，也可用于继承块。您不必更改继承块上的版本，解析器会自动检查最近的前任. apiDoc-Params列几个常用的标签: @api1@api &#123;method&#125; path [title] Required!Without that indicator, apiDoc parser ignore the documentation block. (apidoc 工具的标识开始) @apiName1@apiName name @apiGroup1@apiGroup name @apiDefine12@apiDefine name [title] [description] @apiUse1@apiUse name @apiDeprecated1@apiDeprecated [text] Ex:12345678910/** * @apiDeprecated *//** * @apiDeprecated use now (#Group:Name). * * Example: to set a link to the GetDetails method of your group User * write (#User:GetDetails) */ @apiDescription1@apiDescription text Ex:123456/** * @apiDescription This is the Description. * It is multiline capable. * * Last line of Description. */ @apiParam1@apiParam [(group)] [&#123;type&#125;] [field=defaultValue] [description] 12345678910111213141516/** * @api &#123;get&#125; /user/:id * @apiParam &#123;Number&#125; id Users unique ID. *//** * @api &#123;post&#125; /user/ * @apiParam &#123;String&#125; [firstname] Optional Firstname of the User. * @apiParam &#123;String&#125; lastname Mandatory Lastname. * @apiParam &#123;String&#125; country=\"DE\" Mandatory with default value \"DE\". * @apiParam &#123;Number&#125; [age=18] Optional Age with default 18. * * @apiParam (Login) &#123;String&#125; pass Only logged in users can post this. * In generated documentation a separate * \"Login\" Block will be generated. */ Name Description (group) All parameters will be grouped by this name. Without a group, the default Parameter is set.You can set a title and description with @apiDefine. {type} Parameter type, e.g. {Boolean}, {Number}, {String}, {Object}, {String[]} (array of strings), … {type{size}} Information about the size of the variable.{string{..5}} a string that has max 5 chars.{string{2..5}} a string that has min. 2 chars and max 5 chars.{number{100-999}} a number between 100 and 999. {type=allowedValues} Information about allowed values of the variable.{string=&quot;small&quot;} a string that can only contain the word “small” (a constant).{string=&quot;small&quot;,&quot;huge&quot;} a string that can contain the words “small” or “huge”.{number=1,2,3,99} a number with allowed values of 1, 2, 3 and 99.Can be combined with size:{string {..5}=&quot;small&quot;,&quot;huge&quot;} a string that has max 5 chars and only contain the words “small” or “huge”. field Variablename [field] Fieldname with brackets define the Variable as optional. =defaultValue The parameters default value. description Description of the field. @apiParamExample12@apiParamExample [&#123;type&#125;] [title] example 1234567/** * @api &#123;get&#125; /user/:id * @apiParamExample &#123;json&#125; Request-Example: * &#123; * \"id\": 4711 * &#125; */ @apiSuccess1@apiSuccess [(group)] [&#123;type&#125;] field [description] @apiSuccessExample12@apiSuccessExample [&#123;type&#125;] [title] example 123456789/** * @api &#123;get&#125; /user/:id * @apiSuccessExample &#123;json&#125; Success-Response: * HTTP/1.1 200 OK * &#123; * \"firstname\": \"John\", * \"lastname\": \"Doe\" * &#125; */ @apiError1@apiError [(group)] [&#123;type&#125;] field [description] 1234/** * @api &#123;get&#125; /user/:id * @apiError UserNotFound The &lt;code&gt;id&lt;/code&gt; of the User was not found. */ @apiErrorExample12@apiErrorExample [&#123;type&#125;] [title] example 12345678/** * @api &#123;get&#125; /user/:id * @apiErrorExample &#123;json&#125; Error-Response: * HTTP/1.1 404 Not Found * &#123; * \"error\": \"UserNotFound\" * &#125; */","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"apidoc","slug":"apidoc","permalink":"http://yoursite.com/tags/apidoc/"},{"name":"learn","slug":"learn","permalink":"http://yoursite.com/tags/learn/"}]},{"title":"个人软件安装记录(mac osx)","slug":"self_doc/个人软件安装记录","date":"2018-08-31T07:54:58.000Z","updated":"2018-12-07T07:13:08.386Z","comments":true,"path":"2018/08/31/self_doc/个人软件安装记录/","link":"","permalink":"http://yoursite.com/2018/08/31/self_doc/个人软件安装记录/","excerpt":"","text":"1234567891011121314151617181920212223## tree installbrew install tree## apidoc installnpm install apidoc -g## zshsh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"## zsh configplugins=( git z wd zsh-autosuggestions docker docker-compose)## zsh install zsh-autosuggestionsgit clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions## 持续增加中...","categories":[],"tags":[{"name":"tools安装","slug":"tools安装","permalink":"http://yoursite.com/tags/tools安装/"}]},{"title":"docker 构建最小 go app","slug":"backend/docker/docker_构建最小_go_app","date":"2018-08-30T05:56:07.000Z","updated":"2018-08-30T08:27:38.128Z","comments":true,"path":"2018/08/30/backend/docker/docker_构建最小_go_app/","link":"","permalink":"http://yoursite.com/2018/08/30/backend/docker/docker_构建最小_go_app/","excerpt":"","text":"参考: https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/ 写应用1234567891011121314151617181920212223package mainimport ( \"fmt\" \"io/ioutil\" \"net/http\" \"os\")func main() &#123; resp, err := http.Get(\"http://www.baidu.com\") check(err) body, err := ioutil.ReadAll(resp.Body) check(err) fmt.Println(len(body))&#125;func check(err error) &#123; if err != nil &#123; fmt.Println(err) os.Exit(1) &#125;&#125; Dockerizebasic image 1FROM golang:onbuild compile Dockerfile 123456FROM golang:latest RUN mkdir /app ADD . /app/ WORKDIR /app RUN go build -o main . CMD [\"/app/main\"] 这个构建出来需要500M 因为 golang:latest 是从 Debian Jessie 构建出来的, 底层是操作系统, so 导致镜像特别大. Compile!! 先编译工程 构建镜像 12go build -o main .docker build -t example-scratch:v1 -f Dockerfile.scratch . Dockerfile.scratch 内容:123FROM scratchADD main /CMD [\"/main\"] 这样构建是无法工作的, 原因就在于生产的 main 是需要系统的动态链接库. 12$ docker run -it example-scratch:v1standard_init_linux.go:178: exec user process caused \"exec format error\" 解决方法: 1CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main . 禁用cgo，生产一个静态二进制文件, 我们还将操作系统设置为Linux, -a标志意味着重建我们正在使用的所有软件包，这意味着所有导入都将在cgo禁用的情况下重建。 123$ docker build -t example-scratch:v2 -f Dockerfile.scratch .$ docker run -it example-scratch:v2 118146 # it work","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"docker app","slug":"docker-app","permalink":"http://yoursite.com/tags/docker-app/"}]},{"title":"basic css learn - 1. css display grid","slug":"frontend/css/basic_1_0_css_position","date":"2018-08-29T14:03:33.251Z","updated":"2018-08-29T14:47:49.268Z","comments":true,"path":"2018/08/29/frontend/css/basic_1_0_css_position/","link":"","permalink":"http://yoursite.com/2018/08/29/frontend/css/basic_1_0_css_position/","excerpt":"","text":"参考: https://atomiks.github.io/30-seconds-of-css/","categories":[{"name":"frontend","slug":"frontend","permalink":"http://yoursite.com/categories/frontend/"}],"tags":[{"name":"css","slug":"css","permalink":"http://yoursite.com/tags/css/"},{"name":"css grid","slug":"css-grid","permalink":"http://yoursite.com/tags/css-grid/"}]},{"title":"动态规划题集","slug":"alg/DynamicProgramming/题集","date":"2018-08-29T13:18:44.000Z","updated":"2018-08-29T13:20:52.368Z","comments":true,"path":"2018/08/29/alg/DynamicProgramming/题集/","link":"","permalink":"http://yoursite.com/2018/08/29/alg/DynamicProgramming/题集/","excerpt":"","text":"摘录：https://www.geeksforgeeks.org/dynamic-programming/ ‘Recent Articles’ on Dynamic Programming Topics: Basic Concepts Advanced Concepts Basic Problems Intermediate Problems Hard Problems Quick Links Basic Concepts: Overlapping Subproblems Property Optimal Substructure Property How to solve a Dynamic Programming Problem ? Tabulation vs Memoizatation Advanced Concepts : Bitmasking and Dynamic Programming | Set 1 Digit DP | Introduction Basic Problems : &nbsp;&nbsp; Fibonacci numbers &nbsp;&nbsp; Binomial Coefficient &nbsp;&nbsp; Longest Common Subsequence &nbsp;&nbsp; Longest Repeated Subsequence &nbsp;&nbsp; Largest Sum Contiguous Subarray &nbsp;&nbsp; Ugly numbers &nbsp;&nbsp; Maximum size square sub-matrix with all 1s &nbsp;&nbsp; Longest Increasing Subsequence &nbsp;&nbsp; Min Cost Path &nbsp;&nbsp; Coin change problem &nbsp;&nbsp; Minimum number of edits ( operations ) require to convert string 1 to string 2 &nbsp;&nbsp; Cutting a Rod &nbsp;&nbsp; Subset Sum Problem &nbsp;&nbsp; Minimum number of jumps to reach end &nbsp;&nbsp; Assembly line scheduling &nbsp;&nbsp; Maximum Sum Increasing Subsequence &nbsp;&nbsp; Maximum Length Chain of Pairs &nbsp;&nbsp; Longest Common Substring &nbsp;&nbsp; Count all possible paths from top left to bottom right of a mXn matrix &nbsp;&nbsp; nth Catalan Number &nbsp;&nbsp; Count number of ways to reach a given score in a game &nbsp;&nbsp; Tiling Problem &nbsp;&nbsp; Count even length binary sequences with same sum of first and second half bits &nbsp;&nbsp; Find number of solutions of a linear equation of n variables &nbsp;&nbsp; Bell Numbers (Number of ways to Partition a Set) &nbsp;&nbsp; Compute nCr % p &nbsp;&nbsp; Permutation Coefficient &nbsp;&nbsp; Count number of ways to fill a “n x 4” grid using “1 x 4” tiles &nbsp;&nbsp; A Space Optimized Solution of LCS &nbsp;&nbsp; Find maximum length Snake sequence &nbsp;&nbsp; Minimum cost to fill given weight in a bag &nbsp;&nbsp; Choice of area &nbsp;&nbsp; Maximum weight path ending at any element of last row in a matrix &nbsp;&nbsp; Recursively break a number in 3 parts to get maximum sum &nbsp;&nbsp; Path with maximum average value &nbsp;&nbsp; Maximum sum of pairs with specific difference &nbsp;&nbsp; Maximum subsequence sum such that no three are consecutive &nbsp;&nbsp; Longest subsequence such that difference between adjacents is one &nbsp;&nbsp; Maximum path sum for each position with jumps under divisibility condition &nbsp;&nbsp; Maximum sum Bi-tonic Sub-sequence &nbsp;&nbsp; LCS (Longest Common Subsequence) of three strings &nbsp;&nbsp; Maximum path sum in a triangle &nbsp;&nbsp; Friends Pairing Problem &nbsp;&nbsp; Size of array after repeated deletion of LIS &nbsp;&nbsp; Minimum steps to minimize n as per given condition &nbsp;&nbsp; Maximum path sum that starting with any cell of 0-th row and ending with any cell of (N-1)-th row &nbsp;&nbsp; Gold Mine Problem &nbsp;&nbsp; Find number of endless points &nbsp;&nbsp; Perfect Sum Problem (Print all subsets with given sum) &nbsp;&nbsp; Maximum sum of a path in a Right Number Triangle &nbsp;&nbsp; Subset with sum divisible by m Intermediate Problems : &nbsp;&nbsp; 0-1 Knapsack Problem &nbsp;&nbsp; Length of the longest substring without repeating characters &nbsp;&nbsp; Count number of ways to reach destination in a Maze &nbsp;&nbsp; Super Ugly Number (Number whose prime factors are in given set) &nbsp;&nbsp; Count number of ways to partition a set into k subsets &nbsp;&nbsp; Longest Palindromic Subsequence &nbsp;&nbsp; Egg Dropping Puzzle &nbsp;&nbsp; Weighted job scheduling &nbsp;&nbsp; Longest Bitonic Subsequence &nbsp;&nbsp; Floyd Warshall Algorithm &nbsp;&nbsp; Partition Problem &nbsp;&nbsp; Variations of LIS &nbsp;&nbsp; Box-Stacking Problem &nbsp;&nbsp; Bellman–Ford Algorithm &nbsp;&nbsp; Optimal Binary Search Tree &nbsp;&nbsp; Largest Independent Set Problem &nbsp;&nbsp; Minimum insertions to form a palindrome &nbsp;&nbsp; Minimum number of deletions to make a string palindrome &nbsp;&nbsp; Maximum Product Cutting &nbsp;&nbsp; Clustering/Partitioning an array such that sum of square differences is minimum &nbsp;&nbsp; Maximum decimal value path in a binary matrix &nbsp;&nbsp; Count Derangements (Permutation such that no element appears in its original position) &nbsp;&nbsp; Dice Throw Problem &nbsp;&nbsp; Optimal Strategy for a game &nbsp;&nbsp; Word Break Problem &nbsp;&nbsp; Remove minimum elements from either side such that 2*min becomes more than max &nbsp;&nbsp; Count number of binary strings without consecutive 1’s &nbsp;&nbsp; Count Possible Decodings of a given Digit Sequence &nbsp;&nbsp; Count all possible walks from a source to a destination with exactly k edges &nbsp;&nbsp; Shortest path with exactly k edges in a directed and weighted graph &nbsp;&nbsp; Longest Even Length Substring such that Sum of First and Second Half is same &nbsp;&nbsp; Vertex Cover Problem &nbsp;&nbsp; Find the minimum cost to reach destination using a train &nbsp;&nbsp; Maximum profit by buying and selling a share at most twice &nbsp;&nbsp; Count possible ways to construct buildings &nbsp;&nbsp; Compute sum of digits in all numbers from 1 to n &nbsp;&nbsp; Shortest Common Supersequence &nbsp;&nbsp; Minimum number of coins that make a given value &nbsp;&nbsp; Minimum number of squares whose sum equals to given number n &nbsp;&nbsp; length of the longest consecutive path from a given starting character &nbsp;&nbsp; Total number of non-decreasing numbers with n digits &nbsp;&nbsp; Minimum Initial Points to Reach Destination &nbsp;&nbsp; Count of n digit numbers whose sum of digits equals to given sum &nbsp;&nbsp; Count total number of N digit numbers such that the difference between sum of even and odd digits is 1 &nbsp;&nbsp; Count ways to assign unique cap to every person &nbsp;&nbsp; Longest Repeating Subsequence &nbsp;&nbsp; Find the longest path in a matrix with given constraints &nbsp;&nbsp; Number of paths with exactly k coins &nbsp;&nbsp; Collect maximum coins before hitting a dead end &nbsp;&nbsp; Count number of paths with at-most k turns &nbsp;&nbsp; Partition a set into two subsets such that the difference of subset sums is minimum &nbsp;&nbsp; Longest Zig-Zag Subsequence &nbsp;&nbsp; Largest sum Zigzag sequence in a matrix &nbsp;&nbsp; Count number of subsets having a particular XOR value &nbsp;&nbsp; Weighted Job Scheduling in O(n Log n) time &nbsp;&nbsp; Ways to arrange Balls such that adjacent balls are of different types &nbsp;&nbsp; Minimum time to finish tasks without skipping two consecutive &nbsp;&nbsp; Find if string is K-Palindrome or not | Set 1 &nbsp;&nbsp; Find if string is K-Palindrome or not | Set 2 &nbsp;&nbsp; Wildcard Pattern Matching &nbsp;&nbsp; Longest Common Increasing Subsequence (LCS + LIS) &nbsp;&nbsp; Printing Longest Common Subsequence | Set 2 (Printing All) &nbsp;&nbsp; High-effort vs. Low-effort Tasks Problem &nbsp;&nbsp; Find minimum adjustment cost of an array &nbsp;&nbsp; Find Jobs involved in Weighted Job Scheduling &nbsp;&nbsp; Minimum Cost To Make Two Strings Identical &nbsp;&nbsp; Find number of times a string occurs as a subsequence in given string &nbsp;&nbsp; Count digit groupings of a number with given constraints &nbsp;&nbsp; Non-crossing lines to connect points in a circle &nbsp;&nbsp; Count Distinct Subsequences &nbsp;&nbsp; Find minimum sum such that one of every three consecutive elements is taken &nbsp;&nbsp; Count distinct occurrences as a subsequence &nbsp;&nbsp; Number of permutation with K inversions &nbsp;&nbsp; Print all longest common sub-sequences in lexicographical order &nbsp;&nbsp; Find all distinct subset (or subsequence) sums of an array &nbsp;&nbsp; Count All Palindromic Subsequence in a given String &nbsp;&nbsp; Maximum sum alternating subsequence &nbsp;&nbsp; Sum of average of all subsets &nbsp;&nbsp; Minimum and Maximum values of an expression with * and + &nbsp;&nbsp; Minimum sum subsequence such that at least one of every four consecutive elements is picked &nbsp;&nbsp; Ways to write n as sum of two or more positive integers &nbsp;&nbsp; Unbounded Knapsack (Repetition of items allowed) &nbsp;&nbsp; Finding the maximum square sub-matrix with all equal elements &nbsp;&nbsp; Find Maximum dot product of two arrays with insertion of 0’s &nbsp;&nbsp; Maximum points collected by two persons allowed to meet once &nbsp;&nbsp; Minimum Sum Path In 3-D Array &nbsp;&nbsp; Count binary strings with k times appearing adjacent two set bits &nbsp;&nbsp; Highway Billboard Problem &nbsp;&nbsp; Probability of getting at least K heads in N tosses of Coins &nbsp;&nbsp; Count of strings that can be formed using a, b and c under given constraints &nbsp;&nbsp; Modify array to maximize sum of adjacent differences &nbsp;&nbsp; Temple Offerings &nbsp;&nbsp; Longest alternating subsequence &nbsp;&nbsp; Minimum steps to delete a string after repeated deletion of palindrome substrings &nbsp;&nbsp; Minimum number of deletions to make a sorted sequence &nbsp;&nbsp; Count number of ways to jump to reach end &nbsp;&nbsp; Shortest Uncommon Subsequence &nbsp;&nbsp; Minimum insertions to sort an array &nbsp;&nbsp; Dynamic Programming | Building Bridges &nbsp;&nbsp; Check if any valid sequence is divisible by M &nbsp;&nbsp; Rencontres Number Hard Problems : &nbsp;&nbsp; Palindrome Partitioning &nbsp;&nbsp; Word Wrap Problem &nbsp;&nbsp; Maximum sum rectangle in a 2D matrix &nbsp;&nbsp; Matrix Chain Multiplication &nbsp;&nbsp; Longest Geometric Progression &nbsp;&nbsp; Find all combinations of k-bit numbers with n bits set where 1 &lt;= n &lt;= k in sorted order &nbsp;&nbsp; Find if a string is interleaved of two other strings &nbsp;&nbsp; Longest Arithmetic Progression &nbsp;&nbsp; Boolean Parenthesization Problem &nbsp;&nbsp; Mobile Numeric Keypad Problem &nbsp;&nbsp; Minimum Cost Polygon Triangulation &nbsp;&nbsp; How to print maximum number of A’s using given four keys &nbsp;&nbsp; Smallest length string with repeated replacement of two distinct adjacent &nbsp;&nbsp; Collect maximum points in a grid using two traversals &nbsp;&nbsp; Maximum weight transformation of a given string &nbsp;&nbsp; Find minimum possible size of array with given rules for removing elements &nbsp;&nbsp; Maximum profit by buying and selling a share at most k times &nbsp;&nbsp; Number of subsequences in a string divisible by n &nbsp;&nbsp; Maximize arr[j] – arr[i] + arr[l] – arr[k], such that i &lt; j &lt; k &lt; l &nbsp;&nbsp; A Space Optimized DP solution for 0-1 Knapsack Problem &nbsp;&nbsp; Longest repeating and non-overlapping substring &nbsp;&nbsp; All ways to add parenthesis for evaluation &nbsp;&nbsp; Number of palindromic paths in a matrix &nbsp;&nbsp; Minimum cost to sort strings using reversal operations of different costs &nbsp;&nbsp; Minimum number of elements which are not part of Increasing or decreasing subsequence in array &nbsp;&nbsp; Printing brackets in Matrix Chain Multiplication Problem &nbsp;&nbsp; Check if all people can vote on two machines &nbsp;&nbsp; Probability of Knight to remain in the chessboard &nbsp;&nbsp; Count of AP (Arithmetic Progression) Subsequences in an array &nbsp;&nbsp; Number of subsequences of the form a^i b^j c^k &nbsp;&nbsp; Count ways to increase LCS length of two strings by one &nbsp;&nbsp; Count of arrays in which all adjacent elements are such that one of them divide the another &nbsp;&nbsp; Dynamic Programming on Trees &nbsp;&nbsp; Check whether row or column swaps produce maximum size binary sub-matrix with all 1s","categories":[{"name":"alg","slug":"alg","permalink":"http://yoursite.com/categories/alg/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"},{"name":"题集","slug":"题集","permalink":"http://yoursite.com/tags/题集/"}]},{"title":"Program for Fibonacci numbers","slug":"alg/DynamicProgramming/1_1_Fibonacci numbers","date":"2018-08-29T13:18:44.000Z","updated":"2018-08-29T13:20:49.056Z","comments":true,"path":"2018/08/29/alg/DynamicProgramming/1_1_Fibonacci numbers/","link":"","permalink":"http://yoursite.com/2018/08/29/alg/DynamicProgramming/1_1_Fibonacci numbers/","excerpt":"","text":"来源：https://www.cdn.geeksforgeeks.org/program-for-nth-fibonacci-number/ The Fibonacci numbers are the numbers in the following integer sequence. 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, …….. In mathematical terms, the sequence Fn of Fibonacci numbers is defined by the recurrence relation 1Fn = Fn-1 + Fn-2 with seed values 1F0 = 0 and F1 = 1. Given a number n, print n-th Fibonacci Number. 12345Input : n = 2Output : 1Input : n = 9Output : 34","categories":[{"name":"alg","slug":"alg","permalink":"http://yoursite.com/categories/alg/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}]},{"title":"动态规划","slug":"alg/DynamicProgramming/动态规划总结","date":"2018-08-29T13:18:44.000Z","updated":"2018-08-29T13:20:51.386Z","comments":true,"path":"2018/08/29/alg/DynamicProgramming/动态规划总结/","link":"","permalink":"http://yoursite.com/2018/08/29/alg/DynamicProgramming/动态规划总结/","excerpt":"","text":"动态规划求解的一般思路： 判断问题的子结构（也可看作状态），当具有最优子结构时，动态规划可能适用。 求解重叠子问题。一个递归算法不断地调用同一问题，递归可以转化为查表从而利用子问题的解。分治法则不同，每次递归都产生新的问题。 重新构造一个最优解。 最优子结构?","categories":[{"name":"alg","slug":"alg","permalink":"http://yoursite.com/categories/alg/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}]},{"title":"supervisor 使用","slug":"devops/supervisor_learn","date":"2018-08-29T13:15:52.434Z","updated":"2018-08-29T13:30:56.403Z","comments":true,"path":"2018/08/29/devops/supervisor_learn/","link":"","permalink":"http://yoursite.com/2018/08/29/devops/supervisor_learn/","excerpt":"","text":"install1apt-get install -y supervisor 启动命令1/usr/bin/python /usr/bin/supervisord -c /etc/supervisor/supervisord.conf 配置安装完后的默认配置 /etc/supervisor/supervisord.conf 1234567891011121314151617181920212223242526272829; supervisor config file[unix_http_server]file=/var/run/supervisor.sock ; (the path to the socket file)chmod=0700 ; sockef file mode (default 0700)[supervisord]logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log)pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)childlogdir=/var/log/supervisor ; (&apos;AUTO&apos; child log dir, default $TEMP)environment=IPADDRESS=&quot;172.16.6.6&quot;, HOST_NAME=&quot;i-nom0vro7&quot;; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///var/run/supervisor.sock ; use a unix:// URL for a unix socket; The [include] section can just contain the &quot;files&quot; setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.[include]files = /etc/supervisor/conf.d/*.conf 需要监控的进程 consul 微服务守护进程 coupon_web 守护进程 coupon_gateway 守护进程 coupon_trig 守护进程 coupon_bot 守护进程 配置如下: (在 conf.d 目录下) consul 守护进程:1234567891011[program:consul] ; 程序名称，在 supervisorctl 中通过这个值来对程序进行一系列的操作autorestart=True ; 程序异常退出后自动重启autostart=True ; 在 supervisord 启动的时候也自动启动redirect_stderr=True ; 把 stderr 重定向到 stdout，默认 falsecommand=consul agent -data-dir /data/consul -node=common-conpous.0.13 -bind=172.16.0.13 -join=172.16.0.210 1&gt;/data/logs/out.log 2&gt;&amp;1 ; 启动命令，与手动在命令行启动的命令是一样的user=root ; 用哪个用户启动directory=/data/caiqiu ; 程序的启动目录stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/logs/supervisord_consul.log coupon_web 守护进程:1234567891011[program:coupon_web] ; 程序名称，在 supervisorctl 中通过这个值来对程序进行一系列的操作autorestart=True ; 程序异常退出后自动重启autostart=True ; 在 supervisord 启动的时候也自动启动redirect_stderr=True ; 把 stderr 重定向到 stdout，默认 falsecommand=java -jar -Xms512m -Xmx1024m /data/common-coupon/aries-coupon-web-1.0.0-SNAPSHOT.jar --server.port=8080 --server.address=172.16.0.13 --spring.profiles.active=dev --server.tomcat.max-thread=500user=root ; 用哪个用户启动directory=/data/caiqiu ; 程序的启动目录stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/data/logs/supervisord_coupon_web.log coupon_gateway 守护进程:1234567891011[program:coupon_gateway] ; 程序名称，在 supervisorctl 中通过这个值来对程序进行一系列的操作autorestart=True ; 程序异常退出后自动重启autostart=True ; 在 supervisord 启动的时候也自动启动redirect_stderr=True ; 把 stderr 重定向到 stdout，默认 falsecommand=java -jar -Xms512m -Xmx1024m /data/common-coupon/aries-coupon-gateway-1.0.0-SNAPSHOT.jar --server.port=9090 --server.address=172.16.0.13 --spring.profiles.active=dev --server.tomcat.max-thread=500user=root ; 用哪个用户启动directory=/data/caiqiu ; 程序的启动目录stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/data/logs/supervisord_coupon_gateway.log coupon_trig 守护进程:1234567891011[program:coupon_trig] ; 程序名称，在 supervisorctl 中通过这个值来对程序进行一系列的操作autorestart=True ; 程序异常退出后自动重启autostart=True ; 在 supervisord 启动的时候也自动启动redirect_stderr=True ; 把 stderr 重定向到 stdout，默认 falsecommand=java -jar -Xms512m -Xmx1024m /data/common-coupon/aries-coupon-trig-1.0.0-SNAPSHOT.jar --server.port=8090 --server.address=172.16.0.13 --spring.profiles.active=dev --server.tomcat.max-thread=500user=root ; 用哪个用户启动directory=/data/caiqiu ; 程序的启动目录stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/data/logs/supervisord_coupon_trig.log coupon_bot 守护进程:1234567891011[program:coupon_bot] ; 程序名称，在 supervisorctl 中通过这个值来对程序进行一系列的操作autorestart=True ; 程序异常退出后自动重启autostart=True ; 在 supervisord 启动的时候也自动启动redirect_stderr=True ; 把 stderr 重定向到 stdout，默认 falsecommand=java -jar -Xms512m -Xmx1024m /data/common-coupon/aries-coupon-bot-1.0.0-SNAPSHOT.jar --spring.profiles.active=dev --server.tomcat.max-thread=500user=root ; 用哪个用户启动directory=/data/caiqiu ; 程序的启动目录stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/data/logs/supervisord_coupon_bot.log supervisorctl 命令123456789101112supervisorctl status # 查看 supervisorctl 的状态# account_gateway RUNNING pid 22892, uptime 1 day, 19:17:42# account_web RUNNING pid 22912, uptime 1 day, 19:17:41# consul RUNNING pid 22849, uptime 1 day, 19:17:51supervisorctl reload # 重新载入 supervisorctl 配置, 并且使其生效supervisorctl help # 帮助文档# default commands (type help &lt;topic&gt;):# =====================================# add clear fg open quit remove restart start stop update# avail exit maintail pid reload reread shutdown status tail version","categories":[{"name":"devops","slug":"devops","permalink":"http://yoursite.com/categories/devops/"}],"tags":[{"name":"supervisor","slug":"supervisor","permalink":"http://yoursite.com/tags/supervisor/"}]},{"title":"Lombok原理分析与功能实现","slug":"backend/java/Lombok原理分析与功能实现","date":"2018-08-29T13:14:48.231Z","updated":"2018-08-29T13:26:00.740Z","comments":true,"path":"2018/08/29/backend/java/Lombok原理分析与功能实现/","link":"","permalink":"http://yoursite.com/2018/08/29/backend/java/Lombok原理分析与功能实现/","excerpt":"","text":"参考：https://blog.mythsman.com/2017/12/19/1/ 原理 定义编译期的注解 利用JSR269 api(Pluggable Annotation Processing API )创建编译期的注解处理器 利用tools.jar的javac api处理AST(抽象语法树) 将功能注册进jar包 基础点 注解 JSR269 api javac api处理AST 手撸Getter实验的目的是自定义一个针对类的Getter注解，它能够读取该类的成员方法并自动生成getter方法。 创建Getter注解1234567891011package laboratory.lombokLearn;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface Getter &#123;&#125; 创建Getter注解的处理器基本框架123456789101112131415161718192021package laboratory.lombokLearn;import javax.annotation.processing.*;import javax.lang.model.SourceVersion;import javax.lang.model.element.TypeElement;import java.util.Set;@SupportedAnnotationTypes(\"laboratory.lombokLearn.Getter\")@SupportedSourceVersion(SourceVersion.RELEASE_8)public class GetterProcessor extends AbstractProcessor &#123; @Override public synchronized void init(ProcessingEnvironment processingEnv) &#123; super.init(processingEnv); &#125; @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) &#123; return true; &#125;&#125; 然后需要着重实现两个方法，init跟process。init的主要用途是通过ProcessingEnvironment来获取编译阶段的一些环境信息;process主要是实现具体逻辑的地方，也就是对AST进行处理的地方。 init 方法1234567891011121314private Messager messager;private JavacTrees trees;private TreeMaker treeMaker;private Names names;@Overridepublic synchronized void init(ProcessingEnvironment processingEnv) &#123; super.init(processingEnv); this.messager = processingEnv.getMessager(); this.trees = JavacTrees.instance(processingEnv); Context context = ((JavacProcessingEnvironment) processingEnv).getContext(); this.treeMaker = TreeMaker.instance(context); this.names = Names.instance(context);&#125; Messager主要是用来在编译期打log用的 JavacTrees提供了待处理的抽象语法树 TreeMaker封装了创建AST节点的一些方法 Names提供了创建标识符的方法 PROCESS方法步骤大概是下面这样： 利用roundEnv的getElementsAnnotatedWith方法过滤出被Getter这个注解标记的类，并存入set 遍历这个set里的每一个元素，并生成jCTree这个语法树 创建一个TreeTranslator，并重写其中的visitClassDef方法，这个方法处理遍历语法树得到的类定义部分jcClassDecl 创建一个jcVariableDeclList保存类的成员变量遍历jcTree的所有成员(包括成员变量和成员函数和构造函数)，过滤出其中的成员变量，并添加进jcVariableDeclList将jcVariableDeclList的所有变量转换成需要添加的getter方法，并添加进jcClassDecl的成员中调用默认的遍历方法遍历处理后的jcClassDecl 利用上面的TreeTranslator去处理jcTree summary (answer question)1. 注解的理解12@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.SOURCE) 这个是编译时运行的注解，其实我更加想知道运行时的注解，如何运作的。 2. JSR269 api 是啥？Pluggable Annotation Processing API（注解处理器） 3. AST what？1private JavacTrees trees; 这个就是语法树 1jcTree.accept(） 为类增加方法 运行时的注解我研究一下@Cacheable注解吧","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"lombok","slug":"lombok","permalink":"http://yoursite.com/tags/lombok/"},{"name":"原理","slug":"原理","permalink":"http://yoursite.com/tags/原理/"}]},{"title":"spring aop 切向编程","slug":"backend/java/spring_aop","date":"2018-08-29T13:14:48.231Z","updated":"2018-08-29T13:26:45.498Z","comments":true,"path":"2018/08/29/backend/java/spring_aop/","link":"","permalink":"http://yoursite.com/2018/08/29/backend/java/spring_aop/","excerpt":"","text":"概览 什么是切向编程？ 切向编程的好处 spring aop的使用 spring中类似于@Cacheable的实现 重点讲3和4 什么是切向编程？自己的理解：在一个方法前后执行某段特定功能的代码 切向编程的好处举两个例子： web应用中，需要打印接口传入的params and return result，就需要在接口前后加上log。 将数据库查询出的数据缓存到redis中（类似于@Cacheable）。 spring aop的使用关键点： 声明切面类，使用@Aspect并将类注册到IOC容器中@Component 定义切点：@Pointcut(&quot;execution(public * laboratory.controller..*.*(..))&quot;) 定义执行方法：@Before(&quot;webLog()&quot;) 切点类型@Pointcut(value = &quot;&quot;)value的类型：TOTO: 总结value类型 完整代码WebLogAspect： 1234567891011121314151617181920212223242526272829303132333435363738394041package laboratory.aop;import com.alibaba.fastjson.JSON;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;@Aspect // 1. 声明切面类@Componentpublic class WebLogAspect &#123; @Pointcut(\"execution(public * laboratory.controller..*.*(..))\") // 2. 定义切点 public void webLog()&#123; &#125; @Before(\"webLog()\") // 3. 定义执行方法 public void doBefore(JoinPoint joinPoint) &#123; // 接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // 记录下请求内容// logger.info(\"URL : \" + request.getRequestURL().toString());// logger.info(\"HTTP_METHOD : \" + request.getMethod());// logger.info(\"IP : \" + request.getRemoteAddr());// logger.info(\"CLASS_METHOD : \" + joinPoint.getSignature().getDeclaringTypeName() + \".\" + joinPoint.getSignature().getName());// logger.info(\"ARGS : \" + Arrays.toString(joinPoint.getArgs())); &#125; @AfterReturning(returning = \"ret\", pointcut = \"webLog()\") //3. 定义执行方法 public void doAfterReturning(Object ret) &#123; System.out.println(\"resp: \" + JSON.toJSONString(ret)); &#125;&#125; FirstCache:123456789101112131415161718192021222324252627282930313233343536package laboratory.aop;import laboratory.annotation.FirstCacheAno;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.stereotype.Component;@Aspect@Componentpublic class FirstCache &#123; @Pointcut(\"@annotation(laboratory.annotation.FirstCacheAno)\") public void firstCache() &#123; &#125; @Around(\"firstCache()\") public Object aroundFirstCache(ProceedingJoinPoint proceedingJoinPoint) &#123; System.out.println(\"aroundFirstCache after....\"); MethodSignature signature = (MethodSignature) proceedingJoinPoint.getSignature(); FirstCacheAno firstCache = signature.getMethod().getAnnotation(FirstCacheAno.class); System.out.println(\"firstCache cacheName: \" + firstCache.cacheName()); System.out.println(\"firstCache unless: \" + firstCache.unless()); Object ret = null; try &#123; ret = proceedingJoinPoint.proceed(); System.out.println(ret); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; System.out.println(\"aroundFirstCache end....\"); return ret; &#125;&#125;","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"spring aop","slug":"spring-aop","permalink":"http://yoursite.com/tags/spring-aop/"}]},{"title":"搭建自己的私有网络","slug":"block_chain/搭建自己的私有网络","date":"2018-08-29T13:14:48.228Z","updated":"2018-08-29T13:24:21.195Z","comments":true,"path":"2018/08/29/block_chain/搭建自己的私有网络/","link":"","permalink":"http://yoursite.com/2018/08/29/block_chain/搭建自己的私有网络/","excerpt":"","text":"目标 创建私有的以太网 在私有网部署一个简单的智能合约 使用该公约发起交易 注意事项： 机子内存要2G及以上 setp1: 安装环境记录坑：通过 apt-get install geth 安装的环境只有 geth 命令，无 bootnode, evm, disasm, rlpdump, ethtest这些命令。 Ubuntu安装方式：1234sudo apt-get install software-properties-commonsudo add-apt-repository -y ppa:ethereum/ethereumsudo apt-get updatesudo apt-get install ethereum 可以选择源码安装：(前提是需要 golang &gt; 1.7)123git clone https://github.com/ethereum/go-ethereumcd go-ethereummake geth step2: 创建创世块创世块是区块链的第一个块并且参数被指定在genesis.json文件中，内容如下：12345678910111213141516171819202122&#123;\"config\": &#123; \"chainId\": 15, \"homesteadBlock\": 0, \"eip155Block\": 0, \"eip158Block\": 0 &#125;, \"alloc\" : &#123; \"0x0000000000000000000000000000000000000001\": &#123;\"balance\": \"111111111\"&#125;, \"0x0000000000000000000000000000000000000002\": &#123;\"balance\": \"222222222\"&#125; &#125;, \"coinbase\" : \"0x0000000000000000000000000000000000000000\", \"difficulty\" : \"0x00001\", \"extraData\" : \"\", \"gasLimit\" : \"0x2fefd8\", \"nonce\" : \"0x0000000000000107\", \"mixhash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"timestamp\" : \"0x00\"&#125; 注意： chainId=1 指向的是以太坊的主链上。因此为您的网络创建唯一的chainId非常重要，这样您的客户端就不会混淆私有区块链和主网络.为了说明和测试，将采矿难度(difficulty)设置为较低值。还要确保你指定一个唯一的随机数来开始(nonce)。alloc字段允许您使用Ether预先填充帐户。现在到您创建的genesis.json文件的目录并初始化bootnode节点，您的以太坊客户端可通过该节点加入您的专用网络并与连接到您的专用网络的其他节点进行交互。 1234cd /root/ucsfnet/datageth --datadir=learn init genesis.json bootnode --genkey=boot.key bootnode --nodekey=boot.key 没有bootnode的原因：see step1 step3: 连接到bootnode上开一个新终端：12ssh root@101.102.103.104geth --datadir=/root/ucsfnet/data --bootnodes=enode://148f3....@101.102.103.104:3031 将148f3....替换为 step2 生成的12$ bootnode --nodekey=boot.keyINFO [03-14|16:30:33] UDP listener up self=enode://c591c837ff804c4bdb6a5a8d02e5343d5f96fbf6e198aaf05f91aeb0a9b781e3b6fb95124ac8e4ee1b99ca64df2c93052c54bc02ee1dada70d38bd4a956d4ac4@[::]:30301 step4: 创建一个新账号并查询余额新开一个终端：1geth attach /root/ucsfnet/data/geth.ipc 连接到网络中：查看有哪些账户, 创建一个新账号密码为：mypassword , 查询用户余额12345678&gt; eth.accounts[]&gt; personal.newAccount(\"mypassword\")\"0x73c62b30d6dbe998313384f1c98528c1d372b075\"&gt; web3.fromWei(eth.getBalance(eth.accounts\\[0\\]), \"ether\")0 那个0x打头的就是账户地址：0x73c62b30d6dbe998313384f1c98528c1d372b075 step5: 在私链上挖矿挖矿有2目的： 需要为矿工的算力，提供gas 采矿需要将你的交易写到区块链中 1geth --datadir=/root/ucsfnet/data --mine --minerthreads=1 --etherbase=0x... etherbase 参数应该是step4中的钱包地址开始挖矿后会有一段时间加载数据，耗CPU比较严重。 step6: 开发一个简单的智能合约首先需要安装编译器：123sudo add-apt-repository ppa:ethereum/ethereumsudo apt-get updatesudo apt-get install solc 其次，创建合约，并命名为 greeter.sol 1234567891011121314151617181920212223242526contract mortal &#123;/* Define variable owner of the type address*/ address owner;/* this function is executed at initialization and sets the owner of the contract */ function mortal() &#123; owner = msg.sender; &#125;/* Function to recover the funds on the contract */ function kill() &#123; if (msg.sender == owner) selfdestruct(owner); &#125;&#125;contract greeter is mortal &#123; /* define variable greeting of the type string */ string greeting;/* this runs when the contract is executed */ function greeter(string _greeting) public &#123; greeting = &quot;UCSFnet lives!&quot;; &#125;/* main function */ function greet() constant returns (string) &#123; return greeting; &#125;&#125; 编译合约：12345solc --bin --abi -o /root/test /root/test/greeter.sol## 输出文件$ lsgreeter.abi greeter.bin greeter.sol mortal.abi mortal.bin 在编译命令行中， --bin --abi 是分别生成 EVM（Ethereum Virtual Machine：以太坊虚拟机）字节码 和 ABI（Application Binary Inferface：应用二进制接口）文件。 -o 指定生成后存放的路径 合约内容先不研究 step7: 部署GREETER合约到私网12345678910111213141516171819202122232425262728293031323334353637383940var _greeting = 'Jie lives!';var browser_ballot_sol_greeterContract = web3.eth.contract([&#123; \"constant\": false, \"inputs\": [], \"name\": \"kill\", \"outputs\": [], \"payable\": false, \"type\": \"function\"&#125;, &#123; \"constant\": true, \"inputs\": [], \"name\": \"greet\", \"outputs\": [&#123;\"name\": \"\", \"type\": \"string\"&#125;], \"payable\": false, \"type\": \"function\"&#125;, &#123;\"inputs\": [&#123;\"name\": \"_greeting\", \"type\": \"string\"&#125;], \"payable\": false, \"type\": \"constructor\"&#125;]);var browser_ballot_sol_greeter = browser_ballot_sol_greeterContract.new( _greeting, &#123; from: web3.eth.accounts[0], data: '0x6060604052341561000f57600080fd5b6040516103dd3803806103dd833981016040528080518201919050505b5b336000806101000a81548173ffffffffffffffffffffffffffffffffffffffff021916908373ffffffffffffffffffffffffffffffffffffffff1602179055505b6040805190810160405280600d81526020017f48656c6c6f2c20576f726c642100000000000000000000000000000000000000815250600190805190602001906100b99291906100c1565b505b50610166565b828054600181600116156101000203166002900490600052602060002090601f016020900481019282601f1061010257805160ff1916838001178555610130565b82800160010185558215610130579182015b8281111561012f578251825591602001919060010190610114565b5b50905061013d9190610141565b5090565b61016391905b8082111561015f576000816000905550600101610147565b5090565b90565b610268806101756000396000f30060606040526000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806341c0e1b514610049578063cfae32171461005e575b600080fd5b341561005457600080fd5b61005c6100ed565b005b341561006957600080fd5b61007161017f565b6040518080602001828103825283818151815260200191508051906020019080838360005b838110156100b25780820151818401525b602081019050610096565b50505050905090810190601f1680156100df5780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b6000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff163373ffffffffffffffffffffffffffffffffffffffff16141561017c576000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16ff5b5b565b610187610228565b60018054600181600116156101000203166002900480601f01602080910402602001604051908101604052809291908181526020018280546001816001161561010002031660029004801561021d5780601f106101f25761010080835404028352916020019161021d565b820191906000526020600020905b81548152906001019060200180831161020057829003601f168201915b505050505090505b90565b6020604051908101604052806000815250905600a165627a7a7230582069d50e4318daa30d3f74bb817c3b0cb732c4ec6a493eb108266c548906c8b6d70029', gas: '1000000' &#125;, function (e, contract) &#123; console.log(e, contract); if (typeof contract.address !== 'undefined') &#123; console.log('Contract mined! address: ' + contract.address + ' transactionHash: ' + contract.transactionHash); &#125; &#125;) 数据看着填吧，启动一个终端，连接到私链上1234ssh root@101.102.103.104 geth attach /root/ucsfnet/data/geth.ipc &gt; web3.fromWei(eth.getBalance(eth.accounts[0]), \"ether\")&gt; personal.unlockAccount(eth.accounts[0], \"mypassword\") 部署合约需要account上有余额，且account处于unlock状态下。使用下面的命令载入合约：1loadScript('myContract.js') 注意：需要有矿工挖矿保证交易被挖到将会得到如下内容：1Contract mined! address: 0xa76d017c3035dcf15e28b315477f3f19ae275433 transactionHash: 0x732e84efc03638767efc9a46738161c04d561a92cc2e631c63287e63ef38995b 这样合约就部署完成了 与合同的交换12345&gt; var abi = '[&#123;\"constant\":false,\"inputs\":[],\"name\":\"kill\",\"outputs\":[],\"payable\":false,\"type\":\"function\"&#125;,&#123;\"constant\":true,\"inputs\":[],\"name\":\"greet\",\"outputs\":[&#123;\"name\":\"\",\"type\":\"string\"&#125;],\"payable\":false,\"type\":\"function\"&#125;,&#123;\"inputs\":[&#123;\"name\":\"_greeting\",\"type\":\"string\"&#125;],\"payable\":false,\"type\":\"constructor\"&#125;]'&gt; var abi = JSON.parse(abi)&gt; var contract = web3.eth.contract(abi)&gt; var c = contract.at(\"0xa76d017c3035dcf15e28b315477f3f19ae275433\")&gt; c.greet() 会有一个输出：1UCSFnet lives! 我这输出的是：”Hello, World!” …. 博客推荐Nice low-level description of networking in Ethereum (uses the Python-based client): Setting up private network or local cluster Managing your accounts Connecting to the network The Go Ethereum client Official Ethereum command line tool documentation 参考（算是翻译）：How to create a private Ethereum network 下一个目标https://omarmetwally.blog/2017/09/27/how-to-connect-3-ethereum-nodes-in-a-private-ethereum-network/","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"blockchain","slug":"blockchain","permalink":"http://yoursite.com/tags/blockchain/"},{"name":"以太坊","slug":"以太坊","permalink":"http://yoursite.com/tags/以太坊/"}]},{"title":"Zombie T3","slug":"block_chain/contractLearn/Zombie_Con_Ch3","date":"2018-08-29T13:14:48.227Z","updated":"2018-08-29T13:23:37.173Z","comments":true,"path":"2018/08/29/block_chain/contractLearn/Zombie_Con_Ch3/","link":"","permalink":"http://yoursite.com/2018/08/29/block_chain/contractLearn/Zombie_Con_Ch3/","excerpt":"","text":"涉及内容：智能协议的所有权，Gas的花费，代码优化，和代码安全 ch1. 智能协议的永固性在你把智能协议传上以太坊之后，它就变得不可更改, 这种永固性意味着你的代码永远不能被调整或更新。 尽量不要写死代码 ch2. Ownable ContractsOpenZeppelin库的Ownable 合约：OpenZeppelin 是主打安保和社区审查的智能合约库，您可以在自己的 DApps中引用。 1234567891011121314151617181920212223242526272829303132333435/** * @title Ownable * @dev The Ownable contract has an owner address, and provides basic authorization control * functions, this simplifies the implementation of &quot;user permissions&quot;. */contract Ownable &#123; address public owner; event OwnershipTransferred(address indexed previousOwner, address indexed newOwner); /** * @dev The Ownable constructor sets the original `owner` of the contract to the sender * account. */ function Ownable() public &#123; owner = msg.sender; &#125; /** * @dev Throws if called by any account other than the owner. */ modifier onlyOwner() &#123; require(msg.sender == owner); _; &#125; /** * @dev Allows the current owner to transfer control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function transferOwnership(address newOwner) public onlyOwner &#123; require(newOwner != address(0)); OwnershipTransferred(owner, newOwner); owner = newOwner; &#125;&#125; 构造函数: function Ownable() 是一个 constructor (构造函数)，构造函数不是必须的，它与合约同名，构造函数一生中唯一的一次执行，就是在合约最初被创建的时候。 函数修饰符：modifier onlyOwner() 修饰符跟函数很类似，不过是用来修饰其他已有函数用的， 在其他语句执行前，为它检查下先验条件。_; 类似于 ruby 中的 yield 所以Ownable合约基本都会这么干： 合约创建，构造函数先行，将其 owner 设置为msg.sender（其部署者） 为它加上一个修饰符 onlyOwner，它会限制陌生人的访问，将访问某些函数的权限锁定在 owner 上。 允许将合约所有权转让给他人。 ch4. Gas重要概念： Gas - 驱动以太坊DApps的能源 在 Solidity 中，你的用户想要每次执行你的 DApp 都需要支付一定的 gas，gas 可以用以太币购买，因此，用户每次跑 DApp 都得花费以太币。 一个 DApp 收取多少 gas 取决于功能逻辑的复杂程度。每个操作背后，都在计算完成这个操作所需要的计算资源，（比如，存储数据就比做个加法运算贵得多）， 一次操作所需要花费的 gas 等于这个操作背后的所有运算花销的总和。 由于运行你的程序需要花费用户的真金白银，在以太坊中代码的编程语言，比其他任何编程语言都更强调优化。同样的功能，使用笨拙的代码开发的程序，比起经过精巧优化的代码来，运行花费更高，这显然会给成千上万的用户带来大量不必要的开销。 为什么要用 gas 来驱动？以太坊就像一个巨大、缓慢、但非常安全的电脑。当你运行一个程序的时候，网络上的每一个节点都在进行相同的运算，以验证它的输出 —— 这就是所谓的”去中心化“ 由于数以千计的节点同时在验证着每个功能的运行，这可以确保它的数据不会被被监控，或者被刻意修改。 可能会有用户用无限循环堵塞网络，抑或用密集运算来占用大量的网络资源，为了防止这种事情的发生，以太坊的创建者为以太坊上的资源制定了价格，想要在以太坊上运算或者存储，你需要先付费。 省 gas 的招数：结构封装 （Struct packing）在第1课中，我们提到除了基本版的 uint 外，还有其他变种 uint：uint8，uint16，uint32等。 通常情况下我们不会考虑使用 unit 变种，因为无论如何定义 uint的大小，Solidity 为它保留256位的存储空间。例如，使用 uint8 而不是uint（uint256）不会为你节省任何 gas。 除非，把 unit 绑定到 struct 里面。 如果一个 struct 中有多个 uint，则尽可能使用较小的 uint, Solidity 会将这些 uint 打包在一起，从而占用较少的存储空间。例如： 1234567891011struct NormalStruct &#123; uint a; uint b; uint c;&#125;struct MiniMe &#123; uint32 a; uint32 b; uint c;&#125; // 因为使用了结构打包，mini 比 normal 占用的空间更少NormalStruct normal = NormalStruct(10, 20, 30);MiniMe mini = MiniMe(10, 20, 30);所以，当 uint 定义在一个 struct 中的时候，尽量使用最小的整数子类型以节约空间。 并且把同样类型的变量放一起（即在 struct 中将把变量按照类型依次放置），这样 Solidity 可以将存储空间最小化。例如，有两个 struct： uint c; uint32 a; uint32 b; 和 uint32 a; uint c; uint32 b; 前者比后者需要的gas更少，因为前者把uint32放一起了。 ch5. 时间单位Solidity 使用自己的本地时间单位。 变量 now 将返回当前的unix时间戳（自1970年1月1日以来经过的秒数）。 Solidity 还包含秒(seconds)，分钟(minutes)，小时(hours)，天(days)，周(weeks) 和 年(years) 等时间单位。它们都会转换成对应的秒数放入 uint 中。所以 1分钟 就是 60，1小时是 3600（60秒×60分钟），1天是86400（24小时×60分钟×60秒），以此类推。 示例：1234567891011uint lastUpdated;// 将‘上次更新时间’ 设置为 ‘现在’function updateTimestamp() public &#123; lastUpdated = now;&#125;// 如果到上次`updateTimestamp` 超过5分钟，返回 &apos;true&apos;// 不到5分钟返回 &apos;false&apos;function fiveMinutesHavePassed() public view returns (bool) &#123; return (now &gt;= (lastUpdated + 5 minutes)); ch6. 结构体作为参数传入由于结构体的存储指针可以以参数的方式传递给一个 private 或 internal 的函数，因此结构体可以在多个函数之间相互传递。 遵循这样的语法： 123function _doStuff(Zombie storage _zombie) internal &#123; // do stuff with _zombie&#125; ch7. 公有函数和安全性你必须仔细地检查所有声明为 public 和 external的函数，一个个排除用户滥用它们的可能，谨防安全漏洞。请记住，如果这些函数没有类似 onlyOwner 这样的函数修饰符，用户能利用各种可能的参数去调用它们。 ch8. 进一步了解函数修饰符带参数的函数修饰符之前我们已经读过一个简单的函数修饰符了：onlyOwner。函数修饰符也可以带参数。例如： 1234567891011121314// 存储用户年龄的映射mapping (uint =&gt; uint) public age;// 限定用户年龄的修饰符modifier olderThan(uint _age, uint _userId) &#123; require(age[_userId] &gt;= _age); _;&#125;// 必须年满16周岁才允许开车 (至少在美国是这样的).// 我们可以用如下参数调用`olderThan` 修饰符:function driveCar(uint _userId) public olderThan(16, _userId) &#123; // 其余的程序逻辑&#125; 看到了吧， olderThan 修饰符可以像函数一样接收参数，是“宿主”函数 driveCar 把参数传递给它的修饰符的。 ch10. 利用 ‘View’ 函数节省 Gas“view” 函数不花 “gas”当玩家从外部调用一个view函数，是不需要支付一分 gas 的。 这是因为 view 函数不会真正改变区块链上的任何数据 - 它们只是读取。因此用 view 标记一个函数，意味着告诉 web3.js，运行这个函数只需要查询你的本地以太坊节点，而不需要在区块链上创建一个事务（事务需要运行在每个节点上，因此花费 gas）。 稍后我们将介绍如何在自己的节点上设置 web3.js。但现在，你关键是要记住，在所能只读的函数上标记上表示“只读”的“external view 声明，就能为你的玩家减少在 DApp 中 gas 用量。 注意：如果一个 view 函数在另一个函数的内部被调用，而调用函数与 view 函数的不属于同一个合约，也会产生调用成本。这是因为如果主调函数在以太坊创建了一个事务，它仍然需要逐个节点去验证。所以标记为 view 的函数只有在外部调用时才是免费的。 ch11. 存储非常昂贵Solidity 使用storage(存储)是相当昂贵的，”写入“操作尤其贵。 这是因为，无论是写入还是更改一段数据， 这都将永久性地写入区块链。”永久性“啊！需要在全球数千个节点的硬盘上存入这些数据，随着区块链的增长，拷贝份数更多，存储量也就越大。这是需要成本的！ 为了降低成本，不到万不得已，避免将数据写入存储。这也会导致效率低下的编程逻辑 - 比如每次调用一个函数，都需要在 memory(内存) 中重建一个数组，而不是简单地将上次计算的数组给存储下来以便快速查找。 在大多数编程语言中，遍历大数据集合都是昂贵的。但是在 Solidity 中，使用一个标记了external view的函数，遍历比 storage 要便宜太多，因为 view 函数不会产生任何花销。 （gas可是真金白银啊！）。 我们将在下一章讨论for循环，现在我们来看一下看如何如何在内存中声明数组。 在内存中声明数组在数组后面加上 memory关键字， 表明这个数组是仅仅在内存中创建，不需要写入外部存储，并且在函数调用结束时它就解散了。与在程序结束时把数据保存进 storage 的做法相比，内存运算可以大大节省gas开销 – 把这数组放在view里用，完全不用花钱。 以下是申明一个内存数组的例子： 12345678910function getArray() external pure returns(uint[]) &#123; // 初始化一个长度为3的内存数组 uint[] memory values = new uint[](3); // 赋值 values.push(1); values.push(2); values.push(3); // 返回数组 return values;&#125; 这个小例子展示了一些语法规则，下一章中，我们将通过一个实际用例，展示它和 for 循环结合的做法。 注意：内存数组 必须 用长度参数（在本例中为3）创建。目前不支持 array.push()之类的方法调整数组大小，在未来的版本可能会支持长度修改。 使用 for 循环for循环的语法在 Solidity 和 JavaScript 中类似。 来看一个创建偶数数组的例子：12345678910111213141516function getEvens() pure external returns(uint[]) &#123; uint[] memory evens = new uint[](5); // 在新数组中记录序列号 uint counter = 0; // 在循环从1迭代到10： for (uint i = 1; i &lt;= 10; i++) &#123; // 如果 `i` 是偶数... if (i % 2 == 0) &#123; // 把它加入偶数数组 evens[counter] = i; //索引加一， 指向下一个空的‘even’ counter++; &#125; &#125; return evens;&#125; 这个函数将返回一个形为 [2,4,6,8,10] 的数组。","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"blockchain","slug":"blockchain","permalink":"http://yoursite.com/tags/blockchain/"},{"name":"智能合约","slug":"智能合约","permalink":"http://yoursite.com/tags/智能合约/"}]},{"title":"","slug":"block_chain/在私有网络上搭建3个以上节点","date":"2018-08-29T13:14:48.227Z","updated":"2018-08-29T13:14:48.227Z","comments":true,"path":"2018/08/29/block_chain/在私有网络上搭建3个以上节点/","link":"","permalink":"http://yoursite.com/2018/08/29/block_chain/在私有网络上搭建3个以上节点/","excerpt":"","text":"在私有网络上搭建3个以上节点Step 1: 创建创世块Step 2: 删除旧数据Step 3: 重新初始化创世块Step 4: 发现每个节点的enode地址Step 5: 在每个节点上创建static-nodes.json文件Step 6: 启动私人网络Step 7: 在私网上挖掘","categories":[],"tags":[]},{"title":"redis ops learn","slug":"backend/go/redis/redis_start_learn","date":"2018-08-29T13:07:26.000Z","updated":"2018-08-29T13:07:54.323Z","comments":true,"path":"2018/08/29/backend/go/redis/redis_start_learn/","link":"","permalink":"http://yoursite.com/2018/08/29/backend/go/redis/redis_start_learn/","excerpt":"","text":"连接测试123456789101112131415161718192021222324package mainimport ( \"github.com/go-redis/redis\" \"fmt\" \"log\")func main() &#123; client := redis.NewClient(&amp;redis.Options&#123; Addr: \"localhost:6379\", Password: \"\", //默认空密码 DB: 0, //使用默认数据库 &#125;) defer client.Close() //最后关闭 pong, err := client.Ping().Result() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(\"Connected result: \", pong)&#125; ops: strings12345678910// ops: strings//// setclient.Set(\"hello\", \"hello redis\",0) //忽略错误//// get stringstr := client.Get(\"hello\")fmt.Println(str)//// del stringclient.Del(\"strtest\") ops: lists1234567891011// ops: lists//// pushclient.LPush(\"list\",\"one\",\"two\",\"three\") //rpush则在尾部插入//// rm, popclient.LRem(\"list\",2,\"three\") //删除list中前2个value为 ‘three’的元素client.LPop(\"list\") //删除头部的值，同理RPop删除尾部的值。// rangelist, _ := client.LRange(\"list\", 0, 2).Result()fmt.Println(\"List: \", list) ops: hashes1234567891011121314151617181920// hashes//// setuser := make(map[string]interface&#123;&#125;)user[\"name\"] = \"jim\"user[\"gender\"] = \"man\"user[\"age\"] = 23client.HMSet(\"user\",user)//// setclient.HSet(\"user\", \"name\",\"tom\")//// getname := client.HGet(\"user\",\"name\")fmt.Print(name)//// getAllhash, _ := client.HGetAll(\"user\").Result()for k, v:= range hash&#123; fmt.Printf(\"key: %v, value: %v \",k, v)&#125; 参考: https://www.jianshu.com/p/4045a3721b3c","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"grpc start learn","slug":"backend/go/grpc/grpc_start_learn","date":"2018-08-29T12:21:53.000Z","updated":"2018-08-29T12:22:49.760Z","comments":true,"path":"2018/08/29/backend/go/grpc/grpc_start_learn/","link":"","permalink":"http://yoursite.com/2018/08/29/backend/go/grpc/grpc_start_learn/","excerpt":"","text":"ex helloworld start基本流程建立流程: 建 proto3 文件, 定义 service service 开发 client 开发 1. proto 文件123456789101112131415// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user's name.message HelloRequest &#123; string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123; string message = 1;&#125; 定义了一个 service Greeter , 参数: SayHello, return: HelloReply 2. service 开发1234567891011121314151617181920212223242526const ( port = \":50051\")// server is used to implement helloworld.GreeterServer.type server struct&#123;&#125;// 实现 helloworld.GreeterServer 方法// SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; return &amp;pb.HelloReply&#123;Message: \"Hello \" + in.Name&#125;, nil&#125;func main() &#123; lis, err := net.Listen(\"tcp\", port) // 开启监听 if err != nil &#123; log.Fatalf(\"failed to listen: %v\", err) &#125; s := grpc.NewServer() // 建一个 grpc Server pb.RegisterGreeterServer(s, &amp;server&#123;&#125;) // 将 RegisterGreeterServer 服务绑定到 grpc 上 // Register reflection service on gRPC server. reflection.Register(s) // 将服务注册到 rpc 上 if err := s.Serve(lis); err != nil &#123; // s.Serve(lis) 是将 grpc 服务绑定监听端口 log.Fatalf(\"failed to serve: %v\", err) &#125;&#125; 流程: 开一个监听端口 建立一个 rpc 服务 将服务绑定到 rpc 上 将服务注册到 rpc 上 绑定 grpc 服务 和 端口监听 3. client 使用 grpc 服务123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( \"log\" \"os\" \"time\" \"golang.org/x/net/context\" \"google.golang.org/grpc\" pb \"google.golang.org/grpc/examples/helloworld/helloworld\")const ( address = \"localhost:50051\" defaultName = \"jie\")func main() &#123; // Set up a connection to the server. conn, err := grpc.Dial(address, grpc.WithInsecure()) // 创建客户端 if err != nil &#123; log.Fatalf(\"did not connect: %v\", err) &#125; defer conn.Close() // 延迟关闭连接 c := pb.NewGreeterClient(conn) // 新建一个Greeter连接客户端 // Contact the server and print out its response. name := defaultName if len(os.Args) &gt; 1 &#123; name = os.Args[1] &#125; ctx, cancel := context.WithTimeout(context.Background(), time.Second) // 设置超时 时间 defer cancel() r, err := c.SayHello(ctx, &amp;pb.HelloRequest&#123;Name: name&#125;) // 使用客户端调用远程方法 if err != nil &#123; log.Fatalf(\"could not greet: %v\", err) &#125; log.Printf(\"Greeting: %s\", r.Message)&#125; 流程: 创建客户端 新建一个Greeter连接客户端 设置超时 时间 使用客户端调用远程方法 cloes客户端连接 and cancel() 总结:","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"grpc","slug":"grpc","permalink":"http://yoursite.com/tags/grpc/"}]},{"title":"gin learn start","slug":"backend/go/gin/gin_learn_start","date":"2018-08-29T12:12:00.000Z","updated":"2018-09-04T15:07:50.233Z","comments":true,"path":"2018/08/29/backend/go/gin/gin_learn_start/","link":"","permalink":"http://yoursite.com/2018/08/29/backend/go/gin/gin_learn_start/","excerpt":"","text":"learn go ginParams: Get req params 如何启动一个服务器. url 地址中的参数获取. Get 参数的获取. post req params 如何获取 POST 请求的参数. 结构化获取参数 如何定义 return: string json 拦截器: 如何定义和使用拦截器 Params1. 启动一个简单的服务器Ex:12345678910111213package mainimport \"github.com/gin-gonic/gin\"func main() &#123; r := gin.Default() r.GET(\"/ping\", func(c *gin.Context) &#123; c.JSON(200, gin.H&#123; \"message\": \"pong\", &#125;) &#125;) r.Run() // listen and serve on 0.0.0.0:8080&#125; 1curl http://localhost:8080/ping summary: 导包: import &quot;github.com/gin-gonic/gin&quot; 启动一个默认的路由: r := gin.Default() 注册路径: r.GET(&quot;/ping&quot;, handlers ...HandlerFunc) 启动服务: r.Run() , 默认在8080端口 2. Parameters in path1234567891011121314151617181920func main() &#123; router := gin.Default() // This handler will match /user/john but will not match /user/ or /user router.GET(\"/user/:name\", func(c *gin.Context) &#123; name := c.Param(\"name\") c.String(http.StatusOK, \"Hello %s\", name) &#125;) // However, this one will match /user/john/ and also /user/john/send // If no other routers match /user/john, it will redirect to /user/john/ router.GET(\"/user/:name/*action\", func(c *gin.Context) &#123; name := c.Param(\"name\") action := c.Param(\"action\") message := name + \" is \" + action c.String(http.StatusOK, message) &#125;) router.Run(\":8080\")&#125; 3. Querystring parameters12345678910111213func main() &#123; router := gin.Default() // Query string parameters are parsed using the existing underlying request object. // The request responds to a url matching: /welcome?firstname=Jane&amp;lastname=Doe router.GET(\"/welcome\", func(c *gin.Context) &#123; firstname := c.DefaultQuery(\"firstname\", \"Guest\") lastname := c.Query(\"lastname\") // shortcut for c.Request.URL.Query().Get(\"lastname\") c.String(http.StatusOK, \"Hello %s %s\", firstname, lastname) &#125;) router.Run(\":8080\")&#125; 4. POST 参数解析123456789101112131415func main() &#123; router := gin.Default() router.POST(\"/form_post\", func(c *gin.Context) &#123; message := c.PostForm(\"message\") nick := c.DefaultPostForm(\"nick\", \"anonymous\") c.JSON(200, gin.H&#123; \"status\": \"posted\", \"message\": message, \"nick\": nick, &#125;) &#125;) router.Run(\":8080\")&#125; 5. 上传文件12345678910111213141516func main() &#123; router := gin.Default() // Set a lower memory limit for multipart forms (default is 32 MiB) // router.MaxMultipartMemory = 8 &lt;&lt; 20 // 8 MiB router.POST(\"/upload\", func(c *gin.Context) &#123; // single file file, _ := c.FormFile(\"file\") log.Println(file.Filename) // Upload the file to specific dst. // c.SaveUploadedFile(file, dst) c.String(http.StatusOK, fmt.Sprintf(\"'%s' uploaded!\", file.Filename)) &#125;) router.Run(\":8080\")&#125; 123curl -X POST http://localhost:8080/upload \\ -F \"file=@/Users/appleboy/test.zip\" \\ -H \"Content-Type: multipart/form-data\" 多文件上传12345678910111213141516171819func main() &#123; router := gin.Default() // Set a lower memory limit for multipart forms (default is 32 MiB) // router.MaxMultipartMemory = 8 &lt;&lt; 20 // 8 MiB router.POST(\"/upload\", func(c *gin.Context) &#123; // Multipart form form, _ := c.MultipartForm() files := form.File[\"upload[]\"] for _, file := range files &#123; log.Println(file.Filename) // Upload the file to specific dst. // c.SaveUploadedFile(file, dst) &#125; c.String(http.StatusOK, fmt.Sprintf(\"%d files uploaded!\", len(files))) &#125;) router.Run(\":8080\")&#125; 1234curl -X POST http://localhost:8080/upload \\ -F \"upload[]=@/Users/appleboy/test1.zip\" \\ -F \"upload[]=@/Users/appleboy/test2.zip\" \\ -H \"Content-Type: multipart/form-data\" Grouping routes(分组路由)123456789101112131415161718192021func main() &#123; router := gin.Default() // Simple group: v1 v1 := router.Group(\"/v1\") &#123; v1.POST(\"/login\", loginEndpoint) v1.POST(\"/submit\", submitEndpoint) v1.POST(\"/read\", readEndpoint) &#125; // Simple group: v2 v2 := router.Group(\"/v2\") &#123; v2.POST(\"/login\", loginEndpoint) v2.POST(\"/submit\", submitEndpoint) v2.POST(\"/read\", readEndpoint) &#125; router.Run(\":8080\")&#125; 分组有利于在分组上定义拦截器. 拦截器1234567891011121314151617181920212223242526272829303132333435func main() &#123; // Creates a router without any middleware by default r := gin.New() // Global middleware // Logger middleware will write the logs to gin.DefaultWriter even if you set with GIN_MODE=release. // By default gin.DefaultWriter = os.Stdout r.Use(gin.Logger()) // Recovery middleware recovers from any panics and writes a 500 if there was one. r.Use(gin.Recovery()) // Per route middleware, you can add as many as you desire. r.GET(\"/benchmark\", MyBenchLogger(), benchEndpoint) // Authorization group // authorized := r.Group(\"/\", AuthRequired()) // exactly the same as: authorized := r.Group(\"/\") // per group middleware! in this case we use the custom created // AuthRequired() middleware just in the \"authorized\" group. authorized.Use(AuthRequired()) &#123; authorized.POST(\"/login\", loginEndpoint) authorized.POST(\"/submit\", submitEndpoint) authorized.POST(\"/read\", readEndpoint) // nested group testing := authorized.Group(\"testing\") testing.GET(\"/analytics\", analyticsEndpoint) &#125; // Listen and serve on 0.0.0.0:8080 r.Run(\":8080\")&#125; Model binding and validation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// Binding from JSONtype Login struct &#123; User string `form:\"user\" json:\"user\" xml:\"user\" binding:\"required\"` Password string `form:\"password\" json:\"password\" xml:\"password\" binding:\"required\"`&#125;func main() &#123; router := gin.Default() // Example for binding JSON (&#123;\"user\": \"manu\", \"password\": \"123\"&#125;) router.POST(\"/loginJSON\", func(c *gin.Context) &#123; var json Login if err := c.ShouldBindJSON(&amp;json); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;\"error\": err.Error()&#125;) return &#125; if json.User != \"manu\" || json.Password != \"123\" &#123; c.JSON(http.StatusUnauthorized, gin.H&#123;\"status\": \"unauthorized\"&#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123;\"status\": \"you are logged in\"&#125;) &#125;) // Example for binding XML ( // &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; // &lt;root&gt; // &lt;user&gt;user&lt;/user&gt; // &lt;password&gt;123&lt;/user&gt; // &lt;/root&gt;) router.POST(\"/loginXML\", func(c *gin.Context) &#123; var xml Login if err := c.ShouldBindXML(&amp;xml); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;\"error\": err.Error()&#125;) return &#125; if xml.User != \"manu\" || xml.Password != \"123\" &#123; c.JSON(http.StatusUnauthorized, gin.H&#123;\"status\": \"unauthorized\"&#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123;\"status\": \"you are logged in\"&#125;) &#125;) // Example for binding a HTML form (user=manu&amp;password=123) router.POST(\"/loginForm\", func(c *gin.Context) &#123; var form Login // This will infer what binder to use depending on the content-type header. if err := c.ShouldBind(&amp;form); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;\"error\": err.Error()&#125;) return &#125; if form.User != \"manu\" || form.Password != \"123\" &#123; c.JSON(http.StatusUnauthorized, gin.H&#123;\"status\": \"unauthorized\"&#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123;\"status\": \"you are logged in\"&#125;) &#125;) // Listen and serve on 0.0.0.0:8080 router.Run(\":8080\")&#125; 1234$ curl -v -X POST \\ http://localhost:8080/loginJSON \\ -H 'content-type: application/json' \\ -d '&#123; \"user\": \"manu\" &#125;' params summary参数解析方法: 123456789101112131415161718192021222324252627282930313233343536// router.GET(\"/user/:name/*action\", handlers ...HandlerFunc)name := c.Param(\"name\")action := c.Param(\"action\")// req Url: /welcome?firstname=Jane&amp;lastname=Doefirstname := c.DefaultQuery(\"firstname\", \"Guest\")lastname := c.Query(\"lastname\") // shortcut for c.Request.URL.Query().Get(\"lastname\")// POSTmessage := c.PostForm(\"message\")nick := c.DefaultPostForm(\"nick\", \"anonymous\")// 上传文件file, _ := c.FormFile(\"file\")// 多文件上传form, _ := c.MultipartForm()files := form.File[\"upload[]\"]// 定义结构体type Login struct &#123; User string `form:\"user\" json:\"user\" xml:\"user\" binding:\"required\"` Password string `form:\"password\" json:\"password\" xml:\"password\" binding:\"required\"`&#125;// bind JSON: &#123;\"user\": \"manu\", \"password\": \"123\"&#125;c.ShouldBindJSON(&amp;json)// bind XML: // &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;// &lt;root&gt;// &lt;user&gt;user&lt;/user&gt;// &lt;password&gt;123&lt;/user&gt;// &lt;/root&gt;c.ShouldBindXML(&amp;xml)// bind form: user=manu&amp;password=123c.ShouldBind(&amp;form)","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"gin","slug":"gin","permalink":"http://yoursite.com/tags/gin/"}]},{"title":"goose learn start","slug":"backend/go/goose/goose_start_learn","date":"2018-08-29T12:12:00.000Z","updated":"2018-08-29T12:13:18.646Z","comments":true,"path":"2018/08/29/backend/go/goose/goose_start_learn/","link":"","permalink":"http://yoursite.com/2018/08/29/backend/go/goose/goose_start_learn/","excerpt":"","text":"what goose goose is a database migration tool.You can manage your database’s evolution by creating incremental SQL or Go scripts. install这个前提是需要安装 golang, 并会就 goose 命令生成到 $GOPATH/bin 目录下.1$ go get bitbucket.org/liamstask/goose/cmd/goose Usage12345678910111213141516171819202122$ goosegoose is a database migration management system for Go projects.Usage: goose [options] &lt;subcommand&gt; [subcommand options]Options: -env string which DB environment to use (default \"development\") -path string folder containing db info (default \"db\") -pgschema string which postgres-schema to migrate (default = none)Commands: up Migrate the DB to the most recent version available down Roll back the version by 1 redo Re-run the latest migration status dump the migration status for the current DB create Create the scaffolding for a new migration dbversion Print the current version of the database create创建一个新的 migration , 这个创建的是 go migration1goose create AddSomeColumns 如果是创建 sql migration 的话, 在后边加个 sql 即可.1goose create AddSomeColumns sql up应用所有可用的 migrations 1goose up down从当前版本回滚单个 migrations1goose down redo回滚最近应用的 migrations ，然后再次运行它。 1goose redo status打印所有 migrations 的状态： 1goose status dbversion1goose dbversion 个人实验数据配置如下:目录结构: jieLearn/├── dbconf.yml└── migrations ├── 20180829163647_jieTest.sql └── 20180829165529_addC4Col.sql 12345$ cat dbconf.ymldevelopment: driver: mysql open: root:password@tcp(127.0.0.1:3306)/jie_test?timeout=200ms&amp;parseTime=true&amp;loc=Local 123456789101112131415161718192021222324252627282930313233$ cat jieLearn/migrations/20180829163647_jieTest.sql-- +goose Up-- SQL in section 'Up' is executed when this migration is appliedCREATE TABLE `jie_test`.`test_table` ( `c1` INT NOT NULL, `c2` VARCHAR(45) NULL, `c3` VARCHAR(45) NULL, PRIMARY KEY (`c1`));-- +goose Down-- SQL section 'Down' is executed when this migration is rolled backDROP TABLE `jie_test`.`test_table`;$ cat jieLearn/migrations/20180829165529_addC4Col.sql-- +goose Up-- SQL in section 'Up' is executed when this migration is appliedALTER TABLE `jie_test`.`test_table`ADD COLUMN `c4` VARCHAR(45) NULL AFTER `c3`;-- +goose Down-- SQL section 'Down' is executed when this migration is rolled backALTER TABLE `jie_test`.`test_table`DROP COLUMN `c4`;$ goose -path \"jieLearn\" up$ goose -path \"jieLearn\" down 数据库new table: goose_db_version, test_table goose_db_version: content1234561 0 1 2018-08-29 08:33:232 20180829163647 1 2018-08-29 08:33:233 20180829163647 0 2018-08-29 08:34:534 20180829163647 1 2018-08-29 08:35:355 20180829165529 1 2018-08-29 08:42:396 20180829165529 0 2018-08-29 08:43:00 参考: https://bitbucket.org/liamstask/goose","categories":[{"name":"backend","slug":"backend","permalink":"http://yoursite.com/categories/backend/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"},{"name":"goose","slug":"goose","permalink":"http://yoursite.com/tags/goose/"}]},{"title":"Build a Simple Database - 模块功能概述","slug":"build_own_x/data_base/build_simple_database/模块功能概述","date":"2018-05-17T11:59:57.000Z","updated":"2018-08-29T13:39:43.199Z","comments":true,"path":"2018/05/17/build_own_x/data_base/build_simple_database/模块功能概述/","link":"","permalink":"http://yoursite.com/2018/05/17/build_own_x/data_base/build_simple_database/模块功能概述/","excerpt":"","text":"sqlite architecture (https://www.sqlite.org/arch.html) 小结: core: 主要的构成模块: interface, sqlCommand Processor, Virtual Machine SQL Compiler: Tokenizer, Parser, Code Generator Backend: B-Tree, Pager, OS Interface 翻译:(https://www.sqlite.org/arch.html) 概览SQLite的工作原理是将SQL文本编译为字节码，然后使用虚拟机运行该字节码。 sqlite3_prepare_v2（）和相关接口充当用于将SQL文本转换为字节码的编译器。 sqlite3_stmt对象是用于实现单个SQL语句的单个字节码程序的容器。 sqlite3_step（）接口将一个字节码程序传递给虚拟机，并运行该程序直到它完成，或者形成一行结果返回，或者发生致命错误或中断。 Interface许多C语言接口可以在源文件main.c，legacy.c和vdbeapi.c中找到，尽管一些例程分散在其他文件中，在这些文件中它们可以访问具有文件范围的数据结构。sqlite3_get_table（）例程在table.c中实现。 sqlite3_mprintf（）例程在printf.c中找到。 sqlite3_complete（）接口位于tokenize.c中。 TCL接口由tclsqlite.c实现。 为避免名称冲突，SQLite库中的所有外部符号都以前缀sqlite3开头。那些用于外部使用的符号（换句话说，那些构成SQLite API的符号）会添加一个下划线，因此以sqlite3_开头。扩展API有时会在下划线之前添加扩展名;例如：sqlite3rbu_或sqlite3session_。 Tokenizer当包含SQL语句的字符串要被评估时，它首先被发送到标记器。标记器将SQL文本分解为标记并将这些标记逐个传递给解析器。标记器是在文件tokenize.c中手动编码的 请注意，在此设计中，标记器调用解析器。熟悉YACC和BISON的人可能习惯于以相反的方式做事 - 让解析器调用标记器。不过，令牌分析器调用分析器会更好，因为它可以做成线程安全的并且运行速度更快。 Parser解析器根据其上下文为令牌分配含义。 SQLite的解析器是使用Lemon解析器生成器生成的。Lemon和YACC / BISON一样工作，但它使用了不太容易出错的不同输入语法。Lemon还生成一个可重入且线程安全的解析器。Lemon定义了非终端析构函数的概念，以便在遇到语法错误时不会泄漏内存。驱动Lemon并定义SQLite可理解的SQL语言的语法文件可在parse.y中找到。 因为Lemon是一个通常在开发机器上找不到的程序，Lemon的完整源代码（只有一个C文件）包含在SQLite分发的“tool”子目录中。 Code Generator解析器将令牌组装成解析树之后，代码生成器运行以分析解析器树并生成执行SQL语句工作的字节码。准备好的语句对象是这个字节码的容器。代码生成器中有许多文件，其中包括：attach.c，auth.c，build.c，delete.c，expr.c，insert.c，pragma.c，select.c，trigger.c，update.c ，vacuum.c，where.c，wherecode.c和whereexpr.c。在这些文件中，大部分严重的魔法都是在这里发生的。 expr.c处理表达式的代码生成。其中* .c处理SELECT，UPDATE和DELETE语句中WHERE子句的代码生成。文件attach.c，delete.c，insert.c，select.c，trigger.c update.c和vacuum.c处理具有相同名称的SQL语句的代码生成。 （这些文件中的每一个都根据需要调用expr.c和where.c中的例程。）所有其他SQL语句都由build.c编码。 auth.c文件实现sqlite3_set_authorizer（）的功能 代码生成器，特别是* .c和select.c中的逻辑有时称为查询规划器。对于任何特定的SQL语句，可能有数百，数千或数百万种不同的算法来计算答案。查询计划员是一个AI，致力于从数百万个选择中选择最佳算法。 Bytecode Engine由代码生成器创建的字节码程序由虚拟机运行。 虚拟机本身完全包含在单个源文件vdbe.c中。 vdbe.h头文件定义了虚拟机和SQLite库的其余部分之间的接口，vdbeInt.h定义了虚拟机本身专用的结构和接口。其他各种vdbe * .c文件都是虚拟机的助手。 vdbeaux.c文件包含虚拟机使用的实用程序以及库的其余部分用于构建VM程序的接口模块。 vdbeapi.c文件包含虚拟机的外部接口，如sqlite3_bind_int（）和sqlite3_step（）。各个值（字符串，整数，浮点数和BLOB）存储在由vdbemem.c实现的名为“Mem”的内部对象中。 SQLite使用C语言例程的回调来实现SQL函数。即使内置的SQL函数也是这样实现的。大多数内置的SQL函数（例如：abs（），count（），substr（）等）都可以在func.c源文件中找到。日期和时间转换函数可在date.c中找到。一些函数如coalesce（）和typeof（）直接由代码生成器实现为字节码。 B-TreeSQLite数据库使用btree.c源文件中的B-tree实现在磁盘上进行维护。数据库中的每个表和索引都使用单独的B树。所有B树都存储在同一个磁盘文件中。文件格式细节稳定且定义明确，并保证向前兼容。 B树子系统和SQLite库的其余部分的接口由头文件btree.h定义。 Page CacheB树模块以固定大小的页面从磁盘请求信息。默认的page_size是4096字节，但可以是512到65536字节之间的任意两个幂。页面缓存负责读取，写入和缓存这些页面。页面缓存还提供了回滚和原子提交抽象，并负责锁定数据库文件。 B树驱动程序请求页面缓存中的特定页面，并在需要修改页面或提交或回滚更改时通知页面缓存。页面缓存处理了确保请求被快速，安全和有效地处理的所有细节. 主页面缓存实现在pager.c文件中。 WAL模式逻辑位于单独的wal.c中。内存中缓存由pcache.c和pcache1.c文件实现。页面缓存子系统和SQLite其余部分之间的接口由头文件pager.h定义。 ###OS Interface 为了提供跨操作系统的可移植性，SQLite使用称为VFS的抽象对象。每个VFS都提供了打开，读取，写入和关闭磁盘上的文件以及执行其他特定于操作系统的任务（如查找当前时间或获取随机性以初始化内置伪随机数生成器的方法）。 SQLite当前为unix（在os_unix.c文件中）和Windows（在os_win.c文件中）提供了VFSes。 Utilities内存分配，无格式字符串比较例程，便携式文本到数字转换例程以及其他实用程序位于util.c中。解析器使用的符号表由散列表中的哈希表维护。 utf.c源文件包含Unicode转换子例程。 SQLite在printf.c中有它自己的printf（）（有一些扩展）的私有实现，在random.c中有它自己的伪随机数生成器（PRNG）。 总结:sqlite(数据库)将数据持久化,并将其做到了极致吧.(引人深思) 整体结构, 主要分成三部分: 1. core, 2. SQL Compiler, 3. Backend 其主要流程也相当清晰: interface -&gt; sqlCommand Processor -&gt; Virtual Machine","categories":[{"name":"build-own-x","slug":"build-own-x","permalink":"http://yoursite.com/categories/build-own-x/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"db原理","slug":"db原理","permalink":"http://yoursite.com/tags/db原理/"}]},{"title":"Dual pivot Quicksort","slug":"alg/sorting/Dual_pivot_Quicksort","date":"2018-04-27T06:55:52.000Z","updated":"2018-08-29T13:21:32.071Z","comments":true,"path":"2018/04/27/alg/sorting/Dual_pivot_Quicksort/","link":"","permalink":"http://yoursite.com/2018/04/27/alg/sorting/Dual_pivot_Quicksort/","excerpt":"","text":"time: 2018-04-27 14:55:52 参考：https://www.geeksforgeeks.org/dual-pivot-quicksort/ The idea of dual pivot quick sort is to take two pivots, one in the left end of the array and the second, in the right end of the array. The left pivot must be less than or equal to the right pivot, so we swap them if necessary. Then, we begin partitioning the array into three parts: in the first part, all elements will be less than the left pivot, in the second part all elements will be greater or equal to the left pivot and also will be less than or equal to the right pivot, and in the third part all elements will be greater than the right pivot. Then, we shift the two pivots to their appropriate positions as we see in the below bar, and after that we begin quicksorting these three parts recursively, using this method. Dual pivot quick sort is a little bit faster than the original single pivot quicksort.But still, the worst case will remain O(n^2) when the array is already sorted in an increasing or decreasing order. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// C program to implement dual pivot QuickSort#include &lt;stdio.h&gt;int partition(int* arr, int low, int high, int* lp);void swap(int* a, int* b)&#123; int temp = *a; *a = *b; *b = temp;&#125;void DualPivotQuickSort(int* arr, int low, int high)&#123; if (low &lt; high) &#123; // lp means left pivot, and rp means right pivot. int lp, rp; rp = partition(arr, low, high, &amp;lp); DualPivotQuickSort(arr, low, lp - 1); DualPivotQuickSort(arr, lp + 1, rp - 1); DualPivotQuickSort(arr, rp + 1, high); &#125;&#125;int partition(int* arr, int low, int high, int* lp)&#123; printf(\"------- begin partition --------\\n\"); if (arr[low] &gt; arr[high]) swap(&amp;arr[low], &amp;arr[high]); // p is the left pivot, and q is the right pivot. int j = low + 1,g = high - 1; int k = low + 1, p = arr[low], q = arr[high]; while (k &lt;= g) &#123; printf(\"j: %d value: %d, g: %d value: %d, k: %d value: %d\\n\", j, arr[j], g, arr[g], k, arr[k]); // if elements are less than the left pivot if (arr[k] &lt; p) &#123; swap(&amp;arr[k], &amp;arr[j]); j++; &#125; // if elements are greater than or equal // to the right pivot else if (arr[k] &gt;= q) &#123; while (arr[g] &gt; q &amp;&amp; k &lt; g) g--; swap(&amp;arr[k], &amp;arr[g]); g--; if (arr[k] &lt; p) &#123; swap(&amp;arr[k], &amp;arr[j]); j++; &#125; &#125; k++; for (int i = 0; i &lt; 8; i++) printf(\"%d \", arr[i]); printf(\"\\n\"); &#125; j--; g++; // bring pivots to their appropriate positions. swap(&amp;arr[low], &amp;arr[j]); swap(&amp;arr[high], &amp;arr[g]); // returning the indeces of the pivots. *lp = j; // because we cannot return two elements // from a function. printf(\"------- end partition --------\\n\"); return g;&#125;// Driver codeint main()&#123; int arr[] = &#123; 24, 8, 42, 75, 29, 77, 38, 57 &#125;; printf(\"24, 8, 42, 75, 29, 77, 38, 57\\n\"); DualPivotQuickSort(arr, 0, 7); printf(\"Sorted array: \"); for (int i = 0; i &lt; 8; i++) printf(\"%d \", arr[i]); printf(\"\\n\"); return 0;&#125; 123456789101112131415161718192024, 8, 42, 75, 29, 77, 38, 57------- begin partition --------j: 1 value: 8, g: 6 value: 38, k: 1 value: 824 8 42 75 29 77 38 57 j: 2 value: 42, g: 6 value: 38, k: 2 value: 4224 8 42 75 29 77 38 57 j: 2 value: 42, g: 6 value: 38, k: 3 value: 7524 8 42 38 29 77 75 57 j: 2 value: 42, g: 5 value: 77, k: 4 value: 2924 8 42 38 29 77 75 57 j: 2 value: 42, g: 5 value: 77, k: 5 value: 7724 8 42 38 29 77 75 57 ------- end partition --------------- begin partition --------j: 3 value: 38, g: 3 value: 38, k: 3 value: 388 24 29 38 42 57 75 77 ------- end partition --------------- begin partition --------------- end partition --------Sorted array: 8 24 29 38 42 57 75 77 总结基本的处理流程： 选定最低位和最高位作为轴 num，也就是有两个轴。 lowPoint = low + 1 和 highPoint = high - 1 作为选轴的开始点。 scanPoint = lowPoint 一直扫描到 highPoint， 如果 scanPoint_Value &lt; low_Value : swap(lowPoint_Value, scanPoint_Value) elseif (scanPoint_Value &gt;= high_Value) : swap(highPoint_Value, scanPoint_Value) 最后 swap(low_Value, (lowPoint - 1).Value), swap(high_Value, (highPoint + 1)_Value)","categories":[{"name":"alg","slug":"alg","permalink":"http://yoursite.com/categories/alg/"}],"tags":[{"name":"sorting","slug":"sorting","permalink":"http://yoursite.com/tags/sorting/"}]}]}